# Chat prompts

# NOTE: This is the default system prompt from llama-index source code.
# We didn't include the "some rules to follow" stuff in the Gradio app
system_prompt = (
    "You are an expert Q&A system that is trusted around the world.\n"
    "Always answer the query using the provided context information, "
    "and not prior knowledge.\n"
    "Some rules to follow:\n"
    "1. Never directly reference the given context in your answer.\n"
    "2. Avoid statements like 'Based on the context, ...' or "
    "'The context information ...' or anything along "
    "those lines."
)

# Augmented Q&A prompt we used in Gradio app
qa_prompt_instruction_tmpl = (
    "Context information is below.\n"
    "---------------------\n"
    "{context_str}\n"
    "---------------------\n"
    "Given the context information and not prior knowledge, "
    "answer the query.\n"
    # "If the context information is entirely unrelated to the provided query, "
    # "don't try to answer the question; just say 'Sorry, I cannot answer "
    # "that question.'.\n"
    "Query: {query_str}\n"
    "{additional_instructions}\n"
    "Answer: "
)
