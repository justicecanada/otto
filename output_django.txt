=== Contents of django\import_timer.py ===
import os

import django
from django.urls import resolve

os.environ.setdefault("DJANGO_SETTINGS_MODULE", "otto.settings")
django.setup()
resolve("/")



=== Contents of django\manage.py ===
#!/usr/bin/env python
"""Django's command-line utility for administrative tasks."""
import os
import sys


def main():
    """Run administrative tasks."""
    os.environ.setdefault("DJANGO_SETTINGS_MODULE", "otto.settings")

    try:
        from django.core.management import execute_from_command_line
    except ImportError as exc:
        raise ImportError(
            "Couldn't import Django. Are you sure it's installed and "
            "available on your PYTHONPATH environment variable? Did you "
            "forget to activate a virtual environment?"
        ) from exc
    execute_from_command_line(sys.argv)


if __name__ == "__main__":
    main()



=== Contents of django\case_prep\__init__.py ===



=== Contents of django\case_prep\apps.py ===
from django.apps import AppConfig


class CasePrepConfig(AppConfig):
    default_auto_field = "django.db.models.BigAutoField"
    name = "case_prep"



=== Contents of django\case_prep\forms.py ===
from django import forms

from .models import Session


class SessionForm(forms.ModelForm):
    class Meta:
        model = Session
        fields = ["name"]
        labels = {"name": "Session Name"}



=== Contents of django\case_prep\models.py ===
from django.contrib.auth import get_user_model
from django.db import models

from otto.secure_models import SecureModel, SecureRelatedModel

User = get_user_model()


class Session(SecureModel):
    name = models.CharField(max_length=255)
    created_by = models.ForeignKey(User, on_delete=models.CASCADE)
    created_at = models.DateTimeField(auto_now_add=True)
    book_of_documents = models.FileField(
        upload_to="case_prep/books/", null=True, blank=True
    )

    def __str__(self):
        return self.name

    def get_next_sequence_number(self):
        last_document = self.document_set.order_by("-sequence").first()
        if last_document:
            return last_document.sequence + 1
        else:
            return 1


class Document(SecureRelatedModel):
    session = models.ForeignKey(Session, on_delete=models.CASCADE)
    sequence = models.IntegerField()
    original_name = models.TextField(blank=True)
    name = models.CharField(max_length=255)
    date = models.DateField(null=True, blank=True)
    file = models.FileField(upload_to="case_prep/%Y/%m/%d/")
    content_type = models.CharField(max_length=255, blank=True)
    hidden = models.BooleanField(default=False)
    created_at = models.DateTimeField(auto_now_add=True)

    def save(self, *args, **kwargs):
        if not self.pk:
            self.sequence = self.session.get_next_sequence_number()
        super().save(*args, **kwargs)

    def get_permission_parents(self):
        return [self.session]

    def __str__(self):
        return self.name



=== Contents of django\case_prep\urls.py ===
from django.conf import settings
from django.conf.urls.static import static
from django.urls import path

from . import views

app_name = "case_prep"


urlpatterns = [
    path("", views.index, name="index"),
    path("session/<str:session_id>/", views.session_detail, name="session_detail"),
    path("create_session/", views.create_session, name="create_session"),
    path(
        "delete_session/<str:session_id>/", views.delete_session, name="delete_session"
    ),
    path("delete_document/", views.delete_document, name="delete_document"),
    path("save_changes/", views.save_changes, name="save_changes"),
    path("upload_files/", views.upload_files, name="upload_files"),
    path(
        "generate_book_of_documents/",
        views.generate_book_of_documents,
        name="generate_book_of_documents",
    ),
    path(
        "download_book_of_documents/<str:session_id>/",
        views.download_book_of_documents,
        name="download_book_of_documents",
    ),
    path(
        "download_document/<str:document_id>/",
        views.download_document,
        name="download_document",
    ),
    path(
        "toggle_document_visibility/",
        views.toggle_document_visibility,
        name="toggle_document_visibility",
    ),
    path(
        "create_table_of_contents",
        views.create_table_of_contents,
        name="create_table_of_contents",
    ),
    path(
        "upvote_feature/<str:feature_handle>",
        views.upvote_feature,
        name="upvote_feature",
    ),
] + static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT)



=== Contents of django\case_prep\views.py ===
import io
import json
import mimetypes
import os
import re
import uuid
import zipfile
from datetime import datetime as dt
from io import BytesIO

from django.conf import settings
from django.core.files.base import ContentFile
from django.core.files.storage import default_storage
from django.http import FileResponse, JsonResponse
from django.shortcuts import redirect, render
from django.urls import reverse
from django.utils import timezone
from django.utils.translation import gettext as _

import docx
from docxtpl import DocxTemplate
from html2docx import html2docx
from structlog import get_logger

from otto.secure_models import AccessKey
from otto.utils.decorators import app_access_required

from .models import Document, Session

logger = get_logger(__name__)

app_name = "case_prep"


@app_access_required(app_name)
def index(request):
    sessions = Session.objects.all(AccessKey(request.user))
    return render(request, "case_prep/index.html", {"sessions": sessions})


@app_access_required(app_name)
def create_session(request):
    session = Session()
    access_key = AccessKey(request.user)
    session.id = uuid.uuid4()
    session.created_by = request.user
    session.name = timezone.now().strftime("%Y-%m-%d %H:%M:%S")
    session.save(AccessKey(bypass=True))
    session.grant_ownership_to(
        access_key,
        modified_by=access_key.user,
        reason="Owner of the object.",
    )
    return redirect("case_prep:session_detail", session_id=session.id)


def session_detail(request, session_id):
    access_key = AccessKey(request.user)
    session = Session.objects.get(access_key, pk=session_id)
    documents = Document.objects.filter(access_key, session=session)
    if documents:
        documents = documents.order_by("sequence")

    return render(
        request,
        "case_prep/session_detail.html",
        {"session": session, "documents": documents},
    )


def upload_files(request):
    # Check if the request method is POST
    if request.method == "POST":

        access_key = AccessKey(request.user)

        # Get the session from the session_id POST variable
        session_id = request.POST.get("session_id")
        session = Session.objects.get(access_key, pk=session_id)

        # Loop through the documents variable in request.FILES
        for uploaded_file in request.FILES.getlist("documents"):
            # If the uploaded file is a ZIP file
            if uploaded_file.name.endswith(".zip"):
                # Extract files from the ZIP archive
                with zipfile.ZipFile(uploaded_file, "r") as zip_ref:
                    for file_name in zip_ref.namelist():
                        # Extract each file and create a Document object
                        with zip_ref.open(file_name) as file:
                            # Get the original path and name of the file within the ZIP
                            original_name = os.path.basename(file_name)
                            # Name the file with the original name but without the path or extension
                            name = os.path.splitext(original_name)[0]
                            # Create a Django File object from the file content
                            django_file = ContentFile(file.read(), name=original_name)
                            # Determine content type based on file extension
                            content_type, _ = mimetypes.guess_type(original_name)
                            # Create a Document object with extracted file
                            if not name:
                                name = original_name
                            document = Document.objects.create(
                                access_key,
                                session=session,  # Assuming session is defined
                                original_name=original_name,
                                name=name,  # You can modify this as needed
                                file=django_file,
                                content_type=content_type or "application/octet-stream",
                            )
            else:
                # Create a Document object for non-ZIP files
                name = os.path.splitext(uploaded_file.name)[0]
                if not name:
                    name = uploaded_file.name
                document = Document.objects.create(
                    access_key,
                    session=session,  # Assuming session is defined
                    original_name=uploaded_file.name,
                    name=name,  # You can modify this as needed
                    file=uploaded_file,
                    content_type=uploaded_file.content_type,  # You can modify this as needed
                )

        documents = Document.objects.filter(access_key, session=session)
        if documents:
            documents = documents.order_by("sequence")

        # Return a the rendering of document_list.html template
        return render(
            request,
            "case_prep/document_list.html",
            {"documents": documents},
        )

    # If request method is not POST, return an error
    return JsonResponse({"error": "Invalid request method."}, status=400)


def delete_session(request, session_id):
    access_key = AccessKey(request.user)
    session = Session.objects.get(access_key, pk=session_id)

    logger.info(f"Deleting session {session_id}.")

    # Delete associated documents
    for document in session.document_set.all(access_key):
        document.delete(access_key)

    # Delete session
    session.delete(access_key)

    # Return success response
    return JsonResponse(
        {"message": "Session deleted successfully.", "url": reverse("case_prep:index")}
    )


def delete_document(request):
    access_key = AccessKey(request.user)

    # Get document_id from the body of the request
    document_id = json.loads(request.body)["document_id"]
    document = Document.objects.get(access_key, pk=document_id)

    logger.info(f"Deleting document {document_id}.")

    # Delete document
    document.delete(access_key)

    # Return success response
    return JsonResponse({"message": "Document deleted successfully."})


def save_changes(request):
    access_key = AccessKey(request.user)

    logger.info("Saving changes.")

    if request.method == "POST":

        # Set data to the body of the request which is a JSON array
        data = json.loads(request.body)

        for item in data:
            doc_id = item["id"]
            document = Document.objects.get(access_key, pk=doc_id)
            document.name = item["name"]
            document.sequence = item["sequence"]
            document.hidden = item["hidden"]

            # Check if the item["date"] is a valid YYYY-MM-DD date
            try:
                document.date = dt.strptime(item["date"], "%Y-%m-%d")
            except Exception as e:
                document.date = None

            logger.info(
                f"Saving changes for document {doc_id}.",
                name=document.name,
                sequence=document.sequence,
                hidden=document.hidden,
                date=document.date,
            )

            document.save(access_key)
        return JsonResponse({"message": "Document names updated successfully."})
    else:
        return JsonResponse({"error": "Invalid request method."}, status=400)


# Generate a book of documents by compressing all documents in a session into a ZIP file, naming them according to their sequence number, name, and date
def generate_book_of_documents(request):

    def sanitize_file_name(file_name):
        # Replace spaces and any non-alphanumeric characters with underscores
        sanitized_name = re.sub(r"[^\w\-_\.]", "_", file_name)
        return sanitized_name

    access_key = AccessKey(request.user)

    if request.method == "POST":
        session_id = json.loads(request.body)["session_id"]
        session = Session.objects.get(access_key, pk=session_id)

        # Create a BytesIO stream to hold the ZIP file in memory
        zip_buffer = BytesIO()

        with zipfile.ZipFile(zip_buffer, "w") as zip_ref:
            for document in session.document_set.filter(
                access_key, hidden=False
            ).order_by("sequence"):
                sequence_with_zero_padding = str(document.sequence).zfill(3)
                file_name = f"{sequence_with_zero_padding}_{document.name}_{document.date}.{document.file.name.split('.')[-1]}"
                file_name = sanitize_file_name(file_name)

                # Read the document content
                document_content = document.file.read()

                # Write the document content to the ZIP file
                zip_ref.writestr(file_name, document_content)

        # Ensure the buffer position is at the start
        zip_buffer.seek(0)

        # Save the ZIP file to the desired location in the storage
        file_name = f"{session.created_by.username}-{session.name}.zip"
        file_name = sanitize_file_name(file_name)
        file_path = default_storage.save(file_name, zip_buffer)

        # Update the session model instance with the file path
        session.book_of_documents = file_path
        session.save(access_key)

        return JsonResponse(
            {
                "message": "Book of documents generated successfully.",
                "url": reverse(
                    "case_prep:download_book_of_documents", args=[session_id]
                ),
            }
        )
    else:
        return JsonResponse({"error": "Invalid request method."}, status=400)


def download_book_of_documents(request, session_id):
    access_key = AccessKey(request.user)

    logger.info(f"Downloading book of documents for session {session_id}.")

    session = Session.objects.get(access_key, pk=session_id)

    # Retrieve the File object from the session
    file_obj = session.book_of_documents

    # Return the FileResponse
    response = FileResponse(file_obj.open(), as_attachment=True)
    response["Content-Disposition"] = f"attachment; filename={file_obj.name}"
    return response


def download_document(request, document_id):

    logger.info(f"Downloading document {document_id}.")

    access_key = AccessKey(request.user)
    document = Document.objects.get(access_key, pk=document_id)

    # Return the FileResponse
    response = FileResponse(document.file.open(), as_attachment=True)
    response["Content-Disposition"] = f"attachment; filename={document.original_name}"
    return response


def toggle_document_visibility(request):
    access_key = AccessKey(request.user)

    if request.method == "POST":
        data = json.loads(request.body)
        document_id = data["document_id"]
        document = Document.objects.get(access_key, pk=document_id)
        document.hidden = not document.hidden
        document.save(access_key)

        return JsonResponse({"message": "Document visibility toggled successfully."})

    return JsonResponse({"error": "Invalid request method."}, status=400)


def create_table_of_contents(request):
    access_key = AccessKey(request.user)

    logger.info("Creating table of contents.")

    session_id = json.loads(request.body)["session_id"]

    # Retrieve the session object
    session = Session.objects.get(access_key, pk=session_id)

    # Load the existing table_of_contents.docx file from the templates directory
    template_path = os.path.join(
        settings.BASE_DIR,
        f"case_prep/templates/case_prep/table_of_contents.docx",
    )
    doc_template = DocxTemplate(template_path)

    # Get all documents associated with the session and order them by sequence
    documents = session.document_set.filter(access_key, hidden=False).order_by(
        "sequence"
    )

    # Loop through the documents and extract the relevant information
    docs = []
    for document in documents:
        docs.append(
            {
                "sequence": document.sequence,
                "name": document.name,
                "date": document.date.strftime("%Y-%m-%d") if document.date else "",
            }
        )

        # Increment the sequence number for each document
        document.sequence += 1
        document.save(access_key)

    # Render the template with the context
    doc_template.render(context={"documents": docs})

    # Create a BytesIO object to act as a temporary file-like object
    output_buffer = io.BytesIO()
    doc_template.save(output_buffer)

    # Write the contents to a file and save to the file system
    doc = ContentFile(output_buffer.getvalue())
    doc.name = "table_of_contents.docx"

    # Create a new Document object with sequence 0 and link it to the Session
    new_document = Document.objects.create(
        access_key,
        session=session,
        original_name=doc.name,
        name="Table of Contents",
        file=doc,
        content_type="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        date=timezone.now(),  # Set the date to the current time
    )

    # Ensure the file is saved before returning the response
    new_document.sequence = 1
    new_document.save(access_key)

    return JsonResponse({"message": "Table of contents created successfully."})


def upvote_feature(request, feature_handle):

    from otto.models import Feedback

    logger.info(f"Upvoting feature: {feature_handle}")

    if request.method == "POST":

        if feature_handle == "qa_research":
            feedback_message = "I am interested in the upcoming Q&A research feature for the Case Prep Assistant. Please upvote it and notify me when it becomes available."
        elif feature_handle == "translate":
            feedback_message = "I would like to see a translation feature in the Case Prep Assistant. Please upvote it and notify me when it becomes available."
        elif feature_handle == "summarization":
            feedback_message = "I am interested in the document summarization feature for the Case Prep Assistant. Please upvote it and notify me when it becomes available."
        else:
            logger.error(f"Invalid feature handle: {feature_handle}")
            raise ValueError("Invalid feature handle")

        feedback = Feedback(
            feedback_type="feedback",
            app=app_name,
            feedback_message=feedback_message,
            modified_by=request.user,
        )
        feedback.save()

        return JsonResponse({"message": _("Feedback submitted successfully")})
    return JsonResponse({"message": _("Invalid request")}, status=400)



=== Contents of django\case_prep\migrations\__init__.py ===



=== Contents of django\case_prep\migrations\0001_initial.py ===
# Generated by Django 5.0.7 on 2024-07-25 20:33

from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = []

    operations = [
        migrations.CreateModel(
            name="Document",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("sequence", models.IntegerField()),
                ("original_name", models.TextField(blank=True)),
                ("name", models.CharField(max_length=255)),
                ("date", models.DateField(blank=True, null=True)),
                ("file", models.FileField(upload_to="case_prep/%Y/%m/%d/")),
                ("content_type", models.CharField(blank=True, max_length=255)),
                ("hidden", models.BooleanField(default=False)),
                ("created_at", models.DateTimeField(auto_now_add=True)),
            ],
            options={
                "abstract": False,
            },
        ),
        migrations.CreateModel(
            name="Session",
            fields=[
                (
                    "id",
                    models.UUIDField(editable=False, primary_key=True, serialize=False),
                ),
                ("name", models.CharField(max_length=255)),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                (
                    "book_of_documents",
                    models.FileField(
                        blank=True, null=True, upload_to="case_prep/books/"
                    ),
                ),
            ],
            options={
                "abstract": False,
            },
        ),
    ]



=== Contents of django\case_prep\migrations\0002_initial.py ===
# Generated by Django 5.0.7 on 2024-07-25 20:33

import django.db.models.deletion
from django.conf import settings
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        ("case_prep", "0001_initial"),
        ("otto", "0001_initial"),
        migrations.swappable_dependency(settings.AUTH_USER_MODEL),
    ]

    operations = [
        migrations.AddField(
            model_name="session",
            name="access_controls",
            field=models.ManyToManyField(to="otto.accesscontrol"),
        ),
        migrations.AddField(
            model_name="session",
            name="created_by",
            field=models.ForeignKey(
                on_delete=django.db.models.deletion.CASCADE, to=settings.AUTH_USER_MODEL
            ),
        ),
        migrations.AddField(
            model_name="document",
            name="session",
            field=models.ForeignKey(
                on_delete=django.db.models.deletion.CASCADE, to="case_prep.session"
            ),
        ),
    ]



=== Contents of django\chat\__init__.py ===



=== Contents of django\chat\admin.py ===
from django.contrib import admin

# Register your models here.



=== Contents of django\chat\apps.py ===
from django.apps import AppConfig


class ChatConfig(AppConfig):
    default_auto_field = "django.db.models.BigAutoField"
    name = "chat"



=== Contents of django\chat\forms.py ===
from django import forms
from django.forms import ModelForm
from django.urls import reverse_lazy as url
from django.utils.translation import gettext_lazy as _

from chat.models import Chat, ChatOptions
from librarian.models import DataSource, Library

CHAT_MODELS = [
    ("gpt-4o", _("GPT-4o (Global)")),
    ("gpt-4", _("GPT-4 (Canada)")),
    ("gpt-35", _("GPT-3.5 (Canada)")),
]
SUMMARIZE_STYLES = [
    ("short", _("Short")),
    ("medium", _("Medium")),
    ("long", _("Long")),
]
TEMPERATURES = [
    (0.1, _("Precise")),
    (0.7, _("Balanced")),
    (1.2, _("Creative")),
]
LANGUAGES = [("en", _("English")), ("fr", _("French"))]


class GroupedLibraryChoiceField(forms.ModelChoiceField):
    def __init__(self, *args, **kwargs):
        self.user = kwargs.pop("user", None)
        if not self.user:
            raise ValueError("User must be provided to GroupedLibraryChoiceField")
        super().__init__(queryset=Library.objects.all(), *args, **kwargs)
        print(f"GroupedLibraryChoiceField initialized with user: {self.user}")
        print(f"Initial queryset count: {self.queryset.count()}")

    def get_grouped_choices(self):
        print(f"get_grouped_choices called for user: {self.user}")
        if not self.user:
            raise ValueError("User must be provided to GroupedLibraryChoiceField")

        public_libraries = list(self.queryset.filter(is_public=True))
        managed_libraries = [
            library
            for library in list(self.queryset.filter(is_public=False))
            if self.user.has_perm("librarian.edit_library", library)
        ]
        shared_libraries = [
            library
            for library in list(self.queryset.filter(is_public=False))
            if self.user.has_perm("librarian.view_library", library)
            and not self.user.has_perm("librarian.edit_library", library)
        ]

        groups = [
            (_("JUS-managed"), public_libraries),
            (_("Managed by me"), managed_libraries),
            (_("Shared with me"), shared_libraries),
        ]

        choices = [
            (group, [(lib.pk, str(lib)) for lib in libs])
            for group, libs in groups
            if libs
        ]

        print(
            f"Returning {len(choices)} groups with a total of {sum(len(options) for _, options in choices)} options"
        )
        print(f"Choices: {choices}")
        return choices

    def label_from_instance(self, obj):
        return str(obj)

    @property
    def choices(self):
        return self.get_grouped_choices()


# AC-20: Allows users to control which sources are queried
class ChatOptionsForm(ModelForm):
    class Meta:
        model = ChatOptions
        fields = "__all__"
        exclude = ["chat", "user", "global_default", "preset_name"]
        widgets = {
            "chat_temperature": forms.Select(
                choices=TEMPERATURES,
                attrs={
                    "class": "form-select form-select-sm",
                    "onchange": "triggerOptionSave();",
                },
            ),
            "summarize_style": forms.Select(
                choices=SUMMARIZE_STYLES,
                attrs={
                    "class": "form-select form-select-sm",
                    "onchange": "triggerOptionSave();",
                },
            ),
            "mode": forms.HiddenInput(attrs={"onchange": "triggerOptionSave();"}),
            "qa_system_prompt": forms.HiddenInput(
                attrs={"onchange": "triggerOptionSave();"}
            ),
            "qa_prompt_template": forms.HiddenInput(
                attrs={"onchange": "triggerOptionSave();"}
            ),
            "qa_pre_instructions": forms.HiddenInput(
                attrs={"onchange": "triggerOptionSave();"}
            ),
            "qa_post_instructions": forms.HiddenInput(
                attrs={"onchange": "triggerOptionSave();"}
            ),
            "qa_topk": forms.HiddenInput(attrs={"onchange": "triggerOptionSave();"}),
            "qa_vector_ratio": forms.HiddenInput(
                attrs={"onchange": "triggerOptionSave();"}
            ),
            "qa_source_order": forms.HiddenInput(
                attrs={"onchange": "triggerOptionSave();"}
            ),
            "qa_answer_mode": forms.HiddenInput(
                attrs={"onchange": "triggerOptionSave();"}
            ),
            "qa_prune": forms.HiddenInput(attrs={"onchange": "triggerOptionSave();"}),
            "qa_rewrite": forms.HiddenInput(attrs={"onchange": "triggerOptionSave();"}),
        }

    def __init__(self, *args, **kwargs):
        self.user = kwargs.pop("user", None)
        super(ChatOptionsForm, self).__init__(*args, **kwargs)
        # Each of chat_model, summarize_model, qa_model
        # should be a choice field with the available models
        for field in [
            "chat_model",
            "summarize_model",
            "qa_model",
        ]:
            self.fields[field].widget = forms.Select(
                choices=CHAT_MODELS,
                attrs={
                    "class": "form-select form-select-sm",
                    "onchange": "triggerOptionSave();",
                },
            )

        # summarize_language and translate_language have choices "en", "fr"
        for field in ["summarize_language", "translate_language"]:
            self.fields[field].widget = forms.Select(
                choices=LANGUAGES,
                attrs={
                    "class": "form-select form-select-sm",
                    "onchange": "triggerOptionSave();",
                },
            )

        # Text areas
        for field in [
            "chat_system_prompt",
            "summarize_prompt",
        ]:
            self.fields[field].widget = forms.Textarea(
                attrs={
                    "class": "form-control form-control-sm",
                    "rows": 5,
                    "onkeyup": "triggerOptionSave();",
                }
            )

        self.fields["qa_library"] = GroupedLibraryChoiceField(
            user=self.user,
            empty_label=None,
            widget=forms.Select(
                attrs={
                    "class": "form-select form-select-sm",
                    "onchange": "triggerOptionSave(); updateLibraryModalButton();",
                    "hx-post": url("chat:get_data_sources"),
                    "hx-swap": "outerHTML",
                    "hx-target": "#qa_data_sources",
                    "hx-trigger": "change",
                }
            ),
        )

        _library_id = (
            self.instance.qa_library_id or Library.objects.get_default_library().id
        )

        # Check if any of the qa_data_sources are checked
        any_data_sources_checked = self.instance.qa_data_sources.filter(
            library_id=_library_id
        ).exists()
        if not any_data_sources_checked:
            self.instance.qa_data_sources.set(
                DataSource.objects.filter(library_id=_library_id)
            )

        self.fields["qa_data_sources"] = forms.ModelMultipleChoiceField(
            queryset=DataSource.objects.filter(library_id=_library_id),
            required=False,
            widget=forms.CheckboxSelectMultiple(
                attrs={
                    "onchange": "triggerOptionSave();",
                    "class": "small",
                    "id": "qa_data_sources",
                },
            ),
        )

        self.fields["qa_data_sources"].required = False

    def save(self, commit=True):
        instance = super(ChatOptionsForm, self).save(commit=False)
        # Remove any data sources that aren't in the library
        library_id = instance.qa_library_id
        if not library_id:
            library_id = Library.objects.get_default_library().id
        # Check if any of the qa_data_sources are checked
        any_data_sources_checked = self.instance.qa_data_sources.filter(
            library_id=library_id
        ).exists()
        if not any_data_sources_checked:
            instance.qa_data_sources.set(
                DataSource.objects.filter(library_id=library_id)
            )
        if commit:
            instance.save()
        return instance


class DataSourcesForm(forms.Form):
    def __init__(self, *args, **kwargs):
        self.library_id = kwargs.pop("library_id")
        prefix = kwargs.pop("prefix")
        super(DataSourcesForm, self).__init__(*args, **kwargs)
        field_name = f"{prefix}_data_sources"
        self.fields[field_name] = forms.ModelMultipleChoiceField(
            queryset=DataSource.objects.filter(library_id=self.library_id).order_by(
                "order", "name"
            ),
            required=False,
            widget=forms.CheckboxSelectMultiple(
                attrs={
                    "onchange": "triggerOptionSave();",
                    "class": "small",
                    "id": field_name,
                    "checked": "checked",  # Check all by default
                },
            ),
        )


class ChatRenameForm(ModelForm):
    class Meta:
        model = Chat
        fields = ["title"]
        widgets = {
            "title": forms.TextInput(
                attrs={
                    "class": "form-control form-control-sm",
                    "onkeyup": "if (event.key === 'Escape') { cancelChatRename(); }",
                    "onblur": "cancelChatRename();",
                    "placeholder": _("Untitled chat"),
                }
            )
        }



=== Contents of django\chat\llm.py ===
from django.conf import settings

import tiktoken
from llama_index.core import PromptTemplate, VectorStoreIndex
from llama_index.core.callbacks import CallbackManager, TokenCountingHandler
from llama_index.core.response_synthesizers import CompactAndRefine, TreeSummarize
from llama_index.core.retrievers import QueryFusionRetriever
from llama_index.core.vector_stores.types import MetadataFilter, MetadataFilters
from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding
from llama_index.llms.azure_openai import AzureOpenAI
from llama_index.vector_stores.postgres import PGVectorStore

from otto.models import Cost


class OttoLLM:
    """
    Wrapper around LlamaIndex to assist with cost tracking and reduce boilerplate.
    "model" must match the name of the LLM deployment in Azure.
    """

    _deployment_to_model_mapping = {
        "gpt-4o": "gpt-4o",
        "gpt-4": "gpt-4-1106-preview",
        "gpt-35": "gpt-35-turbo-0125",
    }
    _deployment_to_max_input_tokens_mapping = {
        "gpt-4o": 128000,
        "gpt-4": 128000,
        "gpt-35": 16385,
    }

    def __init__(
        self, deployment: str = settings.DEFAULT_CHAT_MODEL, temperature: float = 0.1
    ):
        if deployment not in self._deployment_to_model_mapping:
            raise ValueError(f"Invalid deployment: {deployment}")
        self.deployment = deployment
        self.model = self._deployment_to_model_mapping[deployment]
        self.temperature = temperature
        self._token_counter = TokenCountingHandler(
            tokenizer=tiktoken.encoding_for_model(self.model).encode
        )
        self._callback_manager = CallbackManager([self._token_counter])
        self.llm = self._get_llm()
        self.embed_model = self._get_embed_model()
        self.max_input_tokens = self._deployment_to_max_input_tokens_mapping[deployment]

    # Convenience methods to interact with LLM
    # Each will return a complete response (not single tokens)
    async def chat_stream(self, chat_history: list):
        """
        Stream complete response (not single tokens) from list of chat history objects
        """
        response_stream = await self.llm.astream_chat(chat_history)
        async for chunk in response_stream:
            yield chunk.message.content

    async def stream(self, prompt: str):
        """
        Stream complete response (not single tokens) from single prompt string
        """
        response_stream = await self.llm.astream_complete(prompt)
        async for chunk in response_stream:
            yield chunk.text

    def complete(self, prompt: str):
        """
        Return complete response string from single prompt string (no streaming)
        """
        return self.llm.complete(prompt).text

    async def tree_summarize(
        self,
        context: str,
        query: str = "summarize the text",
        template: PromptTemplate = None,
    ):
        """
        Stream complete response (not single tokens) from context string and query.
        Optional: summary template (must include "{context_str}" and "{query_str}".)
        """
        response = await self._get_tree_summarizer(
            summary_template=template
        ).aget_response(query, [context])
        response_text = ""
        async for chunk in response:
            response_text += chunk
            yield response_text

    # Token counting / cost tracking
    @property
    def input_token_count(self):
        return self._token_counter.prompt_llm_token_count

    @property
    def output_token_count(self):
        return self._token_counter.completion_llm_token_count

    @property
    def embed_token_count(self):
        return self._token_counter.total_embedding_token_count

    def create_costs(self) -> None:
        """
        Create Otto Cost objects for the given user and feature.
        """
        if self.input_token_count > 0:
            Cost.objects.new(
                cost_type=f"{self.deployment}-in", count=self.input_token_count
            )
        if self.output_token_count > 0:
            Cost.objects.new(
                cost_type=f"{self.deployment}-out", count=self.output_token_count
            )
        if self.embed_token_count > 0:
            Cost.objects.new(cost_type="embedding", count=self.embed_token_count)

        self._token_counter.reset_counts()

    # RAG-related getters for retriever (get sources only) and response synthesizer
    def get_retriever(
        self,
        vector_store_table: str,
        filters: MetadataFilters = None,
        top_k: int = 5,
        vector_weight: float = 0.6,
    ) -> QueryFusionRetriever:

        pg_idx = self.get_index(vector_store_table)

        vector_retriever = pg_idx.as_retriever(
            vector_store_query_mode="default",
            similarity_top_k=max(top_k, 100),
            filters=filters,
            llm=self.llm,
            embed_model=self.embed_model,
        )
        text_retriever = pg_idx.as_retriever(
            vector_store_query_mode="sparse",
            similarity_top_k=max(top_k, 100),
            filters=filters,
            llm=self.llm,
            embed_model=self.embed_model,
        )
        hybrid_retriever = QueryFusionRetriever(
            [vector_retriever, text_retriever],
            similarity_top_k=top_k,
            num_queries=1,  # set this to 1 to disable query generation
            mode="relative_score",
            use_async=False,
            retriever_weights=[vector_weight, 1 - vector_weight],
            llm=self.llm,
        )
        return hybrid_retriever

    def get_index(self, vector_store_table: str) -> VectorStoreIndex:
        vector_store = PGVectorStore.from_params(
            database=settings.DATABASES["vector_db"]["NAME"],
            host=settings.DATABASES["vector_db"]["HOST"],
            password=settings.DATABASES["vector_db"]["PASSWORD"],
            port=5432,
            user=settings.DATABASES["vector_db"]["USER"],
            table_name=vector_store_table,
            embed_dim=1536,  # openai embedding dimension
            hybrid_search=True,
            text_search_config="english",
            perform_setup=True,
        )
        idx = VectorStoreIndex.from_vector_store(
            vector_store=vector_store,
            llm=self.llm,
            embed_model=self.embed_model,
            callback_manager=self._callback_manager,
            show_progress=False,
        )
        return idx

    def get_response_synthesizer(
        self,
        qa_prompt_template="{context}\n{query}",
    ):
        # Due to bug in LlamaIndex, passing service_context alone doesn't count tokens!
        # This is why we pass llm and callback_manager separately.

        return CompactAndRefine(
            streaming=True,
            llm=self.llm,
            callback_manager=self._callback_manager,
            text_qa_template=qa_prompt_template,
        )

    # Private helpers
    def _get_tree_summarizer(
        self, summary_template: PromptTemplate = None
    ) -> TreeSummarize:
        return TreeSummarize(
            llm=self.llm,
            callback_manager=self._callback_manager,
            prompt_helper=None,
            summary_template=summary_template,
            output_cls=None,
            streaming=True,
            use_async=True,
            verbose=True,
        )

    def _get_llm(self) -> AzureOpenAI:
        return AzureOpenAI(
            azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
            api_version=settings.AZURE_OPENAI_VERSION,
            api_key=settings.AZURE_OPENAI_KEY,
            deployment_name=self.deployment,
            model=self.model,
            temperature=self.temperature,
            callback_manager=self._callback_manager,
        )

    def _get_embed_model(self) -> AzureOpenAIEmbedding:
        return AzureOpenAIEmbedding(
            model="text-embedding-3-large",
            deployment_name="text-embedding-3-large",
            dimensions=1536,
            embed_batch_size=16,
            api_key=settings.AZURE_OPENAI_KEY,
            azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
            api_version=settings.AZURE_OPENAI_VERSION,
            callback_manager=self._callback_manager,
        )



=== Contents of django\chat\models.py ===
import uuid

from django.conf import settings
from django.db import models
from django.db.models import Q
from django.utils import timezone
from django.utils.translation import gettext_lazy as _

from structlog import get_logger

from chat.prompts import (
    DEFAULT_CHAT_PROMPT,
    QA_POST_INSTRUCTIONS,
    QA_PRE_INSTRUCTIONS,
    QA_PROMPT_TEMPLATE,
    QA_SYSTEM_PROMPT,
)
from librarian.models import Library, SavedFile
from otto.models import SecurityLabel
from otto.utils.common import display_cad_cost, set_costs

logger = get_logger(__name__)

DEFAULT_MODE = "qa"


class ChatManager(models.Manager):
    def create(self, *args, **kwargs):
        if "mode" in kwargs:
            mode = kwargs.pop("mode")
        else:
            mode = DEFAULT_MODE
        kwargs["options"] = ChatOptions.objects.from_defaults(
            user=kwargs["user"], mode=mode
        )
        kwargs["security_label_id"] = SecurityLabel.default_security_label().id
        return super().create(*args, **kwargs)


class Chat(models.Model):
    """
    A sequence of messages between a user and a bot
    """

    objects = ChatManager()

    id = models.UUIDField(default=uuid.uuid4, primary_key=True, editable=False)
    title = models.CharField(max_length=255, blank=True)
    user = models.ForeignKey(settings.AUTH_USER_MODEL, on_delete=models.CASCADE)
    created_at = models.DateTimeField(auto_now_add=True)
    # Last access time manually updated when chat is opened
    accessed_at = models.DateTimeField(auto_now_add=True)

    # AC-20: Allows for the classification of information
    security_label = models.ForeignKey(
        SecurityLabel,
        on_delete=models.SET_NULL,
        null=True,
    )

    options = models.OneToOneField(
        "ChatOptions", on_delete=models.CASCADE, related_name="chat", null=True
    )

    def __str__(self):
        return f"Chat {self.id}: {self.title}"

    def access(self):
        self.accessed_at = timezone.now()
        self.save()


class ChatOptionsManager(models.Manager):
    def from_defaults(self, mode=None, user=None):
        """
        If a user default exists, copy that into a new ChatOptions object.
        If not, create a new object with some default settings manually.
        Set the mode and chat FK in the new object.
        """
        if user:
            user_default = (
                self.get_queryset().filter(user=user, user_default=True).first()
            )
        if user and user_default:
            new_options = user_default
            new_options.pk = None
            if mode:
                new_options.mode = mode
            new_options.save()
        else:
            # Default Otto settings
            default_library = Library.objects.get_default_library()
            new_options = self.create(
                qa_library=default_library,
                chat_system_prompt=_(DEFAULT_CHAT_PROMPT),
                chat_model=settings.DEFAULT_CHAT_MODEL,
                qa_model=settings.DEFAULT_CHAT_MODEL,
                summarize_model=settings.DEFAULT_CHAT_MODEL,
                qa_prompt_template=_(QA_PROMPT_TEMPLATE),
                qa_pre_instructions=_(QA_PRE_INSTRUCTIONS),
                qa_post_instructions=_(QA_POST_INSTRUCTIONS),
                qa_system_prompt=_(QA_SYSTEM_PROMPT),
            )
            if mode:
                new_options.mode = mode
            new_options.save()
            if default_library:
                new_options.qa_data_sources.set(default_library.data_sources.all())

        return new_options


class ChatOptions(models.Model):
    """
    Options for a chat, e.g. the mode, custom prompts, etc.
    """

    objects = ChatOptionsManager()

    # Default case: ChatOptions object is associated with a particular chat.
    # (Does not show up in the list of option presets for a user.)

    # Second case: user options preset. One user can have many presets.
    user = models.ForeignKey(
        settings.AUTH_USER_MODEL,
        on_delete=models.CASCADE,
        null=True,
        related_name="chat_options",
    )
    preset_name = models.CharField(max_length=255, blank=True)
    # Third case (can overlap with 2nd case): User default options.
    user_default = models.BooleanField(default=False)

    mode = models.CharField(max_length=255, default=DEFAULT_MODE)

    # Chat-specific options
    chat_model = models.CharField(max_length=255, default="gpt-4o")
    chat_temperature = models.FloatField(default=0.1)
    chat_system_prompt = models.TextField(blank=True)

    # Summarize-specific options
    summarize_model = models.CharField(max_length=255, default="gpt-4o")
    summarize_style = models.CharField(max_length=255, default="short")
    summarize_language = models.CharField(max_length=255, default="en")
    summarize_prompt = models.TextField(blank=True)

    # Translate-specific options
    translate_language = models.CharField(max_length=255, default="fr")

    # Library QA-specific options
    qa_model = models.CharField(max_length=255, default="gpt-4o")
    qa_library = models.ForeignKey(
        "librarian.Library",
        on_delete=models.SET_NULL,
        null=True,
        related_name="qa_options",
    )
    qa_data_sources = models.ManyToManyField(
        "librarian.DataSource", related_name="qa_options"
    )
    qa_topk = models.IntegerField(default=5)
    qa_system_prompt = models.TextField(blank=True)
    qa_prompt_template = models.TextField(blank=True)
    qa_pre_instructions = models.TextField(blank=True)
    qa_post_instructions = models.TextField(blank=True)
    qa_source_order = models.CharField(max_length=20, default="score")
    qa_vector_ratio = models.FloatField(default=0.6)
    qa_answer_mode = models.CharField(max_length=20, default="combined")
    qa_prune = models.BooleanField(default=True)
    qa_rewrite = models.BooleanField(default=False)

    @property
    def qa_prompt_combined(self):
        from llama_index.core import ChatPromptTemplate
        from llama_index.core.llms import ChatMessage, MessageRole

        return ChatPromptTemplate(
            message_templates=[
                ChatMessage(
                    content=self.qa_system_prompt,
                    role=MessageRole.SYSTEM,
                ),
                ChatMessage(
                    content=self.qa_prompt_template,
                    role=MessageRole.USER,
                ),
            ]
        ).partial_format(
            pre_instructions=self.qa_pre_instructions,
            post_instructions=self.qa_post_instructions,
        )

    def clean(self):
        if hasattr(self, "chat") and self.user:
            logger.error(
                "ChatOptions cannot be associated with both a chat AND a user.",
            )
            raise ValueError(
                "ChatOptions cannot be associated with both a chat AND a user."
            )

    def make_user_default(self):
        if self.user:
            self.user.chat_options.filter(user_default=True).update(user_default=False)
            self.user_default = True
            self.save()
        else:
            logger.error("User must be set to set user default.")
            raise ValueError("User must be set to set user default")

    def save(self, *args, **kwargs):
        self.clean()
        new = self.pk is None
        if not new:
            orig = ChatOptions.objects.get(pk=self.pk)
            if orig.qa_library != self.qa_library:
                logger.info("Chat library selection changed. Resetting data_sources.")
                self.qa_data_sources.set(self.qa_library.data_sources.all())
        super().save(*args, **kwargs)


class Message(models.Model):
    """
    A single message within a chat, which may be from a user or a bot
    """

    chat = models.ForeignKey("Chat", on_delete=models.CASCADE, related_name="messages")
    text = models.TextField()
    date_created = models.DateTimeField(auto_now_add=True)
    # 0: user didn't click either like or dislike
    # 1: user clicked like
    # -1: user clicked dislike
    feedback = models.IntegerField(default=0)
    feedback_comment = models.TextField(blank=True)
    is_bot = models.BooleanField(default=False)
    bot_name = models.CharField(max_length=255, blank=True)
    usd_cost = models.DecimalField(max_digits=10, decimal_places=4, default=0)
    pinned = models.BooleanField(default=False)
    # Flexible JSON field for mode-specific details such as translation target language
    details = models.JSONField(default=dict)
    mode = models.CharField(max_length=255, default="chat")
    parent = models.OneToOneField(
        "self", on_delete=models.CASCADE, null=True, related_name="child"
    )

    def __str__(self):
        return f"{'(BOT) ' if self.is_bot else ''}msg {self.id}: {self.text}"

    @property
    def num_files(self):
        return self.files.count()

    @property
    def sorted_files(self):
        return self.files.all().order_by("created_at")

    @property
    def sources(self):
        return self.answersource_set.all().order_by("-node_score")

    @property
    def display_cost(self):
        return display_cad_cost(self.usd_cost)

    def calculate_costs(self):
        set_costs(self)

    def get_toggled_feedback(self, feeback_value):
        if feeback_value not in [-1, 1]:
            logger.error("Feedback must be either 1 or -1")
            raise ValueError("Feedback must be either 1 or -1")

        if self.feedback == feeback_value:
            return 0
        return feeback_value

    class Meta:
        constraints = [
            # Only bot messages can have a parent
            models.CheckConstraint(
                check=(Q(parent__isnull=False) & Q(is_bot=True))
                | Q(parent__isnull=True),
                name="check_parent_is_user_message",
            )
        ]


class AnswerSource(models.Model):
    """
    Node from a Document that was used to answer a question. Associated with Message.
    """

    message = models.ForeignKey("Message", on_delete=models.CASCADE)
    document = models.ForeignKey(
        "librarian.Document", on_delete=models.SET_NULL, null=True
    )
    node_text = models.TextField()
    node_score = models.FloatField(default=0.0)
    # Saved citation for cases where the source Document is deleted later
    saved_citation = models.TextField(blank=True)

    def __str__(self):
        document_citation = self.citation
        return f"{document_citation} ({self.node_score:.2f}):\n{self.node_text[:144]}"

    @property
    def html(self):
        from chat.utils import md

        return md.convert(self.node_text)

    @property
    def citation(self):
        return self.document.citation if self.document else self.saved_citation


class ChatFileManager(models.Manager):
    def create(self, *args, **kwargs):
        # If not provided, create the file object
        if not kwargs.get("saved_file"):
            file = SavedFile.objects.create(
                eof=kwargs.pop("eof", False),
                content_type=kwargs.pop("content_type", ""),
            )
            kwargs["saved_file"] = file
        return super().create(*args, **kwargs)


class ChatFile(models.Model):
    """
    A file within a chat. These are displayed in a message.
    Can be a user-uploaded file or a system-returned file (e.g. translation result)
    """

    objects = ChatFileManager()
    message = models.ForeignKey(
        "Message", on_delete=models.CASCADE, related_name="files"
    )
    filename = models.CharField(max_length=255)
    saved_file = models.ForeignKey(
        SavedFile,
        on_delete=models.SET_NULL,
        null=True,
        related_name="chat_files",
    )
    created_at = models.DateTimeField(auto_now_add=True)
    eof = models.BooleanField(default=False)
    # The text extracted from the file
    text = models.TextField(blank=True)

    def __str__(self):
        return f"File {self.id}: {self.filename}"

    def extract_text(self, fast=True):
        # TODO: Extracting text from file may incur Azure Document AI costs.
        # Need to refactor extract_text to create Cost object with correct user and mode.
        # (Presently, this is only used in summarize mode, and user can be inferred...)
        from librarian.utils.process_engine import (
            extract_markdown,
            get_process_engine_from_type,
        )

        if not self.saved_file:
            return

        process_engine = get_process_engine_from_type(self.saved_file.content_type)
        self.text, _ = extract_markdown(
            self.saved_file.file.read(), process_engine, fast=fast
        )
        self.save()



=== Contents of django\chat\prompts.py ===
from django.utils.translation import gettext_lazy as _

DEFAULT_CHAT_PROMPT = _(
    "You are a general-purpose AI chatbot. You follow these rules:\n\n"
    "1. Your name is 'Otto', an AI who works for the Department of Justice Canada.\n\n"
    "2. If the user asks any question regarding Canada's laws and regulations, you must inform them of the [Legislation search app](/laws/), a tool in Otto built to be better suited for finding relevant and accurate laws and regulations in Canada. Make sure to mention the tool at the beginning of your response and in the form of a markdown link."
    "3. You do not have access to the internet or other knowledge bases. "
    "If you are asked about very specific facts, especially one about the "
    "Government of Canada or laws, you always caveat your response, e.g., "
    "'I am a pre-trained AI and do not have access to the internet, "
    "so my answers might not be correct. Based on my training data, I expect that...'\n\n"
    "4. If you are asked a question about Department of Justice or other Government of "
    "Canada / HR policies, you inform users of Otto's 'Q&A' mode which "
    "can provide more accurate information.\n\n"
    "5. You answer in markdown format to provide clear and readable responses.\n\n"
)
QA_SYSTEM_PROMPT = _(
    "You are an expert Q&A system that is trusted around the world.\n"
    "Always answer the query using the provided context information, and not prior knowledge."
)
QA_PROMPT_TEMPLATE = _(
    "CONTEXT INFORMATION:\n"
    "--------------------\n"
    "{context_str}\n"
    "--------------------\n"
    "INSTRUCTIONS:\n"
    "{pre_instructions}\n"
    "--------------------\n"
    "Query: {query_str}\n"
    "{post_instructions}\n"
    "Answer:"
)
QA_PRE_INSTRUCTIONS = _(
    "Given the information from multiple sources and not prior knowledge, answer the query in markdown format with liberal use of **bold**.\n"
    "Output format:\n"
    "\n"
    "I found the following information:\n"
    "\n"
    "* <supporting direct quote> - <source link or filename>\n"
    "...\n"
    "<succinct answer to question>\n"
    "\n"
    "If you can't find the answer in the sources, just say so. Don't try to provide irrelevant references or made up answers."
)
QA_POST_INSTRUCTIONS = ""



=== Contents of django\chat\responses.py ===
import asyncio

from django.core.cache import cache
from django.core.exceptions import ValidationError
from django.core.validators import URLValidator
from django.http import HttpResponse, StreamingHttpResponse
from django.template.loader import render_to_string
from django.utils.translation import gettext_lazy as _

from asgiref.sync import sync_to_async
from llama_index.core.llms import ChatMessage, MessageRole
from llama_index.core.vector_stores.types import MetadataFilter, MetadataFilters
from rules.contrib.views import objectgetter
from structlog import get_logger
from structlog.contextvars import bind_contextvars

from chat.llm import OttoLLM
from chat.models import Message
from chat.tasks import translate_file
from chat.utils import (
    htmx_stream,
    num_tokens_from_string,
    summarize_long_text,
    summarize_long_text_async,
    url_to_text,
)
from librarian.models import Document
from otto.utils.decorators import permission_required

logger = get_logger(__name__)


@permission_required("chat.access_message", objectgetter(Message, "message_id"))
def otto_response(request, message_id=None):
    """
    Stream a response to the user's message. Uses LlamaIndex to manage chat history.
    """
    response_message = Message.objects.get(id=message_id)
    chat = response_message.chat
    assert chat.user_id == request.user.id
    mode = chat.options.mode

    # For costing and logging. Contextvars are accessible anytime during the request
    # including in async functions (i.e. htmx_stream) and Celery tasks.
    bind_contextvars(message_id=message_id, feature=mode)

    if mode == "chat":
        return chat_response(chat, response_message)
    if mode == "summarize":
        return summarize_response(chat, response_message)
    if mode == "translate":
        return translate_response(chat, response_message)
    if mode == "qa":
        return qa_response(chat, response_message)
    else:
        return error_response(chat, response_message)


def chat_response(chat, response_message, eval=False):

    def is_text_to_summarize(message):
        return message.mode == "summarize" and not message.is_bot

    system_prompt = chat.options.chat_system_prompt
    chat_history = [ChatMessage(role=MessageRole.SYSTEM, content=system_prompt)]
    chat_history += [
        ChatMessage(
            role=MessageRole.ASSISTANT if message.is_bot else MessageRole.USER,
            content=(
                message.text
                if not is_text_to_summarize(message)
                else "<text to summarize...>"
            ),
        )
        for message in chat.messages.all().order_by("date_created")
    ]

    model = chat.options.chat_model
    temperature = chat.options.chat_temperature

    llm = OttoLLM(model, temperature)

    tokens = num_tokens_from_string(
        " ".join(message.content for message in chat_history)
    )
    if tokens > llm.max_input_tokens:
        # In this case, just return an error. No LLM costs are incurred.
        return StreamingHttpResponse(
            streaming_content=htmx_stream(
                chat,
                response_message.id,
                llm,
                response_str=_(
                    "**Error:** The chat is too long for this AI model.\n\nYou can try: \n"
                    "1. Starting a new chat\n"
                    "2. Using summarize mode, which can handle longer texts\n"
                    "3. Using a different model\n"
                ),
            ),
            content_type="text/event-stream",
        )

    # TODO: Update eval stuff
    # if eval:
    #     # Just return the full response and an empty list representing source nodes
    #     return llm.invoke(chat_history).content, []

    return StreamingHttpResponse(
        streaming_content=htmx_stream(
            chat,
            response_message.id,
            llm,
            response_replacer=llm.chat_stream(chat_history),
        ),
        content_type="text/event-stream",
    )


@permission_required("chat.access_message", objectgetter(Message, "message_id"))
def stop_response(request, message_id):
    """
    Stop the response to the user's message.
    """
    response_message = Message.objects.get(id=message_id)
    chat = response_message.chat
    assert chat.user_id == request.user.id

    cache.set(f"stop_response_{message_id}", True, timeout=60)

    return HttpResponse(200)


def summarize_response(chat, response_message):
    """
    Summarize the user's input text (or URL) and stream the response.
    If the summarization technique does not support streaming, send final response only.
    """
    user_message = response_message.parent
    files = user_message.sorted_files if user_message is not None else []
    summary_length = chat.options.summarize_style
    custom_summarize_prompt = chat.options.summarize_prompt
    target_language = chat.options.summarize_language
    model = chat.options.summarize_model

    llm = OttoLLM(model)

    # TODO: Extracting text from file may incur Azure Document AI costs.
    # Need to refactor extract_text to create Cost object with correct user and mode.
    async def multi_summary_generator():
        full_text = ""
        for i, file in enumerate(files):
            full_text += f"**{file.filename}**\n\n"
            yield full_text
            if not file.text:
                await sync_to_async(file.extract_text)(fast=True)
            response_stream = await summarize_long_text_async(
                file.text,
                llm,
                summary_length,
                target_language,
                custom_summarize_prompt,
            )
            async for summary in response_stream:
                full_text_with_summary = full_text + summary
                yield full_text_with_summary

            full_text = full_text_with_summary
            if i < len(files) - 1:
                full_text += "\n\n-----\n"
            yield full_text
            await asyncio.sleep(0)

    if len(files) > 0:
        return StreamingHttpResponse(
            streaming_content=htmx_stream(
                chat,
                response_message.id,
                llm,
                response_replacer=multi_summary_generator(),
                dots=True,
            ),
            content_type="text/event-stream",
        )
    elif user_message.text == "":
        summary = _("No text to summarize.")
    else:
        url_validator = URLValidator()
        try:
            url_validator(user_message.text)
            text_to_summarize = url_to_text(user_message.text)
        except ValidationError:
            text_to_summarize = user_message.text

        # Check if response text is too short (most likely a website blocking Otto)
        if len(text_to_summarize.split()) < 35:
            summary = _(
                "Couldn't retrieve the webpage. The site might block bots. Try copy & pasting the webpage here."
            )
        else:
            response = summarize_long_text(
                text_to_summarize,
                llm,
                summary_length,
                target_language,
                custom_summarize_prompt,
            )
            return StreamingHttpResponse(
                streaming_content=htmx_stream(
                    chat,
                    response_message.id,
                    llm,
                    response_replacer=response,
                ),
                content_type="text/event-stream",
            )

    # This will only be reached in an error case
    return StreamingHttpResponse(
        streaming_content=htmx_stream(
            chat, response_message.id, llm, response_str=summary
        ),
        content_type="text/event-stream",
    )


def translate_response(chat, response_message):
    """
    Translate the user's input text and stream the response.
    If the translation technique does not support streaming, send final response only.
    """
    llm = OttoLLM()
    user_message = response_message.parent
    files = user_message.sorted_files if user_message is not None else []
    language = chat.options.translate_language

    def file_msg(response_message, total_files):
        return render_to_string(
            "chat/components/message_files.html",
            context={"message": response_message, "total_files": total_files},
        )

    async def file_translation_generator(task_ids):
        yield "<p>" + _("Initiating translation...") + "</p>"
        while task_ids:
            # To prevent constantly checking the task status, we sleep for a bit
            # File translation is very slow so every few seconds is plenty.
            await asyncio.sleep(2)
            for task_id in task_ids.copy():
                task = translate_file.AsyncResult(task_id)
                # If the task is not running, remove it from the list
                if task.state != "PENDING":
                    task_ids.remove(task_id)
                    # Refresh the response message from the database
                    await sync_to_async(response_message.refresh_from_db)()
            if len(task_ids) == len(files):
                yield "<p>" + _("Translating file") + f" 1/{len(files)}...</p>"
            else:
                yield await sync_to_async(file_msg)(response_message, len(files))

    if len(files) > 0:
        # Initiate the Celery task for translating each file with Azure
        task_ids = []
        for file in files:
            # file is a django ChatFile object with property "file" that is a FileField
            # We need the path of the file to pass to the Celery task
            file_path = file.saved_file.file.path
            task = translate_file.delay(file_path, language)
            task_ids.append(task.id)
        return StreamingHttpResponse(
            # No cost because file translation costs are calculated in Celery task
            streaming_content=htmx_stream(
                chat,
                response_message.id,
                llm,
                response_replacer=file_translation_generator(task_ids),
                dots=True,
                format=False,  # Because the generator already returns HTML
            ),
            content_type="text/event-stream",
        )
    # Simplest method: Just use LLM to translate input text.
    # Note that long plain-translations frequently fail due to output token limits (~4k)
    # It is not easy to check for this in advance, so we just try and see what happens
    # TODO: Evaluate vs. Azure translator (cost and quality)
    target_language = {"en": "English", "fr": "French"}[language]
    translate_prompt = (
        "Translate the following text to English (Canada):\n"
        "Bonjour, comment a va?"
        "\n---\nTranslation: Hello, how are you?\n"
        "Translate the following text to French (Canada):\n"
        "What size is the file?\nPlease answer in bytes."
        "\n---\nTranslation: Quelle est la taille du fichier?\nVeuillez rpondre en octets.\n"
        f"Translate the following text to {target_language} (Canada):\n"
        f"{user_message.text}"
        "\n---\nTranslation: "
    )

    return StreamingHttpResponse(
        streaming_content=htmx_stream(
            chat,
            response_message.id,
            llm,
            response_replacer=llm.stream(translate_prompt),
        ),
        content_type="text/event-stream",
    )


# AC-20: Only read and retrieve information from external sources (libraries and data sources) without modifying them
def qa_response(chat, response_message, eval=False):
    """
    Answer the user's question using a specific vector store table.
    """
    model = chat.options.qa_model
    llm = OttoLLM(model, 0.1)

    # Apply filters if we are in qa mode and specific data sources are selected
    data_sources = chat.options.qa_data_sources.all()
    max_data_sources = chat.options.qa_library.data_sources.count()
    print(f"Data sources: {data_sources}, max: {max_data_sources}")
    if not Document.objects.filter(data_source__in=data_sources).exists():
        response_str = _(
            "Sorry, I couldn't find any information about that. Try selecting a different library or data source."
        )
        if eval:
            return response_str, []
        return StreamingHttpResponse(
            streaming_content=htmx_stream(
                chat,
                response_message.id,
                llm,
                response_str=response_str,
            ),
            content_type="text/event-stream",
        )

    vector_store_table = chat.options.qa_library.uuid_hex
    top_k = chat.options.qa_topk

    # Don't include the top-level nodes (documents); they don't contain text
    filters = MetadataFilters(
        filters=[
            MetadataFilter(
                key="node_type",
                value="document",
                operator="!=",
            ),
        ]
    )
    if len(data_sources) and len(data_sources) != max_data_sources:
        filters.filters.append(
            MetadataFilter(
                key="data_source_uuid",
                value=[data_source.uuid_hex for data_source in data_sources],
                operator="in",
            )
        )
    retriever = llm.get_retriever(
        vector_store_table,
        filters,
        top_k,
        chat.options.qa_vector_ratio,
    )
    synthesizer = llm.get_response_synthesizer(chat.options.qa_prompt_combined)
    input = response_message.parent.text
    source_nodes = retriever.retrieve(input)

    if len(source_nodes) == 0:
        response_str = _(
            "Sorry, I couldn't find any information about that. Try selecting a different library or data source."
        )
        if eval:
            return response_str, source_nodes
        return StreamingHttpResponse(
            # Although there are no LLM costs, there is still a query embedding cost
            streaming_content=htmx_stream(
                chat, response_message.id, llm, response_str=response_str
            ),
            content_type="text/event-stream",
        )

    response = synthesizer.synthesize(query=input, nodes=source_nodes)

    return StreamingHttpResponse(
        streaming_content=htmx_stream(
            chat,
            response_message.id,
            llm,
            response_generator=response.response_gen,
            source_nodes=response.source_nodes,
        ),
        content_type="text/event-stream",
    )


def error_response(chat, response_message):
    """
    Send an error message to the user.
    """
    llm = OttoLLM()
    return StreamingHttpResponse(
        streaming_content=htmx_stream(
            chat,
            response_message.id,
            llm,
            response_str=_("Sorry, this isn't working right now."),
        ),
        content_type="text/event-stream",
    )



=== Contents of django\chat\tasks.py ===
import os
import uuid
from datetime import datetime
from threading import Thread

from django.conf import settings

from azure.ai.translation.document import DocumentTranslationClient
from azure.core.credentials import AzureKeyCredential
from celery import shared_task
from celery.exceptions import SoftTimeLimitExceeded
from structlog import get_logger
from structlog.contextvars import get_contextvars

from otto.models import Cost, User

logger = get_logger(__name__)
ten_minutes = 600


def azure_delete(path):
    azure_storage = settings.AZURE_STORAGE
    try:
        logger.info(f"Deleting {path} from azure storage.")
        azure_storage.delete(path)
        # Now delete the parent folder
        azure_storage.delete(path.rsplit("/", 1)[0])
    except:
        logger.error(f"Error deleting {path}")
        pass


@shared_task(soft_time_limit=ten_minutes)
def translate_file(file_path, target_language):
    try:
        from chat.models import ChatFile, Message

        # Azure translation client
        translation_client = DocumentTranslationClient(
            endpoint=settings.AZURE_COGNITIVE_SERVICE_ENDPOINT,
            credential=AzureKeyCredential(settings.AZURE_COGNITIVE_SERVICE_KEY),
        )
        logger.info(f"Processing translation for {file_path} at {datetime.now()}")
        file_name = file_path.split("/")[-1]
        input_file_name = file_name.replace(" ", "_")
        # Get extension from filename
        file_extension = os.path.splitext(input_file_name)[1]
        file_name_without_extension = os.path.splitext(input_file_name)[0]
        output_file_name = (
            f"{file_name_without_extension}_{target_language.upper()}{file_extension}"
        )
        file_uuid = uuid.uuid4()
        input_file_path = f"temp/translation/in/{file_uuid}/{input_file_name}"
        output_file_path = f"temp/translation/out/{file_uuid}/{output_file_name}"

        # We need to upload to Azure Blob Storage for Translation API to work
        azure_storage = settings.AZURE_STORAGE
        azure_storage.save(input_file_path, open(file_path, "rb"))

        # Set up translation parameters
        source_url = f"https://{settings.AZURE_ACCOUNT_NAME}.blob.core.windows.net/{settings.AZURE_CONTAINER}/{input_file_path}"
        target_url = f"https://{settings.AZURE_ACCOUNT_NAME}.blob.core.windows.net/{settings.AZURE_CONTAINER}/{output_file_path}"

        # Submit the translation job
        poller = translation_client.begin_translation(
            source_url, target_url, target_language, storage_type="File"
        )
        # Wait for translation to finish
        result = poller.result()

        usage = poller.details.total_characters_charged
        Cost.objects.new(cost_type="translate-file", count=usage)

        request_context = get_contextvars()
        out_message = Message.objects.get(id=request_context.get("message_id"))
        for document in result:
            if document.status == "Succeeded":
                # Save the translated file to the database
                new_file = ChatFile.objects.create(
                    message=out_message,
                    filename=output_file_name,
                    content_type="?",
                )

                new_file.saved_file.file.save(
                    output_file_name, azure_storage.open(output_file_path)
                )
            else:
                logger.error("Translation failed: ", error=document.error.message)
                raise Exception(f"Translation failed:\n{document.error.message}")

        Thread(target=azure_delete, args=(input_file_path,)).start()
        Thread(target=azure_delete, args=(output_file_path,)).start()

        logger.info(f"Translation processed for {file_path} at {datetime.now()}")
    except SoftTimeLimitExceeded:
        logger.error(f"Translation task timed out for {file_path}")
        raise Exception(f"Translation task timed out for {file_path}")



=== Contents of django\chat\urls.py ===
from django.conf import settings
from django.conf.urls.static import static
from django.urls import path

from . import responses, views

app_name = "chat"


urlpatterns = [
    path("", views.new_chat, name="new_chat"),
    path("chat-with-ai/", views.new_chat_with_ai, name="chat_with_ai"),
    path("summarize/", views.new_summarize, name="summarize"),
    path("translate/", views.new_translate, name="translate"),
    path("qa/", views.new_qa, name="qa"),
    path("document-qa/", views.new_document_qa, name="document_qa"),
    path("api/qa/", views.api_qa, name="api_qa"),
    path("id/<str:chat_id>/", views.chat, name="chat"),
    path("id/<str:chat_id>/upload/", views.init_upload, name="init_upload"),
    path(
        "id/<str:chat_id>/delete/<str:current_chat>",
        views.delete_chat,
        name="delete_chat",
    ),
    path("delete_all_chats/", views.delete_all_chats, name="delete_all_chats"),
    path("id/<str:chat_id>/message/", views.chat_message, name="chat_message"),
    path(
        "message/<int:message_id>/response/",
        responses.otto_response,
        name="chat_response",
    ),
    path(
        "message/<int:message_id>/response/stop/",
        responses.stop_response,
        name="stop_response",
    ),
    path(
        "message/<int:message_id>/sources/",
        views.message_sources,
        name="message_sources",
    ),
    path("message/<int:message_id>/upload/", views.chunk_upload, name="chunk_upload"),
    path("message/<int:message_id>/upload/done", views.done_upload, name="done_upload"),
    path("file/<int:file_id>/", views.download_file, name="download_file"),
    path(
        "thumbs-feedback/<int:message_id>/<str:feedback>",
        views.thumbs_feedback,
        name="thumbs_feedback",
    ),
    path("get_data_sources/", views.get_data_sources, name="get_data_sources"),
    path("id/<str:chat_id>/options/", views.chat_options, name="chat_options"),
    path(
        "id/<str:chat_id>/options/preset/<str:action>",
        views.chat_options,
        name="chat_options",
    ),
    path(
        "id/<str:chat_id>/set_security_label/<str:security_label_id>",
        views.set_security_label,
        name="set_security_label",
    ),
    path(
        "id/<str:chat_id>/rename/<str:current_chat>",
        views.rename_chat,
        name="rename_chat",
    ),
    path(
        "id/<str:chat_id>/list_item/<str:current_chat>",
        views.chat_list_item,
        name="chat_list_item",
    ),
    path(
        "id/<str:chat_id>/options/qa_accordion/<int:library_id>",
        views.get_qa_accordion,
        name="qa_accordion",
    ),
] + static(settings.STATIC_URL, document_root=settings.STATIC_ROOT)



=== Contents of django\chat\utils.py ===
import asyncio
import sys
from typing import AsyncGenerator, Generator

from django.core.cache import cache
from django.template.loader import render_to_string
from django.utils.translation import gettext_lazy as _

import bleach
import markdown
import tiktoken
from asgiref.sync import sync_to_async
from llama_index.core import PromptTemplate
from llama_index.core.prompts import PromptType
from newspaper import Article

from chat.llm import OttoLLM
from chat.models import AnswerSource, Chat, Message
from otto.models import SecurityLabel

# Markdown instance
md = markdown.Markdown(
    extensions=["fenced_code", "nl2br", "tables", "extra"], tab_length=2
)


def num_tokens_from_string(string: str, model: str = "gpt-4") -> int:
    """Returns the number of tokens in a text string."""
    encoding = tiktoken.encoding_for_model(model)
    num_tokens = len(encoding.encode(string))
    return num_tokens


def llm_response_to_html(llm_response_str):
    s = str(llm_response_str)
    # When message has uneven # of '```' then add a closing '```' on a newline
    if s.count("```") % 2 == 1:
        s += "\n```"
    raw_html = md.convert(s)
    # return raw_html
    allowed_tags = [
        "h1",
        "h2",
        "h3",
        "h4",
        "h5",
        "h6",
        "b",
        "i",
        "strong",
        "em",
        "tt",
        "p",
        "br",
        "span",
        "div",
        "blockquote",
        "code",
        "pre",
        "hr",
        "ul",
        "ol",
        "li",
        "dd",
        "dt",
        "img",
        "a",
        "sub",
        "sup",
        "table",
        "thead",
        "th",
        "tbody",
        "tr",
        "td",
        "tfoot",
        "dl",
    ]
    allowed_attributes = {
        "*": ["id"],
        "img": ["src", "alt", "title"],
        "a": ["href", "alt", "title"],
        "pre": ["class"],
        "code": ["class"],
        "span": ["class"],
    }
    clean_html = bleach.clean(raw_html, allowed_tags, allowed_attributes)
    return clean_html


def url_to_text(url):
    article = Article(url)
    article.config.MAX_TEXT = sys.maxsize
    try:
        article.download()
        article.parse()
        return article.text
    except:
        return ""


async def stream_to_replacer(response_stream, attribute=None):
    response = ""
    try:
        async for chunk in response_stream:
            response += getattr(chunk, attribute) if attribute else chunk
            yield response
    except:
        for chunk in response_stream:
            response += getattr(chunk, attribute) if attribute else chunk
            yield response
            await asyncio.sleep(0)  # This will allow other async tasks to run


def save_sources_and_update_security_label(source_nodes, message, chat):
    from librarian.models import Document

    sources = []
    for node in source_nodes:
        try:
            if node.node.text == "":
                continue
            document = Document.objects.get(uuid_hex=node.node.ref_doc_id)
            score = node.score
            source = AnswerSource(
                message=message,
                document_id=document.id,
                node_text=node.node.text,
                node_score=score,
                saved_citation=document.citation,
            )
            sources.append(source)
        except Exception as e:
            print("Error saving source:", node, e)

    AnswerSource.objects.bulk_create(sources)

    security_labels = [
        source.document.data_source.security_label.acronym for source in sources
    ] + [chat.security_label.acronym]

    message.chat.security_label = SecurityLabel.maximum_of(security_labels)
    message.chat.save()


async def htmx_stream(
    chat: Chat,
    message_id: int,
    llm: OttoLLM,
    response_generator: Generator = None,
    response_replacer: AsyncGenerator = None,
    response_str: str = "",
    format: bool = True,
    dots: bool = False,
    source_nodes: list = [],
) -> AsyncGenerator:
    """
    Formats responses into HTTP Server-Sent Events (SSE) for HTMX streaming.
    This function is a generator that yields SSE strings (lines starting with "data: ").

    There are 3 ways to use this function:
    1. response_generator: A custom generator that yields response chunks.
       Each chunk will be *appended* to the previous chunk.
    2. response_replacer: A custom generator that yields complete response strings.
       Unlike response_generator, each response will *replace* the previous response.
    3. response_str: A static response string.

    If dots is True, typing dots will be added to the end of the response.

    The function typically expects markdown responses from LLM, but can also handle
    HTML responses from other sources. Set format=False to disable markdown parsing.

    By default, the response will be saved as a Message object in the database after
    the response is finished. Set save_message=False to disable this behavior.
    """

    # Helper function to format a string as an SSE message
    def sse_string(message: str, format=True, dots=False, remove_stop=False) -> str:
        sse_joiner = "\ndata: "
        if format:
            message = llm_response_to_html(message)
        if dots:
            message += dots
        out_string = "data: "
        out_string += sse_joiner.join(message.split("\n"))
        if remove_stop:
            out_string += "<div hx-swap-oob='true' id='stop-button'></div>"
        out_string += "\n\n"  # End of SSE message
        return out_string

    ##############################
    # Start of the main function #
    ##############################
    is_untitled_chat = chat.title.strip() == ""
    full_message = ""
    if dots:
        dots = f'<div class="typing"><span></span><span></span><span></span></div>'

    try:
        if response_generator:
            response_replacer = stream_to_replacer(response_generator)
        if response_str:
            response_replacer = stream_to_replacer([response_str])

        # Stream the response text
        async for response in response_replacer:
            full_message = response
            if cache.get(f"stop_response_{message_id}", False):
                break
            yield sse_string(full_message, format, dots)
            await asyncio.sleep(0.01)

        yield sse_string(full_message, format, dots=False, remove_stop=True)

        await sync_to_async(llm.create_costs)()

        message = await sync_to_async(Message.objects.get)(id=message_id)
        message.text = full_message
        await sync_to_async(message.save)()

        if is_untitled_chat:
            title_llm = OttoLLM("gpt-35")
            await sync_to_async(title_chat)(chat.id, force_title=False, llm=title_llm)
            await sync_to_async(title_llm.create_costs)()

        # Update message text with HTML formatting to pass to template
        message.text = llm_response_to_html(full_message)
        context = {"message": message, "swap_oob": True}

        # Save sources and security label
        if source_nodes:
            await sync_to_async(save_sources_and_update_security_label)(
                source_nodes, message, chat
            )
            context["security_labels"] = await sync_to_async(
                SecurityLabel.objects.all
            )()

    except Exception as e:
        full_message = _("An error occurred:") + f"\n```\n{str(e)}\n```"
        message.text = full_message
        await sync_to_async(message.save)()
        message.text = llm_response_to_html(full_message)
        context = {"message": message, "swap_oob": True}

    # Render the message template, wrapped in SSE format
    yield sse_string(
        await sync_to_async(render_to_string)(
            "chat/components/chat_message.html", context
        ),
        format=False,
        remove_stop=True,
    )


def title_chat(chat_id, llm, force_title=True):
    # Assume costs will be calculated in the calling function where LLM instantiated
    chat = Chat.objects.get(id=chat_id)
    chat_messages = chat.messages.order_by("date_created")
    if not force_title and (
        chat.title != ""
        or (
            len(chat_messages) < 3
            and len(" ".join([m.text for m in chat_messages])) < 300
        )
    ):
        return chat.title

    chat_messages_text = []
    for message in chat_messages[:7]:
        if message.text:
            chat_messages_text.append(message.text)
        elif message.files.exists():
            chat_messages_text.append(message.mode + " " + _("with files:"))
            for file in message.files.all():
                chat_messages_text.append(file.filename)
    chat_text = "\n".join([message[:500] for message in chat_messages_text])
    if len(chat_text) < 3:
        return _("Untitled chat")
    chat_text = chat_text[:2000]
    prompt = (
        "Write a concise title (1-4 words) to the following chat. "
        "Some examples are: 'DG meeting notes', 'Pancake recipe', 'Feedback session'.\n"
        "You must respond with at least one word:\n---\n"
        f"{chat_text}\n---\n"
        "TITLE: "
    )
    try:
        generated_title = llm.complete(prompt)[:254]
        if generated_title.startswith('"') and generated_title.endswith('"'):
            generated_title = generated_title[1:-1]
    except Exception as e:
        generated_title = _("Untitled chat")
    chat.title = generated_title
    chat.save()
    return generated_title


def summarize_long_text(
    text,
    llm,
    length="short",
    target_language="en",
    custom_prompt=None,
):

    if len(text) == 0:
        return _("No text provided.")

    length_prompts = {
        "short": {
            "en": "{docs}\n\nTL;DR (in English, in three or four sentences):\n",
            "fr": "{docs}\n\nTL;DR (en franais, en trois ou quatre phrases):\n",
        },
        "medium": {
            "en": "Rewrite the text (in English) in a medium sized summary format and make sure the length is around two or three paragraphs.\n\n Document: {docs}",
            "fr": "Rcrivez le texte (en franais) dans un format de rsum de taille moyenne et assurez-vous que la longueur est de deux ou trois paragraphes.\n\n Document: {docs}",
        },
        "long": {
            "en": (
                "Rewrite the text (in English) as a detailed summary, using multiple paragraphs if necessary. (If the input is short, output 1 paragraph only)\n\n"
                "Some rules to follow:\n"
                '* Simply rewrite; do not say "This document is about..." etc. Include *all* important details.\n'
                "* There is no length limit - be as detailed as possible. However, **do not extrapolate** on the text. The summary must be factual and not introduce any new ideas.\n"
                "* The summary must not be longer than the input text.\n\n"
                "Please rewrite the following document."
                "\n\n Document: {docs}"
            ),
            "fr": (
                "Rcrivez le texte (en anglais) sous forme de rsum dtaill, en utilisant plusieurs paragraphes si ncessaire. (Si la saisie est courte, affichez 1 seul paragraphe)\n\n"
                "Quelques rgles  suivre :\n"
                '* Rcrivez simplement ; ne dites pas "Ce document concerne..." etc. Incluez *tous* les dtails importants.\n'
                "* Il n'y a pas de limite de longueur : soyez aussi dtaill que possible. Cependant, **n'extrapolez pas** sur le texte. Le rsum doit tre factuel et ne pas introduire de nouvelles ides.\n"
                "* Le rsum ne doit pas tre plus long que le texte saisi.\n\n"
                "Veuillez rcrire le document suivant."
                "\n\n Document: {docs}"
            ),
        },
    }

    length_prompt_template = length_prompts[length][target_language]
    if custom_prompt and "{docs}" in custom_prompt:
        length_prompt_template = custom_prompt
    elif custom_prompt:
        length_prompt_template = (
            custom_prompt
            + "\n\n"
            + _("The original document is below, enclosed in triple quotes:")
            + "\n'''\n{docs}\n'''"
        )
    # Tree summarizer prompt requires certain variables
    # Note that we aren't passing in a query here, so the query will be empty
    length_prompt_template = length_prompt_template.replace(
        "{docs}", "{context_str}{query_str}"
    )
    template = PromptTemplate(length_prompt_template, prompt_type=PromptType.SUMMARY)

    response = llm.tree_summarize(
        context=text,
        query="",
        template=template,
    )
    return response


async def summarize_long_text_async(
    text,
    llm,
    length="short",
    target_language="en",
    custom_prompt=None,
):
    return await sync_to_async(summarize_long_text)(
        text, llm, length, target_language, custom_prompt
    )



=== Contents of django\chat\views.py ===
import json

from django.conf import settings
from django.contrib.auth import get_user_model
from django.forms.models import model_to_dict
from django.http import HttpRequest, HttpResponse, JsonResponse
from django.shortcuts import get_object_or_404, redirect, render
from django.urls import reverse
from django.utils import timezone
from django.utils.translation import gettext as _
from django.views.decorators.csrf import csrf_exempt
from django.views.decorators.http import require_GET, require_POST

from rules.contrib.views import objectgetter
from structlog import get_logger
from structlog.contextvars import bind_contextvars

from chat.forms import ChatOptionsForm, ChatRenameForm, DataSourcesForm
from chat.llm import OttoLLM
from chat.metrics.activity_metrics import (
    chat_new_session_started_total,
    chat_request_type_total,
    chat_session_restored_total,
)
from chat.metrics.feedback_metrics import (
    chat_negative_feedback_total,
    chat_positive_feedback_total,
)
from chat.models import Chat, ChatFile, ChatOptions, Message
from chat.utils import llm_response_to_html, title_chat
from librarian.models import DataSource, Library
from otto.models import App, SecurityLabel
from otto.utils.decorators import app_access_required, permission_required
from otto.views import message_feedback

app_name = "chat"
logger = get_logger(__name__)
User = get_user_model()


new_chat_with_ai = lambda request: new_chat(request, mode="chat")
new_translate = lambda request: new_chat(request, mode="translate")
new_summarize = lambda request: new_chat(request, mode="summarize")
new_document_qa = lambda request: new_chat(request, mode="document_qa")
new_qa = lambda request: new_chat(request, mode="qa")


@csrf_exempt
@require_POST
def api_qa(request):

    logger.info("Received API request for Library QA")

    verification_token = request.headers.get("X-VERIFICATION-TOKEN")
    if not verification_token:
        logger.error("Missing verification token")
        return JsonResponse(
            {
                "status": "error",
                "error_code": "MISSING_TOKEN",
                "error_en": "Invalid JSON input",
                "error_fr": "Entre JSON invalide",
            },
            status=400,
        )

    # If the verification token doesn't match settings.OTTO_VERIFICATION_TOKEN, return a 403
    if verification_token != settings.OTTO_VERIFICATION_TOKEN:
        logger.error("Invalid verification token")
        return JsonResponse(
            {
                "status": "error",
                "error_code": "INVALID_TOKEN",
                "error_en": "Invalid verification token",
                "error_fr": "Jeton de vrification invalide",
            },
            status=403,
        )

    # Get the JSON body from the request and parse it into a dictionary
    try:
        request_data = json.loads(request.body)
    except json.JSONDecodeError:
        logger.error("Invalid JSON input", request_body=request.body)
        return JsonResponse(
            {
                "status": "error",
                "error_code": "INVALID_JSON",
                "error_en": "Invalid JSON input",
                "error_fr": "Entre JSON invalide",
            },
            status=400,
        )

    # Get the user and lookup the user in database
    # We expect a upn like "Firstname.Lastname@justice.gc.ca"
    upn = request_data.get("upn", None)
    if not upn:
        logger.error("Missing upn")
        return JsonResponse(
            {
                "status": "error",
                "error_code": "INVALID_USER",
                "error_en": "Missing UPN",
                "error_fr": "Nom d'utilisateur manquant",
            },
            status=400,
        )

    try:
        user = User.objects.get(upn=upn)
    except User.DoesNotExist:
        logger.error("User not found", username=upn)
        return JsonResponse(
            {
                "status": "error",
                "error_code": "USER_NOT_FOUND",
                "error_en": "User not found",
                "error_fr": "Utilisateur non trouv",
            },
            status=401,
        )

    # Check if user has access to the "chat" app
    if not user.has_perm("otto:access_app", App.objects.get(handle=app_name)):
        logger.info(f"User {user.upn} does not have access to the chat app")
        return JsonResponse(
            {
                "status": "error",
                "error_code": "USER_NOT_AUTHORIZED",
                "error_en": "User not authorized to access Otto AI assistant",
                "error_fr": "Utilisateur non autoris  accder  l'assistant IA Otto",
            },
            status=403,
        )

    # Get the library name from the POST request
    library_name = request_data.get("library", "_____")
    try:
        library = Library.objects.get(name=library_name)
    except Library.DoesNotExist:
        logger.error("Library not found", library_name=library_name)
        return JsonResponse(
            {
                "status": "error",
                "error_code": "LIBRARY_NOT_FOUND",
                "error_en": "Library not found",
                "error_fr": "Bibliothque non trouve",
            },
            status=404,
        )

    user_message_text = request_data.get("user_message", "").strip()
    if not user_message_text:
        logger.error("Missing user message")
        return JsonResponse(
            {
                "status": "error",
                "error_en": "Missing user message",
                "error_fr": "Message de l'utilisateur manquant",
            },
            status=400,
        )

    data_sources = request_data.get("data_sources", [])
    if data_sources:
        data_sources_queryset = DataSource.objects.filter(
            name__in=data_sources, library=library
        )
        if data_sources_queryset.count() != len(data_sources):
            logger.error("Data source(s) not found", data_sources=data_sources)
            return JsonResponse(
                {
                    "status": "error",
                    "error_code": "DATASOURCE_INVALID",
                    "error_en": "Data source(s) not found",
                    "error_fr": "Source(s) de donnes non trouve(s)",
                },
                status=404,
            )
        data_sources = data_sources_queryset

    # We should be good now! User exists in Otto and has access to the chat app and parameters are verified
    mode = "qa"

    # Create a new chat
    chat = Chat.objects.create(user=user, mode=mode)

    # Create a chat options object
    chat.options = ChatOptions.objects.from_defaults(user=chat.user)
    chat.options.mode = mode

    # Usage metrics
    chat_new_session_started_total.labels(user=user.upn, mode=mode).inc()

    # Set the library and data sources
    chat.options.qa_library = library
    if data_sources:
        chat.options.qa_data_sources.set(data_sources)

    # Add the user message to the chat
    user_message = Message.objects.create(
        chat=chat, text=user_message_text, is_bot=False, mode=mode
    )

    # Add a bot message to the chat
    Message.objects.create(
        chat=chat, text="", is_bot=True, mode=mode, parent=user_message
    )

    chat.options.save()
    chat.save()

    # Get the current hostname, port and protocol
    host = request.get_host()
    protocol = "https" if request.is_secure() else "http"

    # Return a link to the chat page with the specified mode
    redirect_url = reverse("chat:chat", kwargs={"chat_id": chat.id})
    redirect_url = f"{protocol}://{host}{redirect_url}?awaiting_response=True"
    return JsonResponse(
        {
            "status": "success",
            "redirect_url": redirect_url,
        }
    )


@app_access_required(app_name)
def new_chat(request, mode=None):
    """
    Create a new chat and redirect to it
    """

    empty_chat = Chat.objects.create(user=request.user, mode=mode)

    logger.info("New chat created.", chat_id=empty_chat.id, mode=mode)

    # Usage metrics
    chat_new_session_started_total.labels(user=request.user.upn, mode=mode).inc()

    return redirect("chat:chat", chat_id=empty_chat.id)


@permission_required("chat.access_chat", objectgetter(Chat, "chat_id"))
def delete_chat(request, chat_id, current_chat=None):
    # HTMX delete route
    # Delete chat
    chat = Chat.objects.get(id=chat_id)

    chat.delete()
    logger.info("Chat was deleted.", chat_id=chat_id)

    # Is this the currently open chat? If so, redirect away
    if current_chat == "True":
        response = HttpResponse()
        response["HX-Redirect"] = reverse("chat:new_chat")
        return response
    return HttpResponse(status=200)


@app_access_required("chat")
def delete_all_chats(request):

    # delete all chats for the user
    chat = Chat.objects.filter(user=request.user)
    chat.delete()

    logger.info("all chats deleted")

    # redirect user to new chat
    response = HttpResponse()
    response["HX-Redirect"] = reverse("chat:new_chat")
    return response


@permission_required("chat.access_chat", objectgetter(Chat, "chat_id"))
def chat(request, chat_id):
    """
    Get or create the chat based on the provided chat ID
    """

    logger.info("Chat session retrieved.", chat_id=chat_id)
    bind_contextvars(feature="chat")

    chat = Chat.objects.get(id=chat_id)
    # Get chat options
    if not chat.options:
        # This is just to catch chats which existed before ChatOptions was introduced.
        # The existing chat mode for these chats will be lost.
        chat.options = ChatOptions.objects.from_defaults(user=chat.user)
        chat.save()
    mode = chat.options.mode

    # Get chat messages ready
    messages = Message.objects.filter(chat=chat).order_by("id")
    for message in messages:
        if message.is_bot:
            message.text = llm_response_to_html(message.text)
        else:
            message.text = message.text.strip()

    # Get sidebar chat history list.
    # Don't show empty chats - these will be deleted automatically later.
    # The current chat is always shown, even if it's empty.
    user_chats = (
        Chat.objects.filter(user=request.user, messages__isnull=False)
        .exclude(pk=chat.id)
        .union(Chat.objects.filter(pk=chat.id))
        .order_by("-created_at")
    )
    # Title chats in sidebar if necessary & set default labels
    llm = None
    for user_chat in user_chats:
        user_chat.current_chat = user_chat.id == chat.id
        if user_chat.title.strip() == "":
            if not llm:
                llm = OttoLLM("gpt-35")
            user_chat.title = title_chat(user_chat.id, llm=llm)
            if not user_chat.current_chat:
                user_chat.save()
        if not user_chat.security_label:
            user_chat.security_label_id = SecurityLabel.default_security_label().id
            user_chat.save()
    if llm:
        llm.create_costs()

    # Usage metrics
    awaiting_response = request.GET.get("awaiting_response") == "True"
    if len(messages) > 0 and not awaiting_response:
        chat_session_restored_total.labels(user=request.user.upn, mode=mode)

    # When a chat is created from outside Otto, we want to emulate the behaviour
    # of creating a new message - which returns an "awaiting_response" bot message
    if (
        awaiting_response
        and messages
        and messages.last().is_bot
        and not messages.last().text
    ):
        response_init_message = {
            "is_bot": True,
            "awaiting_response": True,
            "id": messages.last().id,
            "date_created": messages.last().date_created
            + timezone.timedelta(seconds=1),
        }
        messages = [messages.first(), response_init_message]

    # If ChatOptions has an invalid library or data source, remove them
    if not chat.options.qa_library:
        chat.options.qa_library = Library.objects.get_default_library()
        chat.options.save()
    form = ChatOptionsForm(instance=chat.options, user=request.user)
    context = {
        "chat": chat,
        "options_form": form,
        "option_presets": ChatOptions.objects.filter(user=request.user),
        "chat_messages": messages,
        "hide_breadcrumbs": True,
        "user_chats": user_chats,
        "mode": mode,
        "security_labels": SecurityLabel.objects.all(),
    }
    return render(request, "chat/chat.html", context=context)


@require_POST
@permission_required("chat.access_chat", objectgetter(Chat, "chat_id"))
def chat_message(request, chat_id):
    """
    Post a user message to the chat and initiate a streaming response
    """
    # The user must match the chat
    chat = Chat.objects.get(id=chat_id)
    # Create the user's message in database
    user_message_text = request.POST.get("user-message", "").strip()
    mode = chat.options.mode

    logger.debug(
        "User message received.",
        chat_id=chat_id,
        user_message=f"{user_message_text[:100]}{'...' if len(user_message_text) > 100 else ''}",
        mode=mode,
    )

    user_message = Message.objects.create(
        chat=chat, text=user_message_text, is_bot=False, mode=mode
    )
    response_message = Message.objects.create(
        chat=chat, text="", is_bot=True, mode=mode, parent=user_message
    )
    # usage metrics
    chat_request_type_total.labels(user=request.user.upn, type=mode).inc()

    # This tells the frontend to display the 3 dots and initiate the streaming response
    response_init_message = {
        "is_bot": True,
        "awaiting_response": True,
        "id": response_message.id,
        "date_created": response_message.date_created + timezone.timedelta(seconds=1),
    }
    context = {
        "chat_messages": [
            user_message,
            response_init_message,
        ],
        "mode": mode,
    }
    return render(request, "chat/components/chat_messages.html", context=context)


@require_GET
@permission_required("chat.access_chat", objectgetter(Chat, "chat_id"))
def init_upload(request, chat_id):
    """
    Creates a file upload progress message in the chat and initiates the file upload
    """
    chat = Chat.objects.get(id=chat_id)
    mode = chat.options.mode
    # Create the user's message in database
    logger.info("File upload initiated.", chat_id=chat_id, mode=mode)
    message = Message.objects.create(chat=chat, text="", is_bot=False, mode=mode)
    message.save()
    context = {
        "chat_messages": [
            message,
        ],
        "mode": mode,
        "file_upload": True,
    }
    return render(request, "chat/components/chat_messages.html", context=context)


@permission_required("chat.access_message", objectgetter(Message, "message_id"))
def done_upload(request, message_id):
    """
    Creates a "files uploaded" message in the chat and initiates the response
    """
    user_message = Message.objects.get(id=message_id)
    mode = user_message.mode
    logger.info("File upload completed.", message_id=message_id, mode=mode)
    response_message = Message.objects.create(
        chat=user_message.chat, text="", is_bot=True, mode=mode, parent=user_message
    )

    if mode == "translate":
        # usage metrics
        chat_request_type_total.labels(
            user=request.user.upn, type="document translation"
        )
    if mode == "summarize":
        # usage metrics
        chat_request_type_total.labels(user=request.user.upn, type="text summarization")

    response_init_message = {
        "is_bot": True,
        "awaiting_response": True,
        "id": response_message.id,
        "date_created": user_message.date_created + timezone.timedelta(seconds=1),
    }
    context = {
        "chat_messages": [
            user_message,
            response_init_message,
        ],
        "mode": mode,
    }
    return render(request, "chat/components/chat_messages.html", context=context)


@require_POST
@permission_required("chat.access_message", objectgetter(Message, "message_id"))
def chunk_upload(request, message_id):
    """
    Returns JSON for the file upload progress
    Based on https://github.com/shubhamkshatriya25/Django-AJAX-File-Uploader
    """
    file = request.FILES["file"].read()
    content_type = request.POST["content_type"]
    fileName = request.POST["filename"]
    file_id = request.POST["file_id"]
    end = request.POST["end"]
    nextSlice = request.POST["nextSlice"]

    if file == "" or fileName == "" or file_id == "" or end == "" or nextSlice == "":
        return JsonResponse({"data": "Invalid Request"})
    else:
        if file_id == "null":
            file_obj = ChatFile.objects.create(
                message_id=message_id,
                filename=fileName,
                eof=int(end),
                content_type=content_type,
            )
            file_obj.saved_file.file.save(fileName, request.FILES["file"])
            if int(end):
                # TODO: Compare saved file hash with the hash sent by the client
                file_obj.saved_file.generate_hash()
                return JsonResponse(
                    {"data": "Uploaded successfully", "file_id": file_obj.id}
                )
            else:
                return JsonResponse({"file_id": file_obj.id})
        else:
            file_obj = ChatFile.objects.get(id=file_id)
            if not file_obj or file_obj.saved_file.eof:
                return JsonResponse({"data": "Invalid Request"})
            # Append the chunk to the file with write mode ab+
            with open(file_obj.saved_file.file.path, "ab+") as f:
                f.seek(int(nextSlice))
                f.write(file)
            file_obj.saved_file.eof = int(end)
            file_obj.save()
            if int(end):
                return JsonResponse(
                    {
                        "data": "Uploaded successfully",
                        "file_id": file_obj.id,
                    }
                )
            else:
                return JsonResponse({"file_id": file_obj.id})


@permission_required("chat.access_file", objectgetter(ChatFile, "file_id"))
def download_file(request, file_id):
    logger.info("Downloading chat file.", file_id=file_id)
    file_obj = get_object_or_404(ChatFile, pk=file_id)
    file = file_obj.saved_file.file
    # Download the file, don't display it
    response = HttpResponse(file, content_type=file_obj.saved_file.content_type)
    response["Content-Disposition"] = f"attachment; filename={file_obj.filename}"
    return response


@permission_required("chat.access_message", objectgetter(Message, "message_id"))
def thumbs_feedback(request: HttpRequest, message_id: int, feedback: str):
    try:
        feedback = int(feedback)  # cast to integer
        logger.info(
            "Providing chat feedback.",
            message_id=message_id,
            feedback=feedback,
        )
        message = Message.objects.get(id=message_id)
        message.feedback = message.get_toggled_feedback(feedback)
        message.save()
        if feedback:
            chat_positive_feedback_total.labels(
                user=request.user.upn, message=message_id
            ).inc()
        else:
            chat_negative_feedback_total.labels(
                user=request.user.upn, message=message_id
            ).inc()
    except Exception as e:
        # TODO: handle error
        logger.error("An error occured while providing a chat feedback.", error=e)

    if feedback == -1:
        return message_feedback(request, message_id)

    return HttpResponse()


@permission_required("chat.access_chat", objectgetter(Chat, "chat_id"))
def chat_options(request, chat_id, action=None):
    """
    Save and load chat options.
    """

    def _copy_options(source_options, target_options):
        source_options = model_to_dict(source_options)
        # Remove the fields that are not part of the preset
        for field in ["id", "user", "preset_name"]:
            source_options.pop(field)
        # Update the preset options with the dictionary
        fk_fields = ["qa_library"]
        m2m_fields = ["qa_data_sources"]
        # Remove None values
        source_options = {k: v for k, v in source_options.items()}
        for key, value in source_options.items():
            if key in fk_fields:
                setattr(target_options, f"{key}_id", int(value) if value else None)
            elif key in m2m_fields:
                getattr(target_options, key).set(value)
            else:
                setattr(target_options, key, value)
        target_options.save()

    chat = Chat.objects.get(id=chat_id)
    if action in ["reset", "load_preset"]:
        if action == "reset":
            preset_options = ChatOptions.objects.from_defaults(user=request.user)
            logger.info("Resetting chat options to default.", chat_id=chat_id)
        else:
            # Check that the preset is not empty and exists
            preset_name = request.POST.get("option_presets")
            logger.info(
                "Loading chat options from a preset.",
                chat_id=chat_id,
                preset=preset_name,
            )
            if not preset_name:
                return HttpResponse(status=500)
            preset_options = ChatOptions.objects.filter(
                user=request.user, preset_name=preset_name
            ).first()
            if not preset_options:
                return HttpResponse(status=500)
        # Update the chat options with the default options
        chat_options = chat.options
        _copy_options(preset_options, chat_options)
        return render(
            request,
            "chat/components/chat_options_accordion.html",
            {
                "options_form": ChatOptionsForm(
                    instance=chat_options, user=request.user
                ),
                "preset_loaded": "true",
            },
        )
    elif action == "save_preset":
        # Save the current chat options as a preset
        preset_name = request.POST.get("option_presets")
        logger.info(
            "Saving chat options as a preset.", chat_id=chat_id, preset=preset_name
        )
        # Can't be blank
        if not preset_name:
            return HttpResponse(status=500)
        # Get or create the preset
        preset_options = ChatOptions.objects.filter(
            user=request.user, preset_name=preset_name
        ).first()
        if not preset_options:
            preset_options = ChatOptions.objects.create(
                user=request.user, preset_name=preset_name
            )
        _copy_options(chat.options, preset_options)
        # Replaces the preset dropdown with the saved one selected
        return render(
            request,
            "chat/components/options_preset_dropdown.html",
            {
                "option_presets": ChatOptions.objects.filter(user=chat.user),
                "selected_preset": preset_name,
            },
        )
    elif action == "delete_preset":
        # Delete the preset
        preset_name = request.POST.get("option_presets")
        logger.info(
            "Deleting chat options preset.", chat_id=chat_id, preset=preset_name
        )
        if not preset_name:
            return HttpResponse(status=500)
        ChatOptions.objects.filter(user=request.user, preset_name=preset_name).delete()
        # Replaces the preset dropdown with none selected
        return render(
            request,
            "chat/components/options_preset_dropdown.html",
            {"option_presets": ChatOptions.objects.filter(user=chat.user)},
        )
    elif request.method == "POST":
        chat_options = chat.options
        chat_options_form = ChatOptionsForm(
            request.POST, instance=chat_options, user=request.user
        )
        # Check for errors and print them to console
        if not chat_options_form.is_valid():
            logger.error(chat_options_form.errors)
            return HttpResponse(status=500)
        chat_options_form.save()

        # Replaces the preset dropdown with none selected
        return render(
            request,
            "chat/components/options_preset_dropdown.html",
            {"option_presets": ChatOptions.objects.filter(user=chat.user)},
        )
    return HttpResponse(status=500)


@permission_required("chat.access_chat", objectgetter(Chat, "chat_id"))
def chat_list_item(request, chat_id, current_chat=None):
    chat = get_object_or_404(Chat, id=chat_id)
    chat.current_chat = bool(current_chat == "True")
    return render(
        request,
        "chat/components/chat_list_item.html",
        {"chat": chat},
    )


@permission_required("chat.access_chat", objectgetter(Chat, "chat_id"))
def rename_chat(request, chat_id, current_chat=None):
    chat = get_object_or_404(Chat, id=chat_id)
    chat.current_chat = bool(current_chat == "True")

    if request.method == "POST":
        chat_rename_form = ChatRenameForm(request.POST)
        if chat_rename_form.is_valid():
            chat.title = chat_rename_form.cleaned_data["title"]
            chat.save()
            return render(
                request,
                "chat/components/chat_list_item.html",
                {"chat": chat},
            )
        else:
            return render(
                request,
                "chat/components/chat_list_item_title_edit.html",
                {"form": chat_rename_form, "chat": chat},
            )

    chat_rename_form = ChatRenameForm(data={"title": chat.title})
    return render(
        request,
        "chat/components/chat_list_item_title_edit.html",
        {"form": chat_rename_form, "chat": chat},
    )


def get_data_sources(request, prefix="qa"):
    library_id = request.POST.get("qa_library", None)
    if not library_id:
        return HttpResponse(status=500)
    # Assuming DataSource model has a ForeignKey to Library model
    data_sources_form = DataSourcesForm(library_id=library_id, prefix=prefix)
    return render(
        request,
        "chat/components/data_sources_options.html",
        {"options_form": data_sources_form},
    )


@permission_required("chat.access_chat", objectgetter(Chat, "chat_id"))
def get_qa_accordion(request, chat_id, library_id):
    chat = Chat.objects.get(id=chat_id)
    if chat.options.qa_library_id != library_id:
        if chat.options.qa_library_id:
            chat.options.qa_library_id = library_id
        else:
            # If chat.options.qa_library_id is None, it means that the selected library
            # was deleted, and there is no Library corresponding to library_id
            # Thus, revert back to default (Corporate) library
            chat.options.qa_library_id = Library.objects.get_default_library().id
        chat.options.save()
    return render(
        request,
        "chat/components/options_4_qa.html",
        {
            "options_form": ChatOptionsForm(instance=chat.options, user=request.user),
            "swap": True,
            "options_section_id": "qa",
        },
    )


# AC-16 & AC-16(2): Allows for the modification of security labels associated with chat sessions
@permission_required("chat.access_chat", objectgetter(Chat, "chat_id"))
def set_security_label(request, chat_id, security_label_id):
    logger.info(
        "Setting security label for chat.",
        chat_id=chat_id,
        security_label_id=security_label_id,
    )
    chat = Chat.objects.get(id=chat_id)
    chat.security_label_id = security_label_id
    chat.save()
    return render(
        request,
        "chat/components/chat_security_label.html",
        {"chat": chat, "security_labels": SecurityLabel.objects.all()},
    )


@permission_required("chat.access_message", objectgetter(Message, "message_id"))
def message_sources(request, message_id):
    message = Message.objects.get(id=message_id)
    return render(
        request,
        "chat/modals/sources_modal_inner.html",
        {"message": message, "sources": message.sources},
    )



=== Contents of django\chat\management\commands\eval_responses.py ===
"""
True end-to-end evaluation of Otto Corporate QA code, using the actual Views and Models.
Assumes that the corporate knowledge base is loaded into the database.
"""

import json
import os
import time

from django.conf import settings
from django.contrib.auth import get_user_model
from django.contrib.auth.models import Group
from django.core.management.base import BaseCommand

import tqdm
import yaml
from django_extensions.management.utils import signalcommand
from llama_index.core import ChatPromptTemplate, PromptTemplate, Settings
from llama_index.core.llms import ChatMessage, MessageRole
from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding
from llama_index.llms.azure_openai import AzureOpenAI
from structlog import get_logger

from chat.models import Chat, ChatOptions, Message
from chat.responses import chat_response, qa_response
from librarian.models import Library

logger = get_logger(__name__)

UserModel = get_user_model()

llm = AzureOpenAI(
    azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
    azure_deployment="gpt-4o",
    api_key=settings.AZURE_OPENAI_KEY,
    api_version=settings.AZURE_OPENAI_VERSION,
)

embed_model = AzureOpenAIEmbedding(
    model="text-embedding-3-large",
    deployment_name="text-embedding-3-large",
    dimensions=1536,
    embed_batch_size=16,
    api_key=settings.AZURE_OPENAI_KEY,
    azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
    api_version=settings.AZURE_OPENAI_VERSION,
)

Settings.llm = llm
Settings.embed_model = embed_model


# Copy/pasting some of the LlamaIndex eval code here because the FaithfulnessEvaluator
# and CorrectnessEvaluator keep timing out (annoying!)

FAITHFULNESS_TEMPLATE = PromptTemplate(
    "Please tell if a given piece of information "
    "is supported by the context.\n"
    "You need to answer with either YES or NO.\n"
    "Answer YES if any of the context supports the information, even "
    "if most of the context is unrelated. "
    "Also answer YES if the information makes a correct statement about the context "
    "not containing certain information. "
    "Some examples are provided below. \n\n"
    "Information: Apple pie is generally double-crusted.\n"
    "Context: An apple pie is a fruit pie in which the principal filling "
    "ingredient is apples. \n"
    "Apple pie is often served with whipped cream, ice cream "
    "('apple pie  la mode'), custard or cheddar cheese.\n"
    "It is generally double-crusted, with pastry both above "
    "and below the filling; the upper crust may be solid or "
    "latticed (woven of crosswise strips).\n"
    "Answer: YES\n"
    "Information: Apple pies tastes bad.\n"
    "Context: An apple pie is a fruit pie in which the principal filling "
    "ingredient is apples. \n"
    "Apple pie is often served with whipped cream, ice cream "
    "('apple pie  la mode'), custard or cheddar cheese.\n"
    "It is generally double-crusted, with pastry both above "
    "and below the filling; the upper crust may be solid or "
    "latticed (woven of crosswise strips).\n"
    "Answer: NO\n"
    "Information: I'm sorry, but there is no information in the context about George of the Jungle.\n"
    "Context: The statue of liberty was a gift from France to the United States. "
    "The statue was dedicated on October 28, 1886.\n"
    "Answer: YES\n"
    "Information: {generated_answer}\n"
    "Context: {context_str}\n"
    "Answer: "
)


CORRECTNESS_SYSTEM_TEMPLATE = """
You are an expert evaluation system for a question answering chatbot.

You are given the following information:
- a user query, and
- a generated answer

You may also be given a reference answer to use for reference in your evaluation.

Your job is to judge the relevance and correctness of the generated answer.
Output a single score that represents a holistic evaluation.
You must return your response in a line with only the score.
Do not return answers in any other format.
On a separate line provide your reasoning for the score as well.

Follow these guidelines for scoring:
- Your score has to be between 1 and 5, where 1 is the worst and 5 is the best.
- If the generated answer is not relevant to the user query, \
you should give a score of 1.
- If the generated answer is relevant but contains mistakes, \
you should give a score between 2 and 3.
- If the generated answer is relevant and fully correct, \
you should give a score between 4 and 5.

Example Response:
4.0
The generated answer has the exact same metrics as the reference answer, \
    but it is not as concise.

"""

CORRECTNESS_USER_TEMPLATE = """
## User Query
{query}

## Reference Answer
{reference_answer}

## Generated Answer
{generated_answer}
"""

CORRECTNESS_TEMPLATE = ChatPromptTemplate(
    message_templates=[
        ChatMessage(role=MessageRole.SYSTEM, content=CORRECTNESS_SYSTEM_TEMPLATE),
        ChatMessage(role=MessageRole.USER, content=CORRECTNESS_USER_TEMPLATE),
    ]
)


def exponential_backoff_retry(func, max_retries=5, base_delay=1):
    """Retry a function with exponential backoff."""
    delay = base_delay
    for i in range(max_retries):
        try:
            return func()
        except Exception as e:
            logger.error(f"Attempt {i + 1} failed: {e}")
            time.sleep(delay)
            delay *= 2
    return {}  # Return empty dict if all retries fail


class Command(BaseCommand):
    help = "Evaluate the chatbot on a set of reference questions and answers."

    def add_arguments(self, parser):
        parser.add_argument(
            "filename",
            type=str,
            help="Specify filename to load the evaluation set from (in django/chat/eval/)",
        )

    @signalcommand
    def handle(self, *args, **options):
        filename = options.get("filename")
        user = _create_test_user()

        # Load YAML file to dict
        path = os.path.join(settings.BASE_DIR, "chat", "eval", filename)
        with open(path, "r") as file:
            eval_set = yaml.safe_load(file)

        # Evaluate each instance
        results = []
        for eval_instance in tqdm.tqdm(eval_set):
            try:
                results.append(_test_qa_response(eval_instance, user))
            except Exception as e:
                logger.error(f"Failed to evaluate instance: {e}")

        # Save results to file
        results_path = os.path.join(
            settings.BASE_DIR,
            "chat",
            "eval",
            "results",
            f"{filename.split('.')[0]}.json",
        )
        with open(results_path, "w") as file:
            json.dump(results, file)

        # Print out the numeric results
        faithfulness_scores = [
            r["faithfulness"]
            for r in results
            if "faithfulness" in r and r["faithfulness"] is not None
        ]
        correctness_scores = [
            r["correctness"]
            for r in results
            if "correctness" in r and r["correctness"] is not None
        ]
        sources_found = [
            r["p_sources_found"]
            for r in results
            if "p_sources_found" in r and r["p_sources_found"] is not None
        ]

        try:
            print(
                f"Average faithfulness: {100 * sum(faithfulness_scores) / len(faithfulness_scores):.2f}%"
            )
        except ZeroDivisionError:
            print("No faithfulness scores available.")

        try:
            print(
                f"Average correctness: {100 * sum(correctness_scores) / len(correctness_scores):.2f}%"
            )
        except ZeroDivisionError:
            print("No correctness scores available.")

        try:
            print(
                f"Average % sources found: {100 * sum(sources_found) / len(sources_found):.2f}%"
            )
        except ZeroDivisionError:
            print("No sources found scores available.")

        user.delete()

        # System output indicating to user completeness
        self.stdout.write(
            self.style.SUCCESS(
                f"Evaluated {len(eval_set)} instances and saved results to {results_path}. View with eval_results.ipynb"
            )
        )


def _create_test_user():
    # Check if user exists
    user = UserModel.objects.filter(upn="eval_user").first()
    if user:
        user.delete()
    user = UserModel.objects.create_user(upn="eval_user", password="password")
    # Add user to group "Otto admin"
    user.groups.add(Group.objects.get(name="Otto admin"))
    user.save()
    return user


def _test_qa_response(eval_instance, user):
    try:
        # Create chat and build chat history
        chat = Chat(user=user)
        chat.save()
        chat_options = ChatOptions.objects.create(chat=chat, mode=eval_instance["mode"])
        for message in eval_instance["history"]:
            if message.get("user", None):
                last_message = Message.objects.create(
                    chat=chat, text=message["user"], is_bot=False
                )
            elif message.get("ai", None):
                last_message = Message.objects.create(
                    chat=chat, text=message["ai"], is_bot=True
                )
            if "vector_store_table" in eval_instance:
                library = Library.objects.get(
                    vector_store_table=eval_instance["vector_store_table"]
                )

        if library is not None:
            chat_options.qa_library = library
            chat_options.save()

        # Expected answer will be evaluated against the response by GPT-4
        expected_answer = eval_instance["responses"][0]

        # Expected sources are evaluated on substring match with returned sources
        expected_sources = eval_instance.get("sources", [])

        response_message = Message.objects.create(
            chat=chat, is_bot=True, parent=last_message
        )

        # Get response from appropriate chat function
        logger.debug(f"Asking Otto: {last_message.text}")
        logger.debug(f"(Expected answer: {expected_answer})")
        if eval_instance["mode"] == "qa":
            chat.save()
            response_str, source_nodes = qa_response(chat, response_message, eval=True)
            logger.info(f"Response from Otto: {response_str}")
        elif eval_instance["mode"] == "chat":
            response_str = chat_response(chat, response_message, eval=True)
            logger.debug(f"Response from Otto: {response_str}")
        else:
            logger.debug(f"Mode {eval_instance['mode']} not recognized, skipping...")
            return {}
        response_sources = [
            str(source_node.node.metadata) + "\n" + source_node.node.text
            for source_node in source_nodes
        ]

        from concurrent.futures import ThreadPoolExecutor

        # We want to run _eval_correctness, _eval_faithfulness and _eval_sources in parallel
        correctness_eval = None
        faithfulness_eval = None
        sources_eval = None

        with ThreadPoolExecutor(max_workers=3) as executor:
            correctness_future = executor.submit(
                _eval_correctness, last_message.text, response_str, expected_answer
            )
            if eval_instance["mode"] == "qa":
                faithfulness_future = executor.submit(
                    _eval_faithfulness, response_str, response_sources
                )
                sources_future = executor.submit(
                    _eval_sources, response_sources, expected_sources
                )

            correctness_eval = correctness_future.result()
            if eval_instance["mode"] == "qa":
                faithfulness_eval = faithfulness_future.result()
                sources_eval = sources_future.result()

        # Clean up: Delete chat
        chat.delete()
        return {
            "conversation": eval_instance["history"],
            "expected_response": expected_answer,
            "returned_response": response_str,
            "expected_sources": expected_sources,
            "returned_sources": response_sources,
            "faithfulness": faithfulness_eval,
            "correctness": correctness_eval,
            "p_sources_found": sources_eval,
            "mostly_correct": correctness_eval > 0.5,
            "any_sources_found": None if sources_eval is None else sources_eval > 0,
        }
    except Exception as e:
        logger.debug(f"Error: {e}")
        return {}


def _eval_faithfulness(response_str, response_sources):
    eval_response = llm.predict(
        prompt=FAITHFULNESS_TEMPLATE,
        generated_answer=response_str,
        context_str=response_sources,
    )
    return 1.0 if "yes" in eval_response.lower() else 0.0


def _eval_correctness(query_str, response_str, expected_answer):
    eval_response = llm.predict(
        prompt=CORRECTNESS_TEMPLATE,
        query=query_str,
        generated_answer=response_str,
        reference_answer=expected_answer,
    )
    # Normally a score between 1 and 5 - let's normalize to range (0, 1)
    return (float(eval_response.split("\n")[0]) - 1) / 4


def _eval_sources(response_sources, expected_sources, debug=False):
    # Special case: When no sources are expected, this test doesn't apply
    if len(expected_sources) == 0:
        return None
    logger.info(f"Response sources: {[r[:100] for r in response_sources]}")
    logger.info(f"Expected sources: {[e[:100] for e in expected_sources]}")
    source_positions = [-1] * len(expected_sources)
    for i, source in enumerate(expected_sources):
        for j, response_source in enumerate(response_sources):
            if source in response_source:
                if debug:
                    logger.info(f"Source {i} found at position {j}: {source}")
                source_positions[i] = j
                break
    for i, source in enumerate(expected_sources):
        if source_positions[i] == -1:
            if debug:
                logger.debug(f"Source {i} not found: {source}")
    # Return the proportion of sources found
    p_found = 1 - source_positions.count(-1) / len(source_positions)
    return p_found



=== Contents of django\chat\metrics\__init__.py ===



=== Contents of django\chat\metrics\activity_metrics.py ===
from prometheus_client import Counter

chat_new_session_started_total = Counter(
    name="chat_session_started_total",
    documentation="number of chat sessions started by users",
    labelnames=["user", "mode"],
)


chat_session_restored_total = Counter(
    name="chat_session_restored_total",
    documentation="number of chat sessions restored by users",
    labelnames=["user", "mode"],
)


chat_request_type_total = Counter(
    name="chat_request_type_total",
    documentation="number of translation requests sent by users and type",
    labelnames=["user", "type"],
)



=== Contents of django\chat\metrics\feedback_metrics.py ===
from prometheus_client import Counter

chat_negative_feedback_total = Counter(
    "chat_negative_feedback_total",
    "number of negative feedback submitted for a chat message",
    labelnames=["user", "message"],
)

chat_positive_feedback_total = Counter(
    "chat_positive_feedback_total",
    "number of positive feedback submitted for a chat message",
    labelnames=["user", "message"],
)



=== Contents of django\chat\migrations\__init__.py ===



=== Contents of django\chat\migrations\0001_initial.py ===
# Generated by Django 5.0.7 on 2024-07-25 20:33

import uuid
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = []

    operations = [
        migrations.CreateModel(
            name="AnswerSource",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("node_text", models.TextField()),
                ("node_score", models.FloatField(default=0.0)),
                ("saved_citation", models.TextField(blank=True)),
                (
                    "saved_data_source_name",
                    models.CharField(blank=True, max_length=255),
                ),
            ],
        ),
        migrations.CreateModel(
            name="Chat",
            fields=[
                (
                    "id",
                    models.UUIDField(
                        default=uuid.uuid4,
                        editable=False,
                        primary_key=True,
                        serialize=False,
                    ),
                ),
                ("title", models.CharField(blank=True, max_length=255)),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                ("accessed_at", models.DateTimeField(auto_now_add=True)),
            ],
        ),
        migrations.CreateModel(
            name="ChatFile",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("filename", models.CharField(max_length=255)),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                ("eof", models.BooleanField(default=False)),
                ("text", models.TextField(blank=True)),
            ],
        ),
        migrations.CreateModel(
            name="ChatOptions",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("preset_name", models.CharField(blank=True, max_length=255)),
                ("user_default", models.BooleanField(default=False)),
                ("mode", models.CharField(default="qa", max_length=255)),
                (
                    "chat_model",
                    models.CharField(default="gpt-35-turbo", max_length=255),
                ),
                ("chat_temperature", models.FloatField(default=0.1)),
                (
                    "chat_system_prompt",
                    models.TextField(
                        blank=True,
                        default="You are a general-purpose AI chatbot. You follow these rules:\n\n1. You are professional, accurate and helpful above all.\n\n2. Your name is 'Otto', an AI who works for the Department of Justice Canada.\n\n3. You do not have access to the internet or other knowledge bases. If you are asked about very specific facts, especially one about the Government of Canada or laws, you always caveat your response, e.g., 'I am a pre-trained AI and do not have access to the internet, so my answers might not be correct. Based on my training data, I expect that...'\n\n4. If you are asked a question about Department of Justice or other Government of Canada / HR policies, you inform users of Otto's 'Q&A' mode which can provide more accurate information.\n\n6. You answer in markdown format to provide clear and readable responses.",
                    ),
                ),
                (
                    "summarize_model",
                    models.CharField(default="gpt-35-turbo", max_length=255),
                ),
                ("summarize_style", models.CharField(default="short", max_length=255)),
                ("summarize_language", models.CharField(default="en", max_length=255)),
                ("summarize_prompt", models.TextField(blank=True)),
                ("translate_language", models.CharField(default="fr", max_length=255)),
                ("qa_model", models.CharField(default="gpt-35-turbo", max_length=255)),
                ("qa_topk", models.IntegerField(default=5)),
            ],
        ),
        migrations.CreateModel(
            name="Message",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("text", models.TextField()),
                ("date_created", models.DateTimeField(auto_now_add=True)),
                ("feedback", models.IntegerField(default=0)),
                ("feedback_comment", models.TextField(blank=True)),
                ("is_bot", models.BooleanField(default=False)),
                ("bot_name", models.CharField(blank=True, max_length=255)),
                ("cost", models.FloatField(default=0.0)),
                ("pinned", models.BooleanField(default=False)),
                ("details", models.JSONField(default=dict)),
                ("mode", models.CharField(default="chat", max_length=255)),
            ],
        ),
    ]



=== Contents of django\chat\migrations\0002_initial.py ===
# Generated by Django 5.0.7 on 2024-07-25 20:33

import django.db.models.deletion
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        ("chat", "0001_initial"),
        ("librarian", "0001_initial"),
    ]

    operations = [
        migrations.AddField(
            model_name="answersource",
            name="document",
            field=models.ForeignKey(
                null=True,
                on_delete=django.db.models.deletion.SET_NULL,
                to="librarian.document",
            ),
        ),
    ]



=== Contents of django\chat\migrations\0003_initial.py ===
# Generated by Django 5.0.7 on 2024-07-25 20:33

import django.db.models.deletion
from django.conf import settings
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        ("chat", "0002_initial"),
        ("librarian", "0001_initial"),
        ("otto", "0001_initial"),
        migrations.swappable_dependency(settings.AUTH_USER_MODEL),
    ]

    operations = [
        migrations.AddField(
            model_name="chat",
            name="security_label",
            field=models.ForeignKey(
                null=True,
                on_delete=django.db.models.deletion.SET_NULL,
                to="otto.securitylabel",
            ),
        ),
        migrations.AddField(
            model_name="chat",
            name="user",
            field=models.ForeignKey(
                on_delete=django.db.models.deletion.CASCADE, to=settings.AUTH_USER_MODEL
            ),
        ),
        migrations.AddField(
            model_name="chatfile",
            name="saved_file",
            field=models.ForeignKey(
                null=True,
                on_delete=django.db.models.deletion.SET_NULL,
                related_name="chat_files",
                to="librarian.savedfile",
            ),
        ),
        migrations.AddField(
            model_name="chatoptions",
            name="qa_data_sources",
            field=models.ManyToManyField(
                related_name="qa_options", to="librarian.datasource"
            ),
        ),
        migrations.AddField(
            model_name="chatoptions",
            name="qa_library",
            field=models.ForeignKey(
                null=True,
                on_delete=django.db.models.deletion.SET_NULL,
                related_name="qa_options",
                to="librarian.library",
            ),
        ),
        migrations.AddField(
            model_name="chatoptions",
            name="user",
            field=models.ForeignKey(
                null=True,
                on_delete=django.db.models.deletion.CASCADE,
                related_name="chat_options",
                to=settings.AUTH_USER_MODEL,
            ),
        ),
        migrations.AddField(
            model_name="chat",
            name="options",
            field=models.OneToOneField(
                null=True,
                on_delete=django.db.models.deletion.CASCADE,
                related_name="chat",
                to="chat.chatoptions",
            ),
        ),
        migrations.AddField(
            model_name="message",
            name="chat",
            field=models.ForeignKey(
                on_delete=django.db.models.deletion.CASCADE,
                related_name="messages",
                to="chat.chat",
            ),
        ),
        migrations.AddField(
            model_name="message",
            name="parent",
            field=models.OneToOneField(
                null=True,
                on_delete=django.db.models.deletion.CASCADE,
                related_name="child",
                to="chat.message",
            ),
        ),
        migrations.AddField(
            model_name="chatfile",
            name="message",
            field=models.ForeignKey(
                on_delete=django.db.models.deletion.CASCADE,
                related_name="files",
                to="chat.message",
            ),
        ),
        migrations.AddField(
            model_name="answersource",
            name="message",
            field=models.ForeignKey(
                on_delete=django.db.models.deletion.CASCADE, to="chat.message"
            ),
        ),
        migrations.AddConstraint(
            model_name="message",
            constraint=models.CheckConstraint(
                check=models.Q(
                    models.Q(("parent__isnull", False), ("is_bot", True)),
                    ("parent__isnull", True),
                    _connector="OR",
                ),
                name="check_parent_is_user_message",
            ),
        ),
    ]



=== Contents of django\chat\migrations\0004_remove_answersource_saved_data_source_name.py ===
# Generated by Django 5.0.7 on 2024-08-08 14:43

from django.db import migrations


class Migration(migrations.Migration):

    dependencies = [
        ("chat", "0003_initial"),
    ]

    operations = [
        migrations.RemoveField(
            model_name="answersource",
            name="saved_data_source_name",
        ),
    ]



=== Contents of django\chat\migrations\0005_alter_chatoptions_chat_system_prompt.py ===
# Generated by Django 5.0.7 on 2024-08-09 20:26

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ("chat", "0004_remove_answersource_saved_data_source_name"),
    ]

    operations = [
        migrations.AlterField(
            model_name="chatoptions",
            name="chat_system_prompt",
            field=models.TextField(blank=True),
        ),
    ]



=== Contents of django\chat\migrations\0006_alter_chatoptions_chat_model_and_more.py ===
# Generated by Django 5.1 on 2024-08-13 18:09

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ("chat", "0005_alter_chatoptions_chat_system_prompt"),
    ]

    operations = [
        migrations.AlterField(
            model_name="chatoptions",
            name="chat_model",
            field=models.CharField(default="gpt-4o", max_length=255),
        ),
        migrations.AlterField(
            model_name="chatoptions",
            name="qa_model",
            field=models.CharField(default="gpt-4o", max_length=255),
        ),
        migrations.AlterField(
            model_name="chatoptions",
            name="summarize_model",
            field=models.CharField(default="gpt-4o", max_length=255),
        ),
    ]



=== Contents of django\chat\migrations\0007_chatoptions_qa_prompt.py ===
# Generated by Django 5.1 on 2024-08-14 15:37

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ("chat", "0006_alter_chatoptions_chat_model_and_more"),
    ]

    operations = [
        migrations.AddField(
            model_name="chatoptions",
            name="qa_prompt",
            field=models.TextField(blank=True),
        ),
    ]



=== Contents of django\chat\migrations\0008_remove_chatoptions_qa_prompt_and_more.py ===
# Generated by Django 5.1 on 2024-08-16 18:21

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ("chat", "0007_chatoptions_qa_prompt"),
    ]

    operations = [
        migrations.RemoveField(
            model_name="chatoptions",
            name="qa_prompt",
        ),
        migrations.AddField(
            model_name="chatoptions",
            name="qa_post_instructions",
            field=models.TextField(blank=True),
        ),
        migrations.AddField(
            model_name="chatoptions",
            name="qa_pre_instructions",
            field=models.TextField(blank=True),
        ),
        migrations.AddField(
            model_name="chatoptions",
            name="qa_system_prompt",
            field=models.TextField(blank=True),
        ),
    ]



=== Contents of django\chat\migrations\0009_chatoptions_qa_prompt_template.py ===
# Generated by Django 5.1 on 2024-08-16 18:22

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ("chat", "0008_remove_chatoptions_qa_prompt_and_more"),
    ]

    operations = [
        migrations.AddField(
            model_name="chatoptions",
            name="qa_prompt_template",
            field=models.TextField(blank=True),
        ),
    ]



=== Contents of django\chat\migrations\0010_chatoptions_qa_answer_mode_chatoptions_qa_prune_and_more.py ===
# Generated by Django 5.1 on 2024-08-16 19:27

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ("chat", "0009_chatoptions_qa_prompt_template"),
    ]

    operations = [
        migrations.AddField(
            model_name="chatoptions",
            name="qa_answer_mode",
            field=models.CharField(default="combined", max_length=20),
        ),
        migrations.AddField(
            model_name="chatoptions",
            name="qa_prune",
            field=models.BooleanField(default=True),
        ),
        migrations.AddField(
            model_name="chatoptions",
            name="qa_source_order",
            field=models.CharField(default="score", max_length=20),
        ),
        migrations.AddField(
            model_name="chatoptions",
            name="qa_vector_ratio",
            field=models.FloatField(default=0.6),
        ),
    ]



=== Contents of django\chat\migrations\0011_chatoptions_qa_rewrite.py ===
# Generated by Django 5.1 on 2024-08-16 19:39

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ("chat", "0010_chatoptions_qa_answer_mode_chatoptions_qa_prune_and_more"),
    ]

    operations = [
        migrations.AddField(
            model_name="chatoptions",
            name="qa_rewrite",
            field=models.BooleanField(default=False),
        ),
    ]



=== Contents of django\chat\migrations\0012_alter_message_cost.py ===
# Generated by Django 5.1 on 2024-08-26 19:13

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ("chat", "0011_chatoptions_qa_rewrite"),
    ]

    operations = [
        migrations.AlterField(
            model_name="message",
            name="cost",
            field=models.DecimalField(decimal_places=4, default=0, max_digits=10),
        ),
    ]



=== Contents of django\chat\migrations\0013_rename_cost_message_usd_cost.py ===
# Generated by Django 5.1 on 2024-09-03 20:32

from django.db import migrations


class Migration(migrations.Migration):

    dependencies = [
        ("chat", "0012_alter_message_cost"),
    ]

    operations = [
        migrations.RenameField(
            model_name="message",
            old_name="cost",
            new_name="usd_cost",
        ),
    ]



=== Contents of django\laws\__init__.py ===



=== Contents of django\laws\admin.py ===
from django.contrib import admin

# Register your models here.



=== Contents of django\laws\apps.py ===
from django.apps import AppConfig


class LawsConfig(AppConfig):
    default_auto_field = "django.db.models.BigAutoField"
    name = "laws"



=== Contents of django\laws\models.py ===
import time

from django.conf import settings
from django.db import models

import tiktoken
from llama_index.core import VectorStoreIndex
from llama_index.core.callbacks import CallbackManager, TokenCountingHandler
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
from structlog import get_logger
from tqdm import tqdm

logger = get_logger(__name__)

token_counter = TokenCountingHandler(
    tokenizer=tiktoken.encoding_for_model("gpt-4").encode
)


def connect_to_vector_store(vector_store_table: str) -> VectorStoreIndex:
    # Same as in Librarian utils, but with token counter added
    from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding
    from llama_index.llms.azure_openai import AzureOpenAI
    from llama_index.vector_stores.postgres import PGVectorStore

    llm = AzureOpenAI(
        model=settings.DEFAULT_CHAT_MODEL,  # TODO: Rethink how to pass this in. Maybe a global variable? Or dynamic based on the library?
        deployment_name=settings.DEFAULT_CHAT_MODEL,  # TODO: Revisit whether unfiltered is still needed or if an alternative can be used.
        api_key=settings.AZURE_OPENAI_KEY,
        azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
        api_version=settings.AZURE_OPENAI_VERSION,
    )

    embed_model = AzureOpenAIEmbedding(
        model="text-embedding-3-large",
        deployment_name="text-embedding-3-large",
        dimensions=1536,
        embed_batch_size=128,
        api_key=settings.AZURE_OPENAI_KEY,
        azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
        api_version=settings.AZURE_OPENAI_VERSION,
    )

    # Get the vector store for the library
    vector_store = PGVectorStore.from_params(
        database=settings.DATABASES["vector_db"]["NAME"],
        host=settings.DATABASES["vector_db"]["HOST"],
        password=settings.DATABASES["vector_db"]["PASSWORD"],
        port=5432,
        user=settings.DATABASES["vector_db"]["USER"],
        table_name=vector_store_table,
        embed_dim=1536,  # openai embedding dimension
        hybrid_search=True,
        text_search_config="english",
        perform_setup=True,
    )

    # Remove the old content from the vector store
    idx = VectorStoreIndex.from_vector_store(
        vector_store=vector_store,
        llm=llm,
        embed_model=embed_model,
        callback_manager=CallbackManager([token_counter]),
        show_progress=False,
    )

    return idx


class LawManager(models.Manager):

    def from_doc_and_nodes(self, document, nodes, add_to_vector_store=True):
        obj = self.model()
        obj.title = document.metadata["display_metadata"]
        obj.short_title = document.metadata.get("short_title")
        obj.long_title = document.metadata.get("long_title")
        obj.ref_number = (
            document.metadata["consolidated_number"]
            or document.metadata["instrument_number"]
            or document.metadata["bill_number"]
        )
        obj.law_id = document.metadata["id"]
        obj.lang = document.metadata["lang"]
        obj.type = document.metadata["type"]
        obj.last_amended_date = document.metadata.get("last_amended_date")
        obj.current_date = document.metadata.get("current_date")
        obj.enabling_authority = document.metadata.get("enabling_authority")
        obj.node_id = document.doc_id

        obj.full_clean()
        obj.save()

        if add_to_vector_store:
            nodes = [document] + nodes
            idx = connect_to_vector_store("laws_lois__")
            batch_size = 128
            logger.debug(
                f"Embedding & inserting nodes into vector store (batch size={batch_size} nodes)..."
            )
            for i in tqdm(range(0, len(nodes), batch_size)):
                # Exponential backoff retry
                for j in range(4, 12):
                    try:
                        idx.insert_nodes(nodes[i : i + batch_size])
                        break
                    except Exception as e:
                        logger.error(f"Error inserting nodes: {e}")
                        logger.error(f"Retrying in {2**j} seconds...")
                        time.sleep(2**j)
        return obj


class Law(models.Model):
    """
    Act or regulation. Mirrors LlamaIndex vector store representation.
    """

    # Title concatenates short_title, long_title and ref_number
    title = models.TextField()
    short_title = models.TextField(null=True, blank=True)
    long_title = models.TextField(null=True, blank=True)

    # e.g. "A-0.6" or "SOR-86-1026".
    # Enabling authority or external references use these.
    ref_number = models.CharField(max_length=255)

    # Language-agnostic ID of the law
    law_id = models.CharField(max_length=255)

    lang = models.CharField(max_length=10, default="eng")
    type = models.CharField(max_length=255, default="act")
    last_amended_date = models.DateField(null=True)
    current_date = models.DateField(null=True)

    # enabling_authority = models.ForeignKey("self", on_delete=models.PROTECT, null=True)
    enabling_authority = models.CharField(max_length=255, null=True, blank=True)

    # ID of the LlamaIndex node for the document (language-specific)
    node_id = models.CharField(max_length=255, unique=True)

    objects = LawManager()

    @classmethod
    def reset(cls):
        db = settings.DATABASES["vector_db"]
        connection_string = f"postgresql+psycopg2://{db['USER']}:{db['PASSWORD']}@{db['HOST']}:5432/{db['NAME']}"
        engine = create_engine(connection_string)
        Session = sessionmaker(bind=engine)
        session = Session()
        session.execute(text(f"DROP TABLE IF EXISTS data_laws_lois__ CASCADE"))
        session.commit()
        session.close()
        cls.objects.all().delete()

    @classmethod
    def get_index(cls):
        idx = connect_to_vector_store("laws_lois__")
        return idx



=== Contents of django\laws\prompts.py ===
# Chat prompts

# NOTE: This is the default system prompt from llama-index source code.
# We didn't include the "some rules to follow" stuff in the Gradio app
system_prompt = (
    "You are an expert Q&A system that is trusted around the world.\n"
    "Always answer the query using the provided context information, "
    "and not prior knowledge.\n"
    "Some rules to follow:\n"
    "1. Never directly reference the given context in your answer.\n"
    "2. Avoid statements like 'Based on the context, ...' or "
    "'The context information ...' or anything along "
    "those lines."
)

# Augmented Q&A prompt we used in Gradio app
qa_prompt_instruction_tmpl = (
    "Context information is below.\n"
    "---------------------\n"
    "{context_str}\n"
    "---------------------\n"
    "Given the context information and not prior knowledge, "
    "answer the query.\n"
    "If the context information is entirely unrelated to the provided query, "
    "don't try to answer the question; just say 'Sorry, I cannot answer "
    "that question.'.\n"
    "Query: {query_str}\n"
    "{additional_instructions}\n"
    "Answer: "
)



=== Contents of django\laws\tests.py ===
from django.test import TestCase

# Create your tests here.



=== Contents of django\laws\urls.py ===
from django.urls import path

from .views import advanced_search_form, answer, index, search, source

app_name = "laws"
urlpatterns = [
    path("", index, name="index"),
    path("search/", search, name="search"),
    path("answer/", answer, name="answer"),
    path("source/<source_id>", source, name="source"),
    path("advanced_search_form/", advanced_search_form, name="advanced_search_form"),
]



=== Contents of django\laws\views.py ===
import asyncio
import urllib.parse

from django.conf import settings
from django.core.cache import cache
from django.db import connections
from django.http import HttpResponse, StreamingHttpResponse
from django.shortcuts import redirect, render
from django.utils.translation import gettext as _

import markdown
import tiktoken
from llama_index.core import ChatPromptTemplate
from llama_index.core.llms import ChatMessage, MessageRole
from structlog import get_logger

from chat.utils import llm_response_to_html
from otto.utils.decorators import app_access_required

from .models import Law
from .prompts import qa_prompt_instruction_tmpl, system_prompt

TEXT_QA_SYSTEM_PROMPT = ChatMessage(
    content=system_prompt,
    role=MessageRole.SYSTEM,
)
TEXT_QA_PROMPT_TMPL_MSGS = [
    TEXT_QA_SYSTEM_PROMPT,
    ChatMessage(
        content=qa_prompt_instruction_tmpl,
        role=MessageRole.USER,
    ),
]


logger = get_logger(__name__)

md = markdown.Markdown(extensions=["fenced_code", "nl2br", "tables"], tab_length=2)

app_name = "laws"


def _num_tokens(string: str, model_name: str) -> int:
    """Returns the number of tokens in a text string."""
    encoding = tiktoken.encoding_for_model(model_name)
    num_tokens = len(encoding.encode(string))
    return num_tokens


async def sync_generator_to_async(generator):
    for value in generator:
        yield value
        await asyncio.sleep(0)  # This will allow other async tasks to run


def _get_source_node(node_id):
    # Get the source node from the database (settings.DATABASES["vector_db"])
    # It is in a table data_laws_lois__ and column is "node_id"
    # Return the "text" and "metadata_" columns
    # "metadata_" column is a JSON field, so you can access it like a dictionary
    with connections["vector_db"].cursor() as cursor:
        cursor.execute(
            f"SELECT text, metadata_ FROM data_laws_lois__ WHERE node_id = '{node_id}'"
        )
        row = cursor.fetchone()
        if row:
            return {
                "text": row[0],
                "metadata": row[1],
            }
    return None


def _get_other_lang_node(node_id):
    # Replace "eng" with "fra" and vice versa
    lang = "eng" if "eng" in node_id else "fra"
    other_lang_node_id = (
        node_id.replace("eng", "fra")
        if lang == "eng"
        else node_id.replace("fra", "eng")
    )
    return _get_source_node(other_lang_node_id)


def _get_law_url(law):
    ref = law.ref_number.replace(" ", "-").replace("/", "-")
    # Constitution has special case
    if ref == "Const" and law.lang == "eng":
        return "https://laws-lois.justice.gc.ca/eng/Const/Const_index.html"
    if ref == "Const" and law.lang == "fra":
        return "https://laws-lois.justice.gc.ca/fra/ConstRpt/Const_index.html"
    if law.type == "act" and law.lang == "eng":
        return f"https://laws-lois.justice.gc.ca/eng/acts/{ref}/"
    if law.type == "act" and law.lang == "fra":
        return f"https://laws-lois.justice.gc.ca/fra/lois/{ref}/"
    if law.type == "regulation" and law.lang == "eng":
        return f"https://laws-lois.justice.gc.ca/eng/regulations/{ref}/"
    if law.type == "regulation" and law.lang == "fra":
        return f"https://laws-lois.justice.gc.ca/fra/reglements/{ref}/"


@app_access_required(app_name)
def index(request):
    context = {"hide_breadcrumbs": True}
    return render(request, "laws/laws.html", context=context)


def source(request, source_id):
    source_id = urllib.parse.unquote_plus(source_id)
    source_node = _get_source_node(source_id)
    other_lang_node = _get_other_lang_node(source_id)
    law = Law.objects.filter(node_id=source_node["metadata"]["doc_id"]).first()
    nodes = [source_node, other_lang_node]
    if other_lang_node is None:
        nodes = [source_node]
    for node in nodes:
        node["title"] = node["metadata"]["display_metadata"].split("\n")[0]
        node["html"] = md.convert(node["text"])
        node["headings"] = node["metadata"].get("headings", None)
        node["chunk"] = (
            node["metadata"]["chunk"]
            if not node["metadata"]["chunk"].endswith("/1")
            else None
        )
    law.url = _get_law_url(law)
    context = {
        "source_node": source_node,
        "other_lang_node": other_lang_node,
        "law": law,
    }
    if not source_node:
        return HttpResponse(_("Source not found."), status=404)

    return render(request, "laws/source_details.html", context=context)


def advanced_search_form(request):
    """
    Returns the search form HTML for advanced search.
    Advanced search requires some database queries to populate the form.
    """
    context = {}
    context["documents"] = Law.objects.all().order_by("title")
    for document in context["documents"]:
        if ": " in document.title:
            document.title = (
                f'{document.title.split(": ")[0]} ({document.title.split("(")[-1]}'
            )
    context["act_count"] = Law.objects.filter(type="act").count()
    context["reg_count"] = Law.objects.filter(type="regulation").count()
    context["model_options"] = [
        {"id": "gpt-4o", "name": _("GPT-4o (Global)")},
        {"id": "gpt-4", "name": _("GPT-4 (Canada)")},
        {"id": "gpt-35", "name": _("GPT-3.5 (Canada)")},
    ]
    # if settings.GROQ_API_KEY:
    #     context["model_options"] += [
    #         {"id": "llama3-70b-8192", "name": "Llama3 70B (Groq)"},
    #         {"id": "llama3-8b-8192", "name": "Llama3 8B (Groq)"},
    #     ]

    return render(request, f"laws/advanced_search_form.html", context=context)


@app_access_required(app_name)
def answer(request):
    from llama_index.core import Settings
    from llama_index.core.response_synthesizers import CompactAndRefine
    from llama_index.core.schema import MetadataMode
    from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding
    from llama_index.llms.azure_openai import AzureOpenAI

    additional_instructions = request.GET.get("additional_instructions", "")

    CHAT_TEXT_QA_PROMPT = ChatPromptTemplate(
        message_templates=TEXT_QA_PROMPT_TMPL_MSGS
    ).partial_format(additional_instructions=additional_instructions)

    # from llama_index.llms.groq import Groq

    model = request.GET.get("model", settings.DEFAULT_CHAT_MODEL)
    max_tokens = int(request.GET.get("context_tokens", 2000))
    trim_redundant = bool(request.GET.get("trim_redundant", False))
    query = urllib.parse.unquote_plus(request.GET.get("query", ""))
    logger.debug(query)

    # if "llama" in model:
    #     llm = Groq(model=model, api_key=settings.GROQ_API_KEY, temperature=0.1)
    # else:
    model_name = {
        "gpt-4o": "gpt-4o",
        "gpt-4": "gpt-4-turbo-preview",
        "gpt-35": "gpt-35-turbo",
    }[model]
    llm = AzureOpenAI(
        azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
        azure_deployment=model,
        model=model_name,
        api_version=settings.AZURE_OPENAI_VERSION,
        api_key=settings.AZURE_OPENAI_KEY,
        temperature=0.1,
    )
    embed_model = AzureOpenAIEmbedding(
        model="text-embedding-3-large",
        deployment_name="text-embedding-3-large",
        dimensions=1536,
        embed_batch_size=16,
        api_key=settings.AZURE_OPENAI_KEY,
        azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
        api_version=settings.AZURE_OPENAI_VERSION,
    )

    sources = cache.get(f"sources_{query}")
    if not sources:
        generator = iter([_("Error generating AI response.")])
    else:
        trimmed_sources = []
        total_tokens = 0

        if trim_redundant:
            source_section_ids = set(
                [source.node.metadata["section_id"] for source in sources]
            )
        added_ids = set()

        # Allow up to 4000 tokens of context.
        while sources:
            source = sources.pop(0)
            if trim_redundant:
                # Check if source has a parent node in "sources" list
                if source.node.metadata["parent_id"] in added_ids:
                    continue
                elif source.node.metadata["parent_id"] in source_section_ids:
                    # Find the parent node in the sources list, remove it, and make it the "source"
                    parent_index = next(
                        (
                            i
                            for i, s in enumerate(sources)
                            if s.node.metadata["section_id"]
                            == source.node.metadata["parent_id"]
                        ),
                        None,
                    )
                    if parent_index:
                        parent_tokens = _num_tokens(
                            sources[parent_index].node.get_content(
                                metadata_mode=MetadataMode.LLM
                            ),
                            "gpt-4-turbo-preview",
                        )
                        if total_tokens + parent_tokens <= max_tokens:
                            source = sources.pop(parent_index)
            source_tokens = _num_tokens(
                source.node.get_content(metadata_mode=MetadataMode.LLM),
                "gpt-4-turbo-preview",
            )
            if total_tokens + source_tokens <= max_tokens:
                trimmed_sources.append(source)
                added_ids.add(source.node.metadata["section_id"])
                total_tokens += source_tokens
            else:
                continue
        logger.debug("\n\n\nSources passed to LLM:")
        for source in trimmed_sources:
            logger.debug(source.node.metadata["display_metadata"])
            logger.debug(f'Section ID: {source.node.metadata["section_id"]}')
            logger.debug(f'Parent ID: {source.node.metadata["parent_id"]}')
        sources = trimmed_sources
        logger.debug("\n\n\n")

        response_synthesizer = CompactAndRefine(
            llm=llm,
            streaming=True,
            text_qa_template=CHAT_TEXT_QA_PROMPT,
        )
        query_suffix = (
            "\nRespond in markdown format. "
            "The most important words should be **bolded like this**."
            "Answer the query directly if possible. Do not refer to sections or subsections "
            "unnecessarily; instead, provide the answer directly."
        )
        streaming_response = response_synthesizer.synthesize(
            query=query + query_suffix,
            nodes=sources,
        )
        cache.delete(f"sources_{query}")
        generator = streaming_response.response_gen

    def process_bold_blocks(text, is_in_bold_block, bold_block):
        trimmed_text = text.strip()
        if trimmed_text.startswith("**"):
            if is_in_bold_block:
                # End of bold block
                bold_block += text
                is_in_bold_block = False
            else:
                # Start of a new bold block
                is_in_bold_block = True
                bold_block = text
        else:
            if is_in_bold_block:
                bold_block += text
            else:
                bold_block = None

        return is_in_bold_block, bold_block

    def format_html_response(full_message, sse_joiner):
        # Prevent code-format output
        # NOTE: the first replace is necessary to remove the word "markdown" that
        # sometimes appears after triple backticks
        tmp_full_message = full_message.replace("```markdown", "").replace("`", "")

        # Parse Markdown of full_message to HTML
        message_html = llm_response_to_html(tmp_full_message)
        message_html_lines = message_html.split("\n")
        if len(full_message) > 1:
            formatted_response = (
                f"data: <div>{sse_joiner.join(message_html_lines)}</div>\n\n"
            )

        else:
            formatted_response = None

        return (message_html_lines, formatted_response)

    def htmx_sse_response(response_gen):
        # time.sleep(60)
        sse_joiner = "\ndata: "
        full_message = ""
        message_html_lines = []
        try:
            is_in_bold_block = False
            bold_block = ""

            for text in response_gen:
                is_in_bold_block, bold_block_output = process_bold_blocks(
                    text, is_in_bold_block, bold_block
                )

                if bold_block_output is not None:
                    if is_in_bold_block:
                        bold_block = bold_block_output
                    else:
                        full_message += bold_block_output
                        bold_block = ""

                elif not is_in_bold_block:
                    full_message += text

                message_html_lines, formatted_response = format_html_response(
                    full_message, sse_joiner
                )
                if formatted_response is not None:
                    yield (formatted_response)

            # After the loop, handle any remaining bold block
            if is_in_bold_block and bold_block:
                if not bold_block.strip().endswith("**"):
                    bold_block += "**"
                if bold_block.strip() == "**":
                    bold_block = ""
                full_message += bold_block
                message_html_lines, formatted_response = format_html_response(
                    full_message, sse_joiner
                )
                if formatted_response is not None:
                    yield (formatted_response)
        except Exception as e:
            error = str(e)
            full_message = _("An error occurred:") + f"\n```\n{error}\n```"
            message_html = llm_response_to_html(full_message)
            message_html_lines = message_html.split("\n")

        yield (
            f"data: <div hx-swap-oob='true' id='answer-sse'>"
            f"<div>{sse_joiner.join(message_html_lines)}</div></div>\n\n"
        )

    return StreamingHttpResponse(
        streaming_content=sync_generator_to_async(htmx_sse_response(generator)),
        content_type="text/event-stream",
    )


@app_access_required(app_name)
def search(request):
    if request.method != "POST":
        # redirect to laws index
        return redirect("laws:index")
    from langdetect import detect
    from llama_index.core.retrievers import QueryFusionRetriever
    from llama_index.core.vector_stores.types import MetadataFilter, MetadataFilters
    from llama_index.llms.azure_openai import AzureOpenAI

    # time.sleep(60)
    # We don't want to search Document nodes - only chunks
    filters = [
        MetadataFilter(
            key="node_type",
            value="chunk",
            operator="==",
        ),
    ]

    query = request.POST.get("query")
    pg_idx = Law.get_index()

    advanced_mode = request.POST.get("advanced") == "true"
    disable_llm = not (request.POST.get("ai_answer", False) == "on")
    detect_lang = not (request.POST.get("bilingual_results", None) == "on")
    doc_id_list = None

    logger.info(
        "Search query",
        query=query,
        advanced_mode=advanced_mode,
        disable_llm=disable_llm,
        detect_lang=detect_lang,
        pg_idx=pg_idx,
    )

    if not advanced_mode:
        vector_ratio = 1
        top_k = 25
        # Options for the AI answer
        trim_redundant = True
        model = "gpt-4o"
        context_tokens = 2000
        additional_instructions = ""
    else:
        vector_ratio = float(request.POST.get("vector_ratio", 1))
        top_k = int(request.POST.get("top_k", 25))
        trim_redundant = request.POST.get("trim_redundant", "on") == "on"
        model = request.POST.get("model", settings.DEFAULT_CHAT_MODEL)
        context_tokens = request.POST.get("context_tokens", 2000)
        additional_instructions = request.POST.get("additional_instructions", "")
        # Need to escape the instructions so they can be passed in GET parameter
        additional_instructions = urllib.parse.quote_plus(additional_instructions)

        # Search only the selected documents
        doc_id_list = request.POST.getlist("acts") + request.POST.getlist("regs")

    if detect_lang and not advanced_mode:
        # Detect the language of the query and search only documents in that lang
        lang = detect(query).replace("en", "eng").replace("fr", "fra")
        if lang in ["eng", "fra"]:
            if doc_id_list is None:
                doc_id_list = [law.node_id for law in Law.objects.filter(lang=lang)]
            else:
                doc_id_list = [
                    law.node_id
                    for law in Law.objects.filter(lang=lang)
                    if law.node_id in doc_id_list
                ]

    if doc_id_list is not None:
        filters.append(
            MetadataFilter(
                key="doc_id",
                value=doc_id_list,
                operator="in",
            )
        )
    filters = MetadataFilters(filters=filters)
    if vector_ratio == 1:
        retriever = pg_idx.as_retriever(
            vector_store_query_mode="default",
            similarity_top_k=top_k,
            filters=filters,
            vector_store_kwargs={"hnsw_ef_search": 300},
        )
    elif vector_ratio == 0:
        retriever = pg_idx.as_retriever(
            vector_store_query_mode="sparse", similarity_top_k=top_k, filters=filters
        )
    else:
        vector_retriever = pg_idx.as_retriever(
            vector_store_query_mode="default",
            similarity_top_k=max(top_k * 2, 100),
            filters=filters,
            vector_store_kwargs={"hnsw_ef_search": 300},
        )
        text_retriever = pg_idx.as_retriever(
            vector_store_query_mode="sparse",
            similarity_top_k=max(top_k * 2, 100),
            filters=filters,
        )
        retriever = QueryFusionRetriever(
            retrievers=[vector_retriever, text_retriever],
            mode="relative_score",
            llm=AzureOpenAI(
                azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
                azure_deployment=settings.DEFAULT_CHAT_MODEL,
                model=settings.DEFAULT_CHAT_MODEL,
                api_version=settings.AZURE_OPENAI_VERSION,
                api_key=settings.AZURE_OPENAI_KEY,
                temperature=0.1,
            ),
            similarity_top_k=top_k,
            num_queries=1,
            use_async=False,
            retriever_weights=[vector_ratio, 1 - vector_ratio],
        )

    if advanced_mode and len(doc_id_list) == 0:
        context = {
            "sources": [],
            "query": query,
            "disable_llm": True,
            "answer_params": "",
        }
        return render(request, "laws/search_result.html", context=context)
    sources = retriever.retrieve(query)

    # Cache sources so they can be retrieved in the AI answer function
    cache.set(f"sources_{query}", sources, timeout=60)

    # Pass options through to the AI answer function
    url_encoded_query = urllib.parse.quote_plus(query)
    answer_params = f"?query={url_encoded_query}"
    if trim_redundant:
        answer_params += f"&trim_redundant={trim_redundant}"
    if model:
        answer_params += f"&model={model}"
    if context_tokens:
        answer_params += f"&context_tokens={context_tokens}"
    if additional_instructions:
        answer_params += f"&additional_instructions={additional_instructions}"

    context = {
        "sources": [
            {
                "node_id": urllib.parse.quote_plus(s.node.node_id),
                "title": s.node.metadata["display_metadata"].split("\n")[0],
                "chunk": (
                    s.node.metadata["chunk"]
                    if not s.node.metadata["chunk"].endswith("/1")
                    else None
                ),
                "headings": s.node.metadata.get("headings", None),
                "html": md.convert(s.node.text),
            }
            for s in sources
        ],
        "query": query,
        "disable_llm": disable_llm,
        "answer_params": answer_params,
    }

    response = render(
        request,
        "laws/search_result.html",
        context=context,
    )
    # URL-encode query and append to history URL
    # history_url = "/laws/search/"
    # history_url += f"?query={urllib.parse.quote_plus(query)}"
    # response["HX-Push-Url"] = history_url
    return response



=== Contents of django\laws\management\commands\load_laws_xml.py ===
import os
import shutil
import time
import zipfile
from math import ceil

from django.conf import settings
from django.core.management.base import BaseCommand
from django.utils.timezone import datetime

import requests
from django_extensions.management.utils import signalcommand

from laws.models import Law, token_counter


def _price_tokens(token_counter):
    return 0.000178 * token_counter.total_embedding_token_count / 1000


def _download_repo():
    print("Downloading laws-lois-xml repo...")
    repo_url = (
        "https://github.com/justicecanada/laws-lois-xml/archive/refs/heads/main.zip"
    )

    # Path to save the downloaded zip file
    zip_file_path = "/tmp/laws-lois-xml.zip"

    # Path to extract the zip file
    extract_path = "/tmp"

    # Download the zip file
    response = requests.get(repo_url)
    with open(zip_file_path, "wb") as file:
        file.write(response.content)

    # Extract the zip file
    with zipfile.ZipFile(zip_file_path, "r") as zip_ref:
        zip_ref.extractall(extract_path)

    # Clean up the zip file
    os.remove(zip_file_path)


def _get_law_file_paths(laws_dir, eng_law_ids=[]):
    """
    Search for the English and French file paths for each law ID
    """
    file_paths = []
    # French regulations have different names, unfortunately
    # Replace "SOR-" with "DORS-", "SI-" with "TR-" and "_c." with "_ch."
    filenames = set(
        [f"{law_id}.xml" for law_id in eng_law_ids]
        + [f"{law_id.replace('_c.', '_ch.')}.xml" for law_id in eng_law_ids]
        + [f"{law_id.replace('SOR-', 'DORS-')}.xml" for law_id in eng_law_ids]
        + [f"{law_id.replace('SI-', 'TR-')}.xml" for law_id in eng_law_ids]
    )
    for lang in ["eng", "fra"]:
        categories = (
            ["acts", "regulations"] if lang == "eng" else ["lois", "reglements"]
        )
        for category in categories:
            for file in os.listdir(os.path.join(laws_dir, lang, category)):
                if (file in filenames or not filenames) and (file.endswith(".xml")):
                    file_paths.append(os.path.join(laws_dir, lang, category, file))

    print(len(eng_law_ids), "law IDs provided")
    print(len(file_paths), "files found (should be 2x the number of law IDs)")
    # print("File paths:\n", file_paths)
    return file_paths


import os

from llama_index.core.node_parser import SentenceSplitter
from llama_index.core.schema import (
    Document,
    NodeRelationship,
    RelatedNodeInfo,
    TextNode,
)
from lxml import etree as ET


def law_xml_to_nodes(file_path):
    d = get_dict_from_xml(file_path)
    num_sections = len(d["all_chunkable_sections"])
    nodes = [section_to_nodes(section) for section in d["all_chunkable_sections"]]
    # Flatten nodes
    nodes = [node for sublist in nodes for node in sublist]
    file_id = d["title_str"]
    d["nodes"] = nodes
    return d


def section_to_nodes(section, chunk_size=1024, chunk_overlap=100):
    if chunk_size < 50:
        raise ValueError("Chunk size must be at least 50 tokens.")
    splitter = SentenceSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
    # Split the text into chunks
    chunks = splitter.split_text(section["text"])
    # Create a node from each chunk
    nodes = []
    metadata = {
        "section_id": section["section_id"],
        "parent_id": section.get("parent_id", None),
        "file_id": section["doc_title"],
        "section": section["section_str"],
        "headings": section["heading_str"],
        "doc_id": section["doc_id"],
        "in_force_start_date": section["in_force_start_date"],
        "last_amended_date": section["last_amended_date"],
        "lims_id": section["lims_id"],
        "marginal_note": section["marginal_note"],
        "internal_refs": section["internal_refs"],
        "external_refs": section["external_refs"],
        "node_type": "chunk",
    }
    exclude_keys = list(metadata.keys()) + ["chunk"]
    metadata["display_metadata"] = (
        f'{metadata["file_id"]}, {metadata["section"]}\n' f'{metadata["headings"]}'
    )
    original_display_metadata = metadata["display_metadata"]
    for i, chunk in enumerate(chunks):
        metadata["chunk"] = f"{i+1}/{len(chunks)}"
        if len(chunks) > 1:
            metadata["display_metadata"] = (
                f'{original_display_metadata} ({metadata["chunk"]})'
            )
        nodes.append(
            TextNode(
                text=chunk,
                metadata=metadata,
                excluded_llm_metadata_keys=exclude_keys,
                excluded_embed_metadata_keys=exclude_keys,
                metadata_template="{value}",
                text_template="{metadata_str}\n---\n{content}",
            )
        )
    return nodes


def _get_text(element):
    return "".join(element.itertext()) if element is not None else None


def _get_link(element):
    return (
        element.attrib["link"]
        if element is not None and "link" in element.attrib.keys()
        else None
    )


def _get_joined_text(
    element,
    exclude_tags=["MarginalNote", "Label"],
    break_tags=[
        "Provision",
        "Subsection",
        "Paragraph",
        "Definition",
        "row",
        "TableGroup",
        "HistoricalNote",
        "MarginalNote",
        # "OriginatingRef",
    ],
    double_break_tags=["Subsection", "TableGroup"],
    pipe_tags=["entry"],
    em_tags=[
        "DefinedTermEn",
        "DefinedTermFr",
        "XRefExternal",
        "XRefInternal",
        "Emphasis",
    ],
    strong_tags=["MarginalNote", "TitleText"],
    underline_tags=[],
):
    # TODO: Improve table parsing
    def stylized_text(text, tag):
        if tag in em_tags:
            return f"*{text}*"
        if tag in strong_tags:
            return f"**{text}**"
        if tag in underline_tags:
            return f"__{text}__"
        # if tag in strike_tags:
        #     return f"~~{text}~~"
        return text

    all_text = []
    exclude_tags = exclude_tags.copy()
    for e in element.iter():
        if e.tag in exclude_tags:
            exclude_tags.remove(e.tag)
            continue
        if e.text and e.text.strip():
            all_text.append(stylized_text(e.text.strip(), e.tag))
        if e.tail and e.tail.strip():
            all_text.append(e.tail.strip())
        if e.tag in break_tags:
            all_text.append("\n")
        elif e.tag in double_break_tags:
            all_text.append("\n\n")
        if e.tag in pipe_tags:
            all_text.append("|")
        if e.tag == "tbody":
            all_text.append("\n<tbody>")
    text = (
        " ".join(all_text)
        .replace(" \n ", "\n")
        .strip()
        .replace("\u2002", " ")
        .replace("( ", "(")
        .replace(" )", ")")
        .replace(" .", ".")
        .replace("* ;", "*;")
        .replace("* ,", "*,")
        .replace("* .", "*.")
        .strip()
    )
    # When a line ends in a pipe, it should also start with a pipe and space
    lines = text.split("\n")
    for i, line in enumerate(lines):
        line = line.strip()
        if line.endswith("|"):
            lines[i] = "| " + line
        # Replace the <tbody> tag with | --- | --- | --- | etc. for tables
        if line == "<tbody>" and i > 0 and lines[i - 1].strip().endswith("|"):
            lines[i] = "| --- " * (len(lines[i - 1].split("|")) - 2) + "|"
        elif line == "<tbody>":
            lines[i] = ""
    text = "\n".join(lines)
    return text


def get_dict_from_xml(xml_filename):
    # Extract a JSON serializable dictionary from a act/regulation XML file
    dom = ET.parse(xml_filename)
    root = dom.getroot()
    # French regulations have slightly different filenames, but we want a unique ID
    # to link the English and French versions
    filename = os.path.basename(xml_filename).replace(".xml", "")

    # Band-aid fix for Constitution Act(s)
    if "_E" in filename:
        d_lang = "eng"
        filename = filename.replace("_E", "")
    elif "_F" in filename:
        d_lang = "fra"
        filename = filename.replace("_F_Rapport", "")
    else:
        d_lang = os.path.basename(os.path.dirname(os.path.dirname(xml_filename)))

    # Replace "DORS-" with "SOR-", "TR-" with "SI-" and "_ch." with "_c."
    eng_id = (
        filename.replace("DORS-", "SOR-").replace("TR-", "SI-").replace("_ch.", "_c.")
    )
    d = {
        "id": eng_id,
        "lang": d_lang,
        "filename": filename,
        "type": "act" if root.tag == "Statute" else "regulation",
        "short_title": _get_text(root.find(".//ShortTitle")),
        "long_title": _get_text(root.find(".//LongTitle")),
        "bill_number": _get_text(root.find(".//BillNumber")),
        "instrument_number": _get_text(root.find(".//InstrumentNumber")),
        "consolidated_number": _get_text(root.find(".//ConsolidatedNumber")),
        "last_amended_date": root.attrib.get(
            "{http://justice.gc.ca/lims}lastAmendedDate", None
        ),
        "current_date": root.attrib.get(
            "{http://justice.gc.ca/lims}current-date", None
        ),
        "in_force_start_date": root.attrib.get(
            "{http://justice.gc.ca/lims}inforce-start-date", None
        ),
        "enabling_authority": _get_link(root.find(".//EnablingAuthority/XRefExternal")),
        "preamble": get_preamble(root),
        "sections": [
            section
            for section in [
                get_section(section) for section in root.findall(".//Section")
            ]
            if section is not None
        ],
        "schedules": [
            schedule
            for schedule in [
                get_schedule(schedule) for schedule in root.findall(".//Schedule")
            ]
            if schedule is not None
        ],
    }
    # Aggregate all internal and external references and count instances of each
    for ref_name in ["internal_refs", "external_refs"]:
        ref_list = [
            ref
            for section in d["sections"]
            for ref in section[ref_name]
            if ref["link"] is not None
        ]
        ref_list_set = set([ref["link"] for ref in ref_list])
        d[ref_name] = [
            {
                "link": link,
                "count": len([ref for ref in ref_list if ref["link"] == link]),
            }
            for link in ref_list_set
        ]
    # Some pretty-print and/or unique versions of the fields
    d["doc_id"] = f'{d["id"]}_{d["lang"]}'
    d["title_str"] = d["short_title"] if d["short_title"] else d["long_title"]
    for section in d["sections"]:
        section["section_id"] = f'{d["doc_id"]}_section_{section["id"]}'
        section["heading_str"] = get_heading_str(section)
        section["section_str"] = f"Section {section['id']}"
        section["all_str"] = "\n".join(
            [
                d["title_str"],
                section["section_str"],
                section["heading_str"],
                section["text"],
            ]
        )
        for i, subsection in enumerate(section["subsections"]):
            subsection["section_id"] = (
                f'{d["doc_id"]}_subsection_{section["id"]}{subsection["id"]}'
            )
            subsection["parent_id"] = section["section_id"]
            subsection["heading_str"] = get_heading_str(subsection)
            subsection["section_str"] = (
                f"Sub{section['section_str'].lower()}{subsection['id']}"
            )
            # Often the first subsection should have a marginal note (both as metadata, and as bold text in first line of "text")
            # but the XML is coded oddly so we need to pull this from the parent section.
            if i == 0 and section["marginal_note"]:
                subsection["marginal_note"] = section["marginal_note"]
            subsection["all_str"] = "\n".join(
                [
                    d["title_str"],
                    subsection["section_str"],
                    subsection["heading_str"],
                    subsection["text"],
                ]
            )
    for schedule in d["schedules"]:
        schedule["section_id"] = f'{d["doc_id"]}_schedule_{schedule["id"]}'
        schedule["heading_str"] = get_heading_str(schedule)
        schedule["section_str"] = schedule["id"]
        schedule["all_str"] = "\n".join(
            [
                d["title_str"],
                (schedule["id"] if schedule["id"] else "Schedule"),
                "",
                schedule["text"],
            ]
        )
    # Finally, the preamble also needs a "all_str" field
    if d["preamble"]:
        d["preamble"][0]["section_id"] = f'{d["doc_id"]}_preamble'
        d["preamble"][0]["heading_str"] = get_heading_str(d["preamble"][0])
        d["preamble"][0]["section_str"] = "Preamble"
        d["preamble"][0]["all_str"] = "\n".join(
            [
                d["title_str"],
                "Preamble",
                "",
                d["preamble"][0]["text"],
            ]
        )
        for section in d["preamble"][0]["subsections"]:
            section["section_id"] = f'{d["doc_id"]}_preamble_provision_{section["id"]}'
            section["parent_id"] = d["preamble"][0]["section_id"]
            section["heading_str"] = get_heading_str(section)
            section["section_str"] = f"Preamble provision {section['id']}"
            section["all_str"] = "\n".join(
                [
                    d["title_str"],
                    section["section_str"],
                    section["heading_str"],
                    section["text"],
                ]
            )
    # Add a list of all sections, including preamble and schedules and subsections
    d["all_chunkable_sections"] = []
    keep_keys = [
        "section_id",
        "parent_id",
        "section_str",
        "heading_str",
        "text",
        "id",
        "marginal_note",
        "in_force_start_date",
        "last_amended_date",
        "internal_refs",
        "external_refs",
        "lims_id",
    ]
    if d["preamble"]:
        # Keep only the keys we need from d["preamble"][0]
        d["all_chunkable_sections"].append(
            {k: v for k, v in d["preamble"][0].items() if k in keep_keys}
        )
        for p in d["preamble"][0]["subsections"]:
            d["all_chunkable_sections"].append(
                {k: v for k, v in p.items() if k in keep_keys}
            )
    for s in d["sections"]:
        d["all_chunkable_sections"].append(
            {k: v for k, v in s.items() if k in keep_keys}
        )
        for ss in s["subsections"]:
            d["all_chunkable_sections"].append(
                {k: v for k, v in ss.items() if k in keep_keys}
            )
    for s in d["schedules"]:
        d["all_chunkable_sections"].append(
            {k: v for k, v in s.items() if k in keep_keys}
        )
    for i, s in enumerate(d["all_chunkable_sections"]):
        s["doc_id"] = d["doc_id"]
        s["doc_title"] = d["title_str"]
        s["index"] = i
        if s["marginal_note"]:
            s["text"] = f"**{s['marginal_note']}**\n{s['text']}"
    return d


def get_heading_str(section):
    # heading_str = ""
    # for i, heading in enumerate(section["headings"]):
    #     heading_str += f"{' ' * (i+2)}{heading}\n"
    # if section["marginal_note"]:
    #     # heading_str += f"{' ' * (len(section['headings'])+2)}{section['marginal_note']}\n"
    #     heading_str += f"\n**{section['marginal_note']}**"
    # return heading_str
    return " > ".join(section["headings"])


def get_section(section):
    # If the section has an ancestor <Schedule> tag, skip it
    if section.xpath(".//Schedule"):
        return None
    return {
        "id": _get_text(section.find(".//Label")),
        "headings": get_headings(section),
        "marginal_note": _get_text(section.find("MarginalNote")),
        "text": _get_joined_text(section),
        "in_force_start_date": section.attrib.get(
            "{http://justice.gc.ca/lims}inforce-start-date", None
        ),
        "last_amended_date": section.attrib.get(
            "{http://justice.gc.ca/lims}lastAmendedDate", None
        ),
        "subsections": [
            get_section(subsection) for subsection in section.findall(".//Subsection")
        ],
        "external_refs": get_external_xrefs(section),
        "internal_refs": get_internal_xrefs(section),
        "lims_id": section.attrib.get("{http://justice.gc.ca/lims}id", None),
    }


def get_external_xrefs(section):
    # External references have an explicit link attribute
    return [
        {
            "link": xref.attrib.get("link", None),
            "reference_type": xref.attrib.get("reference-type", None),
            "text": xref.text,
        }
        for xref in section.findall(".//XRefExternal")
    ]


def get_internal_xrefs(section):
    # Internal references are always a section number which is the text
    return [
        {
            "link": xref.text,
        }
        for xref in section.findall(".//XRefInternal")
    ]


def get_preamble(root):
    # Returns an array with a single element, the preamble, or no elements
    # so that it can be easily prepended to the sections array
    preamble = root.find(".//Preamble")
    if preamble is None:
        return []
    preamble.findall(".//Provision")
    return [
        {
            "id": "preamble",
            "headings": get_headings(preamble),
            "marginal_note": None,
            "text": _get_joined_text(preamble),
            "in_force_start_date": preamble.attrib.get(
                "{http://justice.gc.ca/lims}inforce-start-date", None
            ),
            "last_amended_date": preamble.attrib.get(
                "{http://justice.gc.ca/lims}lastAmendedDate", None
            ),
            "subsections": [
                {
                    "id": i,
                    "text": _get_joined_text(provision),
                    "headings": get_headings(provision),
                    "marginal_note": None,
                    "in_force_start_date": provision.attrib.get(
                        "{http://justice.gc.ca/lims}inforce-start-date", None
                    ),
                    "last_amended_date": provision.attrib.get(
                        "{http://justice.gc.ca/lims}lastAmendedDate", None
                    ),
                    "internal_refs": get_internal_xrefs(provision),
                    "external_refs": get_external_xrefs(provision),
                    "lims_id": provision.attrib.get(
                        "{http://justice.gc.ca/lims}id", None
                    ),
                }
                for i, provision in enumerate(preamble.findall(".//Provision"))
            ],
            "internal_refs": get_internal_xrefs(preamble),
            "external_refs": get_external_xrefs(preamble),
            "lims_id": preamble.attrib.get("{http://justice.gc.ca/lims}id", None),
        }
    ]


def get_schedule(schedule):
    # if schedule "id" attribute is RelatedProvs or NifProvs, skip it
    if schedule.attrib.get("id", None) in ["RelatedProvs", "NifProvs"]:
        return None
    return {
        "id": _get_text(schedule.find(".//Label")),
        "headings": [
            _get_text(schedule.find(".//TitleText")) or "",
        ],
        "marginal_note": _get_text(schedule.find(".//MarginalNote")),
        "text": _get_joined_text(schedule),
        "in_force_start_date": schedule.attrib.get(
            "{http://justice.gc.ca/lims}inforce-start-date", None
        ),
        "last_amended_date": schedule.attrib.get(
            "{http://justice.gc.ca/lims}lastAmendedDate", None
        ),
        "subsections": [],
        "internal_refs": get_internal_xrefs(schedule),
        "external_refs": get_external_xrefs(schedule),
        "originating_ref": _get_text(schedule.find(".//OriginatingRef")),
        "lims_id": schedule.attrib.get("{http://justice.gc.ca/lims}id", None),
    }


def get_headings(element):
    """
    Headings are found in the inner text of <Heading> tags.
    Returns an array of headings, i.e. ["HeadingLevel1", "HeadingLevel2", "HeadingLevel3"]
    In each case (level 1, 2, 3), the returned heading is always the one CLOSEST (i.e. above) the element
    Note that headings are NOT correctly nested in the hierarchy
    They may be siblings to the element etc. We cannot rely on xpath
    """
    # Brute force solution: Traverse document from top to bottom, keeping track of headings until we hit the element
    headings = [None, None, None, None, None, None]  # 6 levels of headings
    root = element.getroottree().getroot()
    for e in root.iter():
        if e.tag == "Heading":
            level = int(e.attrib.get("level", 1))
            headings[level - 1] = _get_joined_text(e)
            # Remove formatting (e.g. bold) from headings
            headings[level - 1] = (
                headings[level - 1].replace("**", "").replace("__", "")
            )
            for i in range(level, 6):
                headings[i] = None
        if e == element:
            break
    return [h for h in headings if h is not None]


from llama_index.core.schema import MetadataMode


class Command(BaseCommand):
    help = "Load laws XML from github"

    def add_arguments(self, parser):
        parser.add_argument(
            "--full", action="store_true", help="Performs a full load of all data"
        )
        parser.add_argument(
            "--small",
            action="store_true",
            help="Only loads the smallest 1 act and 1 regulation",
        )
        parser.add_argument(
            "--const_only",
            action="store_true",
            help="Only loads the constitution",
        )
        parser.add_argument(
            "--reset",
            action="store_true",
            help="Resets the database before loading",
        )
        parser.add_argument(
            "--debug",
            action="store_true",
            help="Write node markdown to source directories. Does not alter database.",
        )
        parser.add_argument(
            "--download",
            action="store_true",
            help="Download the laws-lois-xml repo from github",
        )

    @signalcommand
    def handle(self, *args, **options):
        total_cost = 0
        full = options.get("full", False)
        reset = options.get("reset", False)
        small = options.get("small", False)
        const_only = options.get("const_only", False)
        debug = options.get("debug", False)
        laws_root = os.path.join(os.path.dirname(settings.BASE_DIR), "laws-lois-xml")
        if options.get("download", True):
            _download_repo()
            laws_root = "/tmp/laws-lois-xml-main"
        elif small:
            laws_root = os.path.join(
                os.path.dirname(settings.BASE_DIR),
                "django",
                "tests",
                "laws",
                "xml_sample",
            )
        if full:
            law_ids = []  # All laws will be loaded
        elif small:
            law_ids = [
                "SOR-2010-203",  # Certain Ships Remission Order, 2010 (5kb)
                "S-14.3",  # An Act to grant access to records of the Special Committee on the Defence of Canada Regulations (5kb)
            ]
        else:
            # Subset of legislation, for testing
            law_ids = [
                "A-0.6",  # Accessible Canada Act
                "SOR-2021-241",  # Accessible Canada Regulations
                "A-2",  # Aeronautics Act
                "B-9.01",  # Broadcasting Act
                "SOR-97-555",  # Broadcasting Distribution Regulations
                "SOR-96-433",  # Canadian Aviation Regulations
                "SOR-2011-318",  # Canadian Aviation Security Regulations, 2012
                "C-15.1",  # Canadian Energy Regulator Act
                "C-15.31",  # Canadian Environmental Protection Act, 1999
                "C-24.5",  # Cannabis Act
                "SOR-2018-144",  # Cannabis Regulations
                "C-46",  # Criminal Code
                "SOR-2021-25",  # Cross-border Movement of Hazardous Waste and Hazardous Recyclable Material Regulations
                "F-14",  # Fisheries Act
                "SOR-93-53",  # Fishery (General) Regulations
                "C.R.C.,_c._870",  # Food and Drug Regulations
                "F-27",  # Food and Drugs Act
                "I-2.5",  # Immigration and Refugee Protection Act
                "SOR-2002-227",  # Immigration and Refugee Protection Regulations
                "I-21",  # Interpretation Act
                "SOR-2016-151",  # Multi-Sector Air Pollutants Regulations
                "SOR-2010-189",  # Renewable Fuels Regulations
                "S-22",  # Statutory Instruments Act
                "C.R.C.,_c._1509",  # Statutory Instruments Regulations
                "A-1",  # Access to Information Act
                "F-11",  # Financial Administration Act
                "N-22",  # Canadian Navigable Waters Act
            ]

        file_paths = _get_law_file_paths(laws_root, law_ids)
        # Create constitution file paths
        constitution_dir = os.path.join(settings.BASE_DIR, "laws", "data")
        constitution_file_paths = [
            os.path.join(constitution_dir, "Constitution 2020_E.xml"),
            os.path.join(constitution_dir, "Constitution 2020_F_Rapport.xml"),
        ]
        if const_only:
            file_paths = constitution_file_paths
        elif not small:
            file_paths += constitution_file_paths
        total_file_size = sum([os.path.getsize(file_path) for file_path in file_paths])
        file_size_so_far = 0
        empty_count = 0
        exist_count = 0
        error_count = 0
        added_count = 0

        # Reset the Django and LlamaIndex tables
        if reset:
            Law.reset()

        xslt_path = os.path.join(laws_root, "xslt", "LIMS2HTML.xsl")

        start_time = time.time()

        for i, file_path in enumerate(file_paths):
            # Get the directory path of the XML file
            directory = os.path.dirname(file_path)
            # Get the base name of the XML file
            base_name = os.path.basename(file_path)
            # Construct the output HTML file path
            html_file_path = os.path.join(
                directory, "html", f"{os.path.splitext(base_name)[0]}.html"
            )
            print(f"Processing file {i+1}/{len(file_paths)}: {base_name}")
            file_size_so_far += os.path.getsize(file_path)
            # Use xsltproc to render the XML to HTML
            # os.system(f"xsltproc -o {html_file_path} {xslt_path} {file_path}")

            # Create nodes from XML
            node_dict = law_xml_to_nodes(file_path)
            if not node_dict["nodes"]:
                print("No nodes found in this document.")
                empty_count += 1
                continue
            doc_metadata = {
                "id": node_dict["id"],
                "lang": node_dict["lang"],
                "filename": node_dict["filename"],
                "type": node_dict["type"],
                "short_title": node_dict["short_title"],
                "long_title": node_dict["long_title"],
                "bill_number": node_dict["bill_number"],
                "instrument_number": node_dict["instrument_number"],
                "consolidated_number": node_dict["consolidated_number"],
                "last_amended_date": node_dict["last_amended_date"],
                "current_date": node_dict["current_date"],
                "enabling_authority": node_dict["enabling_authority"],
                "node_type": "document",
            }
            if file_path in constitution_file_paths:
                # This is used as a reference in other Acts/Regulations
                doc_metadata["consolidated_number"] = "Const"
                # The date metadata in these files is missing
                # Last amendment reference I can find in the document
                doc_metadata["last_amended_date"] = "2011-12-16"
                # Date this script was written
                doc_metadata["current_date"] = "2024-05-23"
                doc_metadata["type"] = "act"

            exclude_keys = list(doc_metadata.keys())
            doc_metadata["display_metadata"] = (
                f'{doc_metadata["short_title"] or ""}'
                f'{": " if doc_metadata["short_title"] and doc_metadata["long_title"] else ""}'
                f'{doc_metadata["long_title"] or ""} '
                f'({doc_metadata["consolidated_number"] or doc_metadata["instrument_number"] or doc_metadata["bill_number"]})'
            )

            document = Document(
                text="",
                metadata=doc_metadata,
                excluded_llm_metadata_keys=exclude_keys,
                excluded_embed_metadata_keys=exclude_keys,
                metadata_template="{value}",
                text_template="{metadata_str}",
            )
            document.doc_id = f'{node_dict["id"]}_{node_dict["lang"]}'

            nodes = node_dict["nodes"]
            for i, node in enumerate(nodes):
                node.id_ = node.metadata["section_id"]
                if node.metadata["parent_id"] is not None:
                    node.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(
                        node_id=node.metadata["parent_id"]
                    )
                node.relationships[NodeRelationship.SOURCE] = RelatedNodeInfo(
                    node_id=document.doc_id
                )
            # Set prev/next relationships
            for i in range(len(nodes) - 1):
                nodes[i].relationships[NodeRelationship.NEXT] = RelatedNodeInfo(
                    node_id=nodes[i + 1].node_id
                )
                nodes[i + 1].relationships[NodeRelationship.PREVIOUS] = RelatedNodeInfo(
                    node_id=nodes[i].node_id
                )

            # Write text files of nodes (for debugging purposes)
            if debug:
                nodes_file_path = os.path.join(
                    directory, "nodes", f"{os.path.splitext(base_name)[0]}.md"
                )
                # Create the /nodes directory if it doesn't exist
                if not os.path.exists(os.path.dirname(nodes_file_path)):
                    os.makedirs(os.path.dirname(nodes_file_path))
                with open(nodes_file_path, "w") as f:
                    f.write(
                        f"{document.get_content(metadata_mode=MetadataMode.LLM)}\n\n---\n\n"
                    )
                    for node in nodes:
                        f.write(
                            f"{node.get_content(metadata_mode=MetadataMode.LLM)}\n\n---\n\n"
                        )

            # Nodes and document should be ready now! Let's add to our Django model
            # This will also handle the creation of LlamaIndex vector tables
            else:
                try:
                    print(
                        f"Adding to database: {document.metadata['display_metadata']}"
                    )
                    Law.objects.from_doc_and_nodes(
                        document, nodes, add_to_vector_store=True
                    )
                    embedding_cost = _price_tokens(token_counter)
                    token_counter.reset_counts()
                    total_cost += embedding_cost
                    added_count += 1
                except Exception as e:
                    print(f"Error processing: {document.metadata['display_metadata']}")
                    print(e, "\n")
                    if "Law with this Node id already exists" in str(e):
                        exist_count += 1
                    else:
                        error_count += 1
                    continue
                embedding_cost = 0
                est_time_left_seconds = (
                    (time.time() - start_time) / file_size_so_far
                ) * (total_file_size - file_size_so_far)
                # Format as HH:MM:SS
                est_time_left = (
                    str(datetime.utcfromtimestamp(est_time_left_seconds))
                    .split(" ")[1]
                    .split(".")[0]
                )
                time_so_far = (
                    str(datetime.utcfromtimestamp(time.time() - start_time))
                    .split(" ")[1]
                    .split(".")[0]
                )
                print(
                    f"Added: {added_count}; Already exists: {exist_count}; Empty laws: {empty_count}; Errors: {error_count}\n"
                    f"Document cost: ${embedding_cost:.2f}; "
                    f"Cost so far: ${total_cost:.2f}; "
                    f"Estimated total: ${(total_cost/file_size_so_far) * total_file_size:.2f}\n"
                    f"Time so far / estimated time left: {time_so_far} / {est_time_left}\n"
                )

        if options.get("download", False) and not small:
            # Clean up the downloaded repo
            shutil.rmtree(laws_root)
        print("Done!")
        print(
            f"Added: {added_count}; Already exists: {exist_count}; Empty laws: {empty_count}; Errors: {error_count}"
        )



=== Contents of django\laws\migrations\__init__.py ===



=== Contents of django\laws\migrations\0001_initial.py ===
# Generated by Django 5.0.7 on 2024-07-25 20:33

from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = []

    operations = [
        migrations.CreateModel(
            name="Law",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("title", models.TextField()),
                ("short_title", models.TextField(blank=True, null=True)),
                ("long_title", models.TextField(blank=True, null=True)),
                ("ref_number", models.CharField(max_length=255)),
                ("law_id", models.CharField(max_length=255)),
                ("lang", models.CharField(default="eng", max_length=10)),
                ("type", models.CharField(default="act", max_length=255)),
                ("last_amended_date", models.DateField(null=True)),
                ("current_date", models.DateField(null=True)),
                (
                    "enabling_authority",
                    models.CharField(blank=True, max_length=255, null=True),
                ),
                ("node_id", models.CharField(max_length=255, unique=True)),
            ],
        ),
    ]



=== Contents of django\librarian\__init__.py ===



=== Contents of django\librarian\admin.py ===
from django.contrib import admin

from .models import DataSource, Document, Library

admin.site.register(Library)
admin.site.register(DataSource)
admin.site.register(Document)



=== Contents of django\librarian\apps.py ===
from django.apps import AppConfig


class LibrarianConfig(AppConfig):
    default_auto_field = "django.db.models.BigAutoField"
    name = "librarian"



=== Contents of django\librarian\forms.py ===
from django import forms
from django.contrib.auth import get_user_model
from django.utils.translation import gettext_lazy as _

from autocomplete import widgets

from librarian.models import DataSource, Document, Library, LibraryUserRole

User = get_user_model()


class LibraryDetailForm(forms.ModelForm):
    template_name = "librarian/forms/library.html"

    def __init__(self, *args, **kwargs):
        self.user = kwargs.pop("user", None)
        super(LibraryDetailForm, self).__init__(*args, **kwargs)
        # A library can only be made public if it has an id (it is an existing library)
        # and the user has the change_publicity permission.
        self.can_make_public = self.user and self.user.has_perm(
            "librarian.change_publicity", self.instance
        )
        # If not, hide the is_public field
        if not self.can_make_public:
            self.fields.pop("is_public")
        else:
            # If the initial value of is_public is False, add an onclick property
            # to the is_public field to show the warning message
            if not self.instance.is_public:
                self.fields["is_public"].widget.attrs[
                    "onclick"
                ] = "toggleWarning(this);"
        # If an existing library, check if user has permissions to delete this library
        self.deletable = self.instance.pk and self.user.has_perm(
            "librarian.delete_library", self.instance
        )

    class Meta:
        model = Library
        fields = [
            "name_en",
            "name_fr",
            "description_en",
            "description_fr",
            "order",
            "is_public", 
        ]
        widgets = {
            "name_en": forms.TextInput(attrs={"class": "form-control form-control-sm"}),
            "name_fr": forms.TextInput(attrs={"class": "form-control form-control-sm"}),
            "description_en": forms.Textarea(
                attrs={"class": "form-control form-control-sm", "rows": 2}
            ),
            "description_fr": forms.Textarea(
                attrs={"class": "form-control form-control-sm", "rows": 2}
            ),
            "order": forms.NumberInput(attrs={"class": "form-control form-control-sm"}),
            # AC-21: Add a checkbox to make the library public
            "is_public": forms.CheckboxInput(attrs={"class": "form-check-input"}),
        }

    def save(self, commit=True):
        is_new = not self.instance.pk
        instance = super(LibraryDetailForm, self).save(commit=commit)
        if is_new:
            # Add the user as a library admin role
            LibraryUserRole.objects.create(
                library=instance, user=self.user, role="admin"
            )
            instance.reset()
        return instance


class DataSourceDetailForm(forms.ModelForm):
    template_name = "librarian/forms/data_source.html"

    def __init__(self, *args, **kwargs):
        self.library_id = kwargs.pop("library_id", None)
        super(DataSourceDetailForm, self).__init__(*args, **kwargs)
        if self.library_id:
            self.fields["library"].initial = self.library_id

    class Meta:
        model = DataSource
        fields = ["name_en", "name_fr", "security_label", "order", "library"]
        widgets = {
            "library": forms.HiddenInput(),
            "name_en": forms.TextInput(attrs={"class": "form-control form-control-sm"}),
            "name_fr": forms.TextInput(attrs={"class": "form-control form-control-sm"}),
            "security_label": forms.Select(
                attrs={"class": "form-select form-select-sm"}
            ),
            "order": forms.NumberInput(attrs={"class": "form-control form-control-sm"}),
        }


class DocumentDetailForm(forms.ModelForm):
    template_name = "librarian/forms/document.html"

    def __init__(self, *args, **kwargs):
        self.data_source_id = kwargs.pop("data_source_id", None)
        super(DocumentDetailForm, self).__init__(*args, **kwargs)
        if self.data_source_id:
            self.fields["data_source"].initial = self.data_source_id
        # If there is a filename, hide the url and selector fields
        if self.instance.filename:
            self.fields.pop("url")
            self.fields.pop("selector")

    class Meta:
        model = Document
        fields = ["manual_title", "url", "selector", "data_source", "filename"]
        widgets = {
            "data_source": forms.HiddenInput(),
            "filename": forms.HiddenInput(),
            "manual_title": forms.TextInput(
                attrs={"class": "form-control form-control-sm"}
            ),
            "url": forms.TextInput(attrs={"class": "form-control form-control-sm"}),
            "selector": forms.TextInput(
                attrs={"class": "form-control form-control-sm"}
            ),
        }


class LibraryUsersForm(forms.Form):
    template_name = "librarian/forms/library_users.html"

    admins = forms.ModelMultipleChoiceField(
        queryset=User.objects.all(),
        label=_("Administrators (edit library and manage users)"),
        required=True,
        widget=widgets.Autocomplete(
            name="admins",
            options={
                "item_value": User.id,
                "item_label": User.email,
                "multiselect": True,
                "minimum_search_length": 2,
                "model": User,
            },
        ),
    )
    contributors = forms.ModelMultipleChoiceField(
        queryset=User.objects.all(),
        label=_("Contributors (edit library)"),
        required=False,
        widget=widgets.Autocomplete(
            name="contributors",
            options={
                "item_value": User.id,
                "item_label": User.email,
                "multiselect": True,
                "minimum_search_length": 2,
                "model": User,
            },
        ),
    )
    viewers = forms.ModelMultipleChoiceField(
        queryset=User.objects.all(),
        label=_("Viewers (read-only access)"),
        required=False,
        widget=widgets.Autocomplete(
            name="viewers",
            options={
                "item_value": User.id,
                "item_label": User.email,
                "multiselect": True,
                "minimum_search_length": 2,
                "model": User,
            },
        ),
    )

    def __init__(self, *args, **kwargs):
        self.library = kwargs.pop("library", None)
        super(LibraryUsersForm, self).__init__(*args, **kwargs)
        self.fields["admins"].initial = self.library.admins
        self.fields["contributors"].initial = self.library.contributors
        self.fields["viewers"].initial = self.library.viewers

    def save(self):
        self.library.user_roles.all().delete()

        for user in self.cleaned_data["admins"]:
            LibraryUserRole.objects.create(
                library=self.library, user=user, role="admin"
            )
        for user in self.cleaned_data["contributors"]:
            LibraryUserRole.objects.create(
                library=self.library, user=user, role="contributor"
            )
        for user in self.cleaned_data["viewers"]:
            LibraryUserRole.objects.create(
                library=self.library, user=user, role="viewer"
            )

    # Override clean function to check if the same user is in multiple roles
    def clean(self):
        cleaned_data = super(LibraryUsersForm, self).clean()
        user_roles_list = []
        user_roles_set = set()
        for role in ["admins", "contributors", "viewers"]:
            for user in cleaned_data[role]:
                user_roles_list.append(user)
                user_roles_set.add(user)
        if len(user_roles_list) != len(user_roles_set):
            raise forms.ValidationError(_("The same user cannot be in multiple roles."))
        return cleaned_data



=== Contents of django\librarian\models.py ===
import hashlib
import uuid

from django.conf import settings
from django.core.exceptions import ValidationError
from django.db import models, transaction
from django.template.loader import render_to_string
from django.utils import timezone
from django.utils.translation import get_language
from django.utils.translation import gettext_lazy as _

from celery.result import AsyncResult
from sqlalchemy import create_engine, text
from sqlalchemy.engine import reflection
from sqlalchemy.orm import sessionmaker
from structlog import get_logger
from structlog.contextvars import bind_contextvars

from chat.llm import OttoLLM
from otto.models import SecurityLabel, User
from otto.utils.common import display_cad_cost, set_costs

logger = get_logger(__name__)
llm = OttoLLM()

STATUS_CHOICES = [
    ("PENDING", "Not started"),
    ("INIT", "Starting..."),
    ("PROCESSING", "Processing..."),
    ("SUCCESS", "Success"),
    ("ERROR", "Error"),
    ("BLOCKED", "Stopped"),
]


def generate_uuid_hex():
    # We use the hex for compatibility with LlamaIndex table names
    # (Can't have dashes)
    return uuid.uuid4().hex


class LibraryManager(models.Manager):
    def get_default_library(self):
        try:
            return self.get_queryset().get(is_default_library=True)
        except Library.DoesNotExist:
            logger.error("Default 'Corporate' library not found")
            return None

    def reset_vector_store(self):
        db = settings.DATABASES["vector_db"]
        connection_string = f"postgresql+psycopg2://{db['USER']}:{db['PASSWORD']}@{db['HOST']}:5432/{db['NAME']}"

        engine = create_engine(connection_string)
        Session = sessionmaker(bind=engine)
        session = Session()

        metadata = reflection.Inspector.from_engine(engine)

        for table_name in metadata.get_table_names():
            session.execute(text(f"DROP TABLE IF EXISTS {table_name} CASCADE"))

        session.commit()
        session.close()

    def create(self, *args, **kwargs):
        library = super().create(*args, **kwargs)
        library.reset()
        return library


class Library(models.Model):
    # Same as vector store table name
    uuid_hex = models.CharField(
        default=generate_uuid_hex, editable=False, unique=True, max_length=32
    )
    objects = LibraryManager()

    # Named libraries will show in a list; unnamed libraries are bound to a chat
    name = models.CharField(max_length=255, null=True, blank=True)
    description = models.TextField(null=True, blank=True)

    created_at = models.DateTimeField(auto_now_add=True)
    created_by = models.ForeignKey(
        User, on_delete=models.SET_NULL, null=True, blank=True
    )
    modified_at = models.DateTimeField(auto_now=True)
    # Last access time manually updated when library is queried through Library Q&A
    accessed_at = models.DateTimeField(auto_now_add=True)

    chat = models.OneToOneField(
        "chat.Chat", on_delete=models.CASCADE, null=True, blank=True
    )
    order = models.IntegerField(default=0)
    is_public = models.BooleanField(default=False)
    is_default_library = models.BooleanField(default=False)

    class Meta:
        ordering = ["-is_public", "order", "name"]
        verbose_name_plural = "Libraries"

    def clean(self):
        self._validate_public_library()
        # Ensure that there is at most 1 default library
        if (
            self.is_default_library
            and Library.objects.filter(is_default_library=True)
            .exclude(pk=self.pk)
            .exists()
        ):
            raise ValidationError("There can be only one default library")
        super().clean()

    def _validate_public_library(self):
        if self.is_public and not self.name:
            raise ValidationError("Public libraries must have a name")
        if self.is_public and (
            Library.objects.filter(is_public=True, name=self.name)
            .exclude(pk=self.pk)
            .exists()
        ):
            raise ValidationError("A public library with this name already exists")

    def save(self, *args, **kwargs):
        self.clean()
        super().save(*args, **kwargs)

    def access(self):
        self.accessed_at = timezone.now()
        self.save()

    def __str__(self):
        return self.name or "Untitled library"

    @transaction.atomic
    def delete(self, *args, **kwargs):
        self.reset(recreate=False)
        super().delete(*args, **kwargs)

    def process_all(
        self,
        force=True,
    ):
        for ds in self.data_sources.all():
            for document in ds.documents.all():
                document.process()

    def reset(self, recreate=True):
        db = settings.DATABASES["vector_db"]
        connection_string = f"postgresql+psycopg2://{db['USER']}:{db['PASSWORD']}@{db['HOST']}:5432/{db['NAME']}"

        engine = create_engine(connection_string)
        Session = sessionmaker(bind=engine)
        session = Session()
        session.execute(text(f"DROP TABLE IF EXISTS data_{self.uuid_hex} CASCADE"))
        session.commit()
        session.close()
        if recreate:
            # This will create the vector store table
            llm.get_retriever(self.uuid_hex).retrieve("?")

    @property
    def sorted_data_sources(self):
        return self.data_sources.all()

    @property
    def security_label(self):
        return SecurityLabel.maximum_of(
            self.data_sources.values_list("security_label__acronym", flat=True)
        )

    @property
    def admins(self):
        return self.user_roles.filter(role="admin").values_list("user", flat=True)

    @property
    def contributors(self):
        return self.user_roles.filter(role="contributor").values_list("user", flat=True)

    @property
    def viewers(self):
        return self.user_roles.filter(role="viewer").values_list("user", flat=True)


# AC-20: Allows for fine-grained control over who can access and manage information sources
class LibraryUserRole(models.Model):
    """
    Represents a user's role in a library.
    """

    # AC-21: Allows for the assignment of different roles to users
    ROLE_CHOICES = [
        ("admin", "Admin"),
        ("contributor", "Contributor"),
        ("viewer", "Viewer"),
    ]

    library = models.ForeignKey(
        Library, on_delete=models.CASCADE, related_name="user_roles"
    )
    user = models.ForeignKey(User, on_delete=models.CASCADE)
    role = models.CharField(max_length=20, choices=ROLE_CHOICES)

    class Meta:
        unique_together = ["library", "user"]

    def __str__(self):
        return f"{self.user} in {self.library}: {self.role}"


class DataSourceManager(models.Manager):
    def create(self, *args, **kwargs):
        # Set the security label default to "UC" (unclassified)

        # We do this instead of setting a default value on 'security_label' because
        # this is a reference to an instance of the SecurityLabel model which
        # may not exist at migration time
        kwargs["security_label_id"] = SecurityLabel.default_security_label().id
        return super().create(*args, **kwargs)


class DataSource(models.Model):
    """
    Represents sub-library "collection" of documents.
    """

    # UUID is used for filtering in the vector store
    uuid_hex = models.CharField(
        default=generate_uuid_hex, editable=False, unique=True, max_length=32
    )
    objects = DataSourceManager()
    name = models.CharField(max_length=255)
    library = models.ForeignKey(
        Library, on_delete=models.CASCADE, related_name="data_sources"
    )
    created_at = models.DateTimeField(auto_now_add=True)
    modified_at = models.DateTimeField(auto_now=True)
    order = models.IntegerField(default=0)

    # AC-21: Allow users to categorize sensitive information
    security_label = models.ForeignKey(
        SecurityLabel,
        on_delete=models.SET_NULL,
        null=True,
    )

    class Meta:
        ordering = ["order", "name"]

    def __str__(self):
        return self.name

    def delete(self):
        for document in self.documents.all():
            document.delete()
        super().delete()

    def process_all(self, force=True):
        for document in self.documents.all():
            document.process()


class Document(models.Model):
    """
    Result of a WebCrawl or direct upload.
    """

    class Meta:
        ordering = ["-created_at"]

    uuid_hex = models.CharField(
        default=generate_uuid_hex, editable=False, unique=True, max_length=32
    )
    sha256_hash = models.CharField(max_length=64, null=True, blank=True)
    status = models.CharField(max_length=20, choices=STATUS_CHOICES, default="PENDING")
    celery_task_id = models.CharField(max_length=50, null=True, blank=True)

    created_at = models.DateTimeField(auto_now_add=True)
    modified_at = models.DateTimeField(auto_now=True)
    # Cost includes OpenAI embedding and (in some cases) Azure Document AI costs
    usd_cost = models.DecimalField(max_digits=10, decimal_places=6, default=0)

    # Document always associated with a single DataSource
    data_source = models.ForeignKey(
        DataSource,
        on_delete=models.CASCADE,
        related_name="documents",
    )

    # Extracted title may come from HTML <title>, PDF metadata, etc.
    extracted_title = models.CharField(max_length=255, null=True, blank=True)

    # Last modified time of the document as extracted from the source metadata, etc.
    extracted_modified_at = models.DateTimeField(null=True, blank=True)

    # Generated title and description from LLM
    generated_title = models.CharField(max_length=255, null=True, blank=True)
    generated_description = models.TextField(null=True, blank=True)

    # User-provided citation; has precedence over extracted_title etc.
    manual_title = models.CharField(max_length=255, null=True, blank=True)

    # Not necessary to store permanently in this model; saved in vector DB chunks
    extracted_text = models.TextField(null=True, blank=True)
    num_chunks = models.IntegerField(null=True, blank=True)

    # Specific to URL-based documents
    url = models.URLField(null=True, blank=True)
    selector = models.CharField(max_length=255, null=True, blank=True)
    fetched_at = models.DateTimeField(null=True, blank=True)
    url_content_type = models.CharField(max_length=255, null=True, blank=True)

    # Specific to file-based documents
    file = models.ForeignKey(
        "SavedFile",
        on_delete=models.SET_NULL,
        null=True,
        blank=True,
        related_name="documents",
    )
    # Filename stored here instead of in the File object since one file (hash)
    # may be uploaded under different filenames
    filename = models.CharField(max_length=255, null=True, blank=True)

    def __str__(self):
        return self.name

    @property
    def title(self):
        return self.manual_title or self.extracted_title or self.generated_title or None

    @property
    def name(self):
        return self.title or self.filename or self.url or "Untitled document"

    @property
    def celery_status_message(self):
        if self.celery_task_id:
            try:
                result = AsyncResult(self.celery_task_id)
                return result.info.get("status_text", "Processing...")
            except Exception as e:
                self.celery_task_id = None
                self.status = "ERROR"
                self.save()
            return "Error"
        return None

    @property
    def citation(self):
        return render_to_string(
            "librarian/components/document_citation.html", {"document": self}
        )

    @property
    def href(self):
        return render_to_string(
            "librarian/components/document_href.html", {"document": self}
        )

    @property
    def truncated_text(self):
        if self.extracted_text:
            truncated_text = self.extracted_text[:500]
            if len(self.extracted_text) > 500:
                truncated_text += "..."
            return truncated_text
        return ""

    @property
    def display_cost(self):
        return display_cad_cost(self.usd_cost)

    @property
    def content_type(self):
        if self.file:
            return self.file.content_type
        else:
            return self.url_content_type

    def remove_from_vector_store(self):
        idx = llm.get_index(self.data_source.library.uuid_hex)
        idx.delete_ref_doc(self.uuid_hex, delete_from_docstore=True)

    def delete(self, *args, **kwargs):
        logger.info(f"Deleting document {str(self)} from vector store.")
        try:
            self.remove_from_vector_store()
        except Exception as e:
            logger.error(f"Failed to remove document from vector store: {e}")
        super().delete(*args, **kwargs)

    def process(self):
        from .tasks import process_document

        bind_contextvars(document_id=self.id)

        # Logic for updating the document embeddings, metadata, etc.
        if not (self.file or self.url):
            self.status = "ERROR"
            self.save()
            return
        process_document.delay(self.id, get_language())
        self.celery_task_id = "tbd"
        self.status = "INIT"
        self.save()

    def stop(self):
        if self.celery_task_id:
            try:
                AsyncResult(self.celery_task_id).revoke(terminate=True)
            except Exception as e:
                logger.error(f"Failed to stop document processing task: {e}")
        self.celery_task_id = None
        self.status = "BLOCKED"
        self.save()

    def calculate_costs(self):
        set_costs(self)


class SavedFile(models.Model):
    """
    Represents a file uploaded by the user.
    This object is referenced by 0..* Document or ChatFile objects.
    """

    sha256_hash = models.CharField(max_length=64, null=True, blank=True, db_index=True)
    file = models.FileField(upload_to="files/%Y/%m/%d/")
    content_type = models.CharField(max_length=255, blank=True)
    created_at = models.DateTimeField(auto_now_add=True)
    eof = models.BooleanField(default=True)

    def __str__(self):
        return self.file.name

    def generate_hash(self):
        if self.file:
            with self.file.open("rb") as f:
                sha256 = hashlib.sha256(f.read())
                self.sha256_hash = sha256.hexdigest()
                self.save()



=== Contents of django\librarian\tasks.py ===
import time
import urllib.parse
from datetime import datetime

from django.utils import translation
from django.utils.translation import gettext as _

from celery import current_task, shared_task
from celery.exceptions import SoftTimeLimitExceeded
from structlog import get_logger
from tqdm import tqdm

from chat.llm import OttoLLM
from librarian.models import Document
from librarian.utils.process_engine import (
    create_nodes,
    extract_html_metadata,
    extract_markdown,
    fetch_from_url,
    get_process_engine_from_type,
)
from otto.models import User

logger = get_logger(__name__)

ten_minutes = 600


@shared_task(soft_time_limit=ten_minutes)
def process_document(document_id, language=None):
    """
    Process a URL and save the content to a document.
    """
    if language is None:
        language = translation.get_language()
    try:
        document = Document.objects.get(id=document_id)
    except Document.DoesNotExist:
        logger.error("Document not found", document_id=document_id)
        return
    document.status = "PROCESSING"
    document.celery_task_id = current_task.request.id
    document.save()

    llm = OttoLLM()
    try:
        with translation.override(language):
            process_document_helper(document, llm)

    except SoftTimeLimitExceeded:
        document.status = "ERROR"
        document.celery_task_id = None
        document.save()

    llm.create_costs()


def process_document_helper(document, llm):
    url = document.url
    file = document.file
    if not (url or file):
        raise ValueError("URL or file is required")

    if url:
        logger.info("Processing URL", url=url)
        base_url = (
            urllib.parse.urlparse(url).scheme
            + "://"
            + urllib.parse.urlparse(url).netloc
        )
        current_task.update_state(
            state="PROCESSING",
            meta={
                "status_text": _("Fetching URL..."),
            },
        )
        content, content_type = fetch_from_url(url)
        document.url_content_type = content_type
    else:
        logger.info("Processing file", file=file)
        base_url = None
        current_task.update_state(
            state="PROCESSING",
            meta={
                "status_text": _("Reading file..."),
            },
        )
        content = file.file.read()
        content_type = file.content_type

    current_task.update_state(
        state="PROCESSING",
        meta={
            "status_text": _("Extracting text..."),
        },
    )
    process_engine = get_process_engine_from_type(content_type)
    if process_engine == "HTML":
        extracted_metadata = extract_html_metadata(content)
        for key, value in extracted_metadata.items():
            setattr(document, key, value)

    document.extracted_text, chunks = extract_markdown(
        content,
        process_engine,
        fast=True,
        base_url=base_url,
        selector=document.selector,
    )
    num_chunks = len(chunks)
    document.num_chunks = num_chunks
    document.save()

    current_task.update_state(
        state="PROCESSING",
        meta={
            "status_text": _("Adding to library..."),
        },
    )
    nodes = create_nodes(chunks, document)

    library_uuid = document.data_source.library.uuid_hex
    vector_store_index = llm.get_index(library_uuid)
    # Delete existing nodes
    document_uuid = document.uuid_hex
    vector_store_index.delete_ref_doc(document_uuid, delete_from_docstore=True)
    # Insert new nodes in batches
    batch_size = 16
    for i in tqdm(range(0, len(nodes), batch_size)):
        if i > 0:
            percent_complete = i / len(nodes) * 100
            current_task.update_state(
                state="PROCESSING",
                meta={
                    "status_text": f"{_('Adding to library...')} ({int(percent_complete)}% {_('done')})",
                },
            )
        # Exponential backoff retry
        for j in range(3, 12):
            try:
                vector_store_index.insert_nodes(nodes[i : i + batch_size])
                break
            except Exception as e:
                print(f"Error inserting nodes: {e}")
                print("Retrying...")
                time.sleep(2**j)

    # Done!
    document.status = "SUCCESS"
    document.fetched_at = datetime.now()
    document.celery_task_id = None
    document.save()



=== Contents of django\librarian\translation.py ===
from modeltranslation.translator import TranslationOptions, register

from .models import DataSource, Library


@register(Library)
class LibraryTranslationOptions(TranslationOptions):
    fields = ("name", "description")


@register(DataSource)
class DataSourceTranslationOptions(TranslationOptions):
    fields = ("name",)



=== Contents of django\librarian\urls.py ===
from django.urls import path

from librarian.views import (
    document_start,
    document_stop,
    download_document,
    modal_create_data_source,
    modal_create_document,
    modal_create_library,
    modal_delete_data_source,
    modal_delete_document,
    modal_delete_library,
    modal_edit_data_source,
    modal_edit_document,
    modal_edit_library,
    modal_library_list,
    modal_manage_library_users,
    poll_status,
    upload,
)

app_name = "librarian"
urlpatterns = [
    path("modal/", modal_library_list, name="modal"),
    path("modal/library/create/", modal_create_library, name="modal_create_library"),
    path(
        "modal/library/<int:library_id>/edit/",
        modal_edit_library,
        name="modal_edit_library",
    ),
    path(
        "modal/library/<int:library_id>/delete/",
        modal_delete_library,
        name="modal_delete_library",
    ),
    path(
        "modal/library/<int:library_id>/users/",
        modal_manage_library_users,
        name="modal_manage_library_users",
    ),
    path(
        "modal/library/<int:library_id>/data_source/create/",
        modal_create_data_source,
        name="modal_create_data_source",
    ),
    path(
        "modal/data_source/<int:data_source_id>/edit/",
        modal_edit_data_source,
        name="modal_edit_data_source",
    ),
    path(
        "modal/data_source/<int:data_source_id>/delete/",
        modal_delete_data_source,
        name="modal_delete_data_source",
    ),
    path(
        "modal/data_source/<int:data_source_id>/document/create/",
        modal_create_document,
        name="modal_create_document",
    ),
    path(
        "modal/document/<int:document_id>/edit/",
        modal_edit_document,
        name="modal_edit_document",
    ),
    path(
        "modal/document/<int:document_id>/delete/",
        modal_delete_document,
        name="modal_delete_document",
    ),
    # Polling for status updates
    path(
        "modal/data_source/<int:data_source_id>/status/",
        poll_status,
        name="data_source_status",
    ),
    path(
        "modal/data_source/<int:data_source_id>/document/<int:document_id>/status/",
        poll_status,
        name="document_status",
    ),
    # Document upload and processing
    path("modal/upload/to/<int:data_source_id>/", upload, name="upload"),
    path("document/<int:document_id>/start/", document_start, name="document_start"),
    path("document/<int:document_id>/stop/", document_stop, name="document_stop"),
    path(
        "document/<int:document_id>/download/",
        download_document,
        name="download_document",
    ),
]



=== Contents of django\librarian\views.py ===
# views.py
from dataclasses import dataclass

from django.contrib import messages
from django.http import HttpResponse
from django.shortcuts import get_object_or_404, render
from django.urls import reverse
from django.utils.translation import gettext as _

from rules.contrib.views import objectgetter
from structlog import get_logger
from structlog.contextvars import bind_contextvars

from otto.utils.decorators import permission_required

from .forms import (
    DataSourceDetailForm,
    DocumentDetailForm,
    LibraryDetailForm,
    LibraryUsersForm,
)
from .models import DataSource, Document, Library, SavedFile

logger = get_logger(__name__)


def get_editable_libraries(user):
    return [
        library
        for library in Library.objects.filter(chat=None)
        if user.has_perm("librarian.edit_library", library)
    ]


# AC-20: Implements role-based access control for interacting with data sources
def modal_view(request, item_type=None, item_id=None, parent_id=None):
    """
    !!! This is not to be called directly, but rather through the wrapper functions
        which implement permission checking (see below) !!!

    This _beastly_ function handles almost all actions in the "Edit libraries" modal.

    This includes the initial view (no library selected), and the subsequent views for
    editing a library, data source, or document; creating each of the same; including
    GET, POST, and DELETE requests. It also handles library user management.

    The modal is updated with the new content after each request.
    When a data source is visible that contains in-progress documents, the modal will
    poll for updates until all documents are processed or stopped.
    """
    bind_contextvars(feature="librarian")

    libraries = get_editable_libraries(request.user)
    selected_library = None
    data_sources = None
    selected_data_source = None
    documents = None
    selected_document = None
    form = None
    users_form = None
    show_document_status = False
    focus_el = None

    if item_type == "document":
        if request.method == "POST":
            document = Document.objects.get(id=item_id) if item_id else None
            form = DocumentDetailForm(request.POST, instance=document)
            if form.is_valid():
                form.save()
                messages.success(
                    request,
                    (
                        _("Document updated successfully.")
                        if item_id
                        else _("Document created successfully.")
                    ),
                )
                if not item_id:
                    form.instance.process()
                selected_document = form.instance
                selected_data_source = selected_document.data_source
                item_id = selected_document.id
                show_document_status = True
            else:
                logger.error("Error updating document:", errors=form.errors)
                selected_data_source = get_object_or_404(DataSource, id=parent_id)
        elif request.method == "DELETE":
            if item_id == 1:
                return HttpResponse(status=400)
            document = get_object_or_404(Document, id=item_id)
            document.delete()
            messages.success(request, _("Document deleted successfully."))
            selected_data_source = document.data_source
        else:
            if item_id:
                selected_document = get_object_or_404(Document, id=item_id)
                selected_data_source = selected_document.data_source
                show_document_status = True
            else:
                selected_data_source = get_object_or_404(DataSource, id=parent_id)
        documents = list(selected_data_source.documents.all())
        selected_library = selected_data_source.library
        data_sources = selected_library.data_sources.all()
        if not item_id and not request.method == "DELETE":
            new_document = create_temp_object("document")
            documents.insert(0, new_document)
            selected_document = new_document
            focus_el = "#id_url"
        if not request.method == "DELETE":
            form = form or DocumentDetailForm(
                instance=selected_document if item_id else None,
                data_source_id=parent_id,
            )

    if item_type == "data_source":
        if request.method == "POST":
            data_source = DataSource.objects.get(id=item_id) if item_id else None
            form = DataSourceDetailForm(
                request.POST,
                instance=data_source,
            )
            if form.is_valid():
                form.save()
                messages.success(
                    request,
                    (
                        _("Data source updated successfully.")
                        if item_id
                        else _("Data source created successfully.")
                    ),
                )
                selected_data_source = form.instance
                item_id = selected_data_source.id
                selected_library = selected_data_source.library
                documents = selected_data_source.documents.all()
            else:
                logger.error("Error updating data source:", errors=form.errors)
                selected_library = get_object_or_404(Library, id=parent_id)
        elif request.method == "DELETE":
            data_source = get_object_or_404(DataSource, id=item_id)
            data_source.delete()
            messages.success(request, _("Data source deleted successfully."))
            selected_library = data_source.library
            data_sources = selected_library.data_sources.all()
        else:
            if item_id:
                selected_data_source = get_object_or_404(DataSource, id=item_id)
                selected_library = selected_data_source.library
                documents = selected_data_source.documents.all()
            else:
                selected_library = get_object_or_404(Library, id=parent_id)
        data_sources = list(selected_library.data_sources.all())
        if not item_id and not request.method == "DELETE":
            new_data_source = create_temp_object("data_source")
            data_sources.insert(0, new_data_source)
            selected_data_source = new_data_source
            focus_el = "#id_name_en"
        if not request.method == "DELETE":
            form = form or DataSourceDetailForm(
                instance=selected_data_source if item_id else None,
                library_id=parent_id,
            )

    if item_type == "library":
        if request.method == "POST":
            library = Library.objects.get(id=item_id) if item_id else None
            form = LibraryDetailForm(request.POST, instance=library, user=request.user)
            if form.is_valid():
                form.save()
                messages.success(
                    request,
                    (
                        _("Library updated successfully.")
                        if item_id
                        else _("Library created successfully.")
                    ),
                )
                libraries = get_editable_libraries(request.user)
                selected_library = form.instance
                # Refresh the form so "public" checkbox behaves properly
                form = LibraryDetailForm(instance=selected_library, user=request.user)
                item_id = selected_library.id
                data_sources = selected_library.data_sources.all()
                if request.user.has_perm(
                    "librarian.manage_library_users", selected_library
                ):
                    users_form = LibraryUsersForm(library=selected_library)
            else:
                logger.error("Error updating library:", errors=form.errors)
        elif request.method == "DELETE":
            library = get_object_or_404(Library, id=item_id)
            library.delete()
            messages.success(request, _("Library deleted successfully."))
            libraries = get_editable_libraries(request.user)
        if not request.method == "DELETE":
            if item_id:
                selected_library = get_object_or_404(Library, id=item_id)
                data_sources = selected_library.data_sources.all()
                if request.user.has_perm(
                    "librarian.manage_library_users", selected_library
                ):
                    users_form = LibraryUsersForm(library=selected_library)
            elif not selected_library:
                new_library = create_temp_object("library")
                libraries.insert(0, new_library)
                selected_library = new_library
                focus_el = "#id_name_en"
            form = form or LibraryDetailForm(
                instance=selected_library if item_id else None, user=request.user
            )

    if item_type == "library_users":
        if request.method == "POST":
            selected_library = get_object_or_404(Library, id=item_id)
            users_form = LibraryUsersForm(request.POST, library=selected_library)
            if users_form.is_valid():
                users_form.save()
                messages.success(request, _("Library users updated successfully."))
            else:
                logger.error("Error updating library users:", errors=users_form.errors)
            # The change may have resulted in the user losing access to manage library users
            if not request.user.has_perm(
                "librarian.manage_library_users", selected_library
            ):
                users_form = None
            data_sources = selected_library.data_sources.all()
            form = LibraryDetailForm(instance=selected_library, user=request.user)
        else:
            return HttpResponse(status=405)

    # Poll for updates when a data source is selected that has processing documents
    # (with status "INIT" or "PROCESSING")
    try:
        poll = selected_data_source.documents.filter(
            status__in=["INIT", "PROCESSING"]
        ).exists()
    except:
        poll = False
    # We have to construct the poll URL manually (instead of using request.path)
    # because some views, e.g. document_start, return this view from a different URL
    if poll:
        if selected_document and selected_document.id:
            poll_url = reverse(
                "librarian:document_status",
                kwargs={
                    "document_id": selected_document.id,
                    "data_source_id": selected_data_source.id,
                },
            )
        elif selected_document or (selected_data_source and selected_data_source.id):
            poll_url = reverse(
                "librarian:data_source_status",
                kwargs={"data_source_id": selected_data_source.id},
            )
    else:
        poll_url = None

    context = {
        "libraries": libraries,
        "selected_library": selected_library,
        "data_sources": data_sources,
        "selected_data_source": selected_data_source,
        "documents": documents,
        "selected_document": selected_document,
        "detail_form": form,
        "users_form": users_form,
        "document_status": show_document_status,
        "focus_el": focus_el,
        "poll_url": poll_url,
        "poll_response": "poll" in request.GET,
    }
    return render(request, "librarian/modal_inner.html", context)


@permission_required(
    "librarian.edit_data_source", objectgetter(DataSource, "data_source_id")
)
def poll_status(request, data_source_id, document_id=None):
    """
    Polling view for data source status updates
    Updates the document list in the modal with updated titles / status icons
    """
    documents = Document.objects.filter(data_source_id=data_source_id)
    poll = False
    try:
        poll = documents.filter(status__in=["INIT", "PROCESSING"]).exists()
    except:
        poll = False
    poll_url = request.path if poll else None

    document = Document.objects.get(id=document_id) if document_id else None
    return render(
        request,
        "librarian/components/poll_update.html",
        {"documents": documents, "poll_url": poll_url, "selected_document": document},
    )


def modal_library_list(request):
    return modal_view(request)


def modal_create_library(request):
    if request.method == "POST":
        is_public = "is_public" in request.POST
        if is_public and not request.user.has_perm("librarian.manage_public_libraries"):
            return HttpResponse(status=403)
    return modal_view(request, item_type="library")


@permission_required("librarian.edit_library", objectgetter(Library, "library_id"))
def modal_edit_library(request, library_id):
    if request.method == "POST":
        is_public = "is_public" in request.POST
        if is_public and not request.user.has_perm("librarian.manage_public_libraries"):
            return HttpResponse(status=403)
    return modal_view(request, item_type="library", item_id=library_id)


@permission_required("librarian.delete_library", objectgetter(Library, "library_id"))
def modal_delete_library(request, library_id):
    return modal_view(request, item_type="library", item_id=library_id)


# AC-20: Only authenticated and authorized users can interact with information sources
@permission_required("librarian.edit_library", objectgetter(Library, "library_id"))
def modal_create_data_source(request, library_id):
    return modal_view(request, item_type="data_source", parent_id=library_id)


# AC-20: Only authenticated and authorized users can interact with information sources
@permission_required(
    "librarian.edit_data_source", objectgetter(DataSource, "data_source_id")
)
def modal_edit_data_source(request, data_source_id):
    return modal_view(request, item_type="data_source", item_id=data_source_id)


@permission_required(
    "librarian.delete_data_source", objectgetter(DataSource, "data_source_id")
)
def modal_delete_data_source(request, data_source_id):
    return modal_view(request, item_type="data_source", item_id=data_source_id)


# AC-20: Only authenticated and authorized users can interact with information sources
@permission_required(
    "librarian.edit_data_source", objectgetter(DataSource, "data_source_id")
)
def modal_create_document(request, data_source_id):
    return modal_view(request, item_type="document", parent_id=data_source_id)


# AC-20: Only authenticated and authorized users can interact with information sources
@permission_required("librarian.edit_document", objectgetter(Document, "document_id"))
def modal_edit_document(request, document_id):
    return modal_view(request, item_type="document", item_id=document_id)


@permission_required("librarian.delete_document", objectgetter(Document, "document_id"))
def modal_delete_document(request, document_id):
    return modal_view(request, item_type="document", item_id=document_id)


# AC-21: Only authenticated and authorized users can manage library users
@permission_required(
    "librarian.manage_library_users", objectgetter(Library, "library_id")
)
def modal_manage_library_users(request, library_id):
    return modal_view(request, item_type="library_users", item_id=library_id)


@dataclass
class LibrarianTempObject:
    id: int = None
    name: str = ""
    temp: bool = True


def create_temp_object(item_type):
    """
    Helper for creating a temporary object for the modal
    """
    temp_names = {
        "document": _("Unsaved document"),
        "data_source": _("Unsaved data source"),
        "library": _("Unsaved library"),
    }
    return LibrarianTempObject(id=None, name=temp_names[item_type], temp=True)


@permission_required("librarian.edit_document", objectgetter(Document, "document_id"))
def document_start(request, document_id):
    bind_contextvars(feature="librarian")

    # Initiate celery task
    document = get_object_or_404(Document, id=document_id)
    document.process()
    return modal_view(request, item_type="document", item_id=document_id)


@permission_required("librarian.edit_document", objectgetter(Document, "document_id"))
def document_stop(request, document_id):
    # Stop celery task
    document = get_object_or_404(Document, id=document_id)
    document.stop()
    return modal_view(request, item_type="document", item_id=document_id)


@permission_required(
    "librarian.edit_data_source", objectgetter(DataSource, "data_source_id")
)
def upload(request, data_source_id):
    """
    Handles POST request for (multiple) document upload
    <input type="file" name="file" id="document-file-input" multiple>
    """
    bind_contextvars(feature="librarian")

    for file in request.FILES.getlist("file"):
        file_obj = SavedFile.objects.create(content_type=file.content_type)
        file_obj.file.save(file.name, file)
        document = Document.objects.create(
            data_source_id=data_source_id, file=file_obj, filename=file.name
        )
        document.process()
    # Update the modal with the new documents
    request.method = "GET"
    return modal_view(request, item_type="data_source", item_id=data_source_id)


@permission_required(
    "librarian.download_document", objectgetter(Document, "document_id")
)
def download_document(request, document_id):
    # AC-20: Provide an audit trail of interactions with external information sources
    logger.info("Downloading file for QA document", document_id=document_id)
    document = get_object_or_404(Document, pk=document_id)
    file_obj = document.file
    file = file_obj.file
    # Download the file, don't display it
    response = HttpResponse(file, content_type=file_obj.content_type)
    response["Content-Disposition"] = f"attachment; filename={document.filename}"
    return response



=== Contents of django\librarian\metrics\__init__.py ===



=== Contents of django\librarian\metrics\activity_metrics.py ===
from prometheus_client import Counter

librarian_access_total = Counter(
    name="librarian_access_total",
    documentation="number of times the librarian application page has been accessed by users",
    labelnames=["user"],
)


librarian_new_library_total = Counter(
    name="librarian_new_library_total",
    documentation="number of times a new library has been added to the librarian application",
    labelnames=["user"],
)


librarian_library_delete_total = Counter(
    name="librarian_library_delete_total",
    documentation="number of times a library has been removed from the librarian application",
    labelnames=["user"],
)


librarian_data_source_new_total = Counter(
    name="librarian_new_data_source_total",
    documentation="number of times a new data_source has been added to a library in the librarian application",
    labelnames=["user", "library"],
)


librarian_data_source_update_total = Counter(
    name="librarian_data_source_update_total",
    documentation="number of times data_sources have been updated in a library in the librarian application",
    labelnames=["user", "library"],
)

librarian_data_source_delete_total = Counter(
    name="librarian_data_source_delete_total",
    documentation="number of times data_sources have been removed from a library in the librarian application",
    labelnames=["user", "library"],
)

librarian_document_block_total = Counter(
    name="librarian_document_block_total",
    documentation="number of times a document has been blocked in the librarian application",
    labelnames=["user", "document"],
)


librarian_document_unblock_total = Counter(
    name="librarian_document_unblock_total",
    documentation="number of times a document has been unblocked in the librarian application",
    labelnames=["user", "document"],
)



=== Contents of django\librarian\migrations\__init__.py ===



=== Contents of django\librarian\migrations\0001_initial.py ===
# Generated by Django 5.0.7 on 2024-07-25 20:33

import librarian.models
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = []

    operations = [
        migrations.CreateModel(
            name="DataSource",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                (
                    "uuid_hex",
                    models.CharField(
                        default=librarian.models.generate_uuid_hex,
                        editable=False,
                        max_length=32,
                        unique=True,
                    ),
                ),
                ("name", models.CharField(max_length=255)),
                ("name_en", models.CharField(max_length=255, null=True)),
                ("name_fr", models.CharField(max_length=255, null=True)),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                ("modified_at", models.DateTimeField(auto_now=True)),
                ("order", models.IntegerField(default=0)),
            ],
            options={
                "ordering": ["order", "name"],
            },
        ),
        migrations.CreateModel(
            name="Document",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                (
                    "uuid_hex",
                    models.CharField(
                        default=librarian.models.generate_uuid_hex,
                        editable=False,
                        max_length=32,
                        unique=True,
                    ),
                ),
                ("sha256_hash", models.CharField(blank=True, max_length=64, null=True)),
                (
                    "status",
                    models.CharField(
                        choices=[
                            ("PENDING", "Not started"),
                            ("INIT", "Starting..."),
                            ("PROCESSING", "Processing..."),
                            ("SUCCESS", "Success"),
                            ("ERROR", "Error"),
                            ("BLOCKED", "Stopped"),
                        ],
                        default="PENDING",
                        max_length=20,
                    ),
                ),
                (
                    "celery_task_id",
                    models.CharField(blank=True, max_length=50, null=True),
                ),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                ("modified_at", models.DateTimeField(auto_now=True)),
                (
                    "extracted_title",
                    models.CharField(blank=True, max_length=255, null=True),
                ),
                ("extracted_modified_at", models.DateTimeField(blank=True, null=True)),
                (
                    "generated_title",
                    models.CharField(blank=True, max_length=255, null=True),
                ),
                ("generated_description", models.TextField(blank=True, null=True)),
                (
                    "manual_title",
                    models.CharField(blank=True, max_length=255, null=True),
                ),
                ("extracted_text", models.TextField(blank=True, null=True)),
                ("num_chunks", models.IntegerField(blank=True, null=True)),
                ("url", models.URLField(blank=True, null=True)),
                ("selector", models.CharField(blank=True, max_length=255, null=True)),
                ("fetched_at", models.DateTimeField(blank=True, null=True)),
                (
                    "url_content_type",
                    models.CharField(blank=True, max_length=255, null=True),
                ),
                ("filename", models.CharField(blank=True, max_length=255, null=True)),
            ],
            options={
                "ordering": ["-created_at"],
            },
        ),
        migrations.CreateModel(
            name="Library",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                (
                    "uuid_hex",
                    models.CharField(
                        default=librarian.models.generate_uuid_hex,
                        editable=False,
                        max_length=32,
                        unique=True,
                    ),
                ),
                ("name", models.CharField(blank=True, max_length=255, null=True)),
                ("name_en", models.CharField(blank=True, max_length=255, null=True)),
                ("name_fr", models.CharField(blank=True, max_length=255, null=True)),
                ("description", models.TextField(blank=True, null=True)),
                ("description_en", models.TextField(blank=True, null=True)),
                ("description_fr", models.TextField(blank=True, null=True)),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                ("modified_at", models.DateTimeField(auto_now=True)),
                ("accessed_at", models.DateTimeField(auto_now_add=True)),
                ("order", models.IntegerField(default=0)),
                ("is_public", models.BooleanField(default=False)),
            ],
            options={
                "verbose_name_plural": "Libraries",
                "ordering": ["-is_public", "order", "name"],
            },
        ),
        migrations.CreateModel(
            name="LibraryUserRole",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                (
                    "role",
                    models.CharField(
                        choices=[
                            ("admin", "Admin"),
                            ("contributor", "Contributor"),
                            ("viewer", "Viewer"),
                        ],
                        max_length=20,
                    ),
                ),
            ],
        ),
        migrations.CreateModel(
            name="SavedFile",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                (
                    "sha256_hash",
                    models.CharField(
                        blank=True, db_index=True, max_length=64, null=True
                    ),
                ),
                ("file", models.FileField(upload_to="files/%Y/%m/%d/")),
                ("content_type", models.CharField(blank=True, max_length=255)),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                ("eof", models.BooleanField(default=True)),
            ],
        ),
    ]



=== Contents of django\librarian\migrations\0002_initial.py ===
# Generated by Django 5.0.7 on 2024-07-25 20:33

import django.db.models.deletion
from django.conf import settings
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        ("chat", "0003_initial"),
        ("librarian", "0001_initial"),
        ("otto", "0001_initial"),
        migrations.swappable_dependency(settings.AUTH_USER_MODEL),
    ]

    operations = [
        migrations.AddField(
            model_name="datasource",
            name="security_label",
            field=models.ForeignKey(
                null=True,
                on_delete=django.db.models.deletion.SET_NULL,
                to="otto.securitylabel",
            ),
        ),
        migrations.AddField(
            model_name="document",
            name="data_source",
            field=models.ForeignKey(
                on_delete=django.db.models.deletion.CASCADE,
                related_name="documents",
                to="librarian.datasource",
            ),
        ),
        migrations.AddField(
            model_name="library",
            name="chat",
            field=models.OneToOneField(
                blank=True,
                null=True,
                on_delete=django.db.models.deletion.CASCADE,
                to="chat.chat",
            ),
        ),
        migrations.AddField(
            model_name="library",
            name="created_by",
            field=models.ForeignKey(
                blank=True,
                null=True,
                on_delete=django.db.models.deletion.SET_NULL,
                to=settings.AUTH_USER_MODEL,
            ),
        ),
        migrations.AddField(
            model_name="datasource",
            name="library",
            field=models.ForeignKey(
                on_delete=django.db.models.deletion.CASCADE,
                related_name="data_sources",
                to="librarian.library",
            ),
        ),
        migrations.AddField(
            model_name="libraryuserrole",
            name="library",
            field=models.ForeignKey(
                on_delete=django.db.models.deletion.CASCADE,
                related_name="user_roles",
                to="librarian.library",
            ),
        ),
        migrations.AddField(
            model_name="libraryuserrole",
            name="user",
            field=models.ForeignKey(
                on_delete=django.db.models.deletion.CASCADE, to=settings.AUTH_USER_MODEL
            ),
        ),
        migrations.AddField(
            model_name="document",
            name="file",
            field=models.ForeignKey(
                blank=True,
                null=True,
                on_delete=django.db.models.deletion.SET_NULL,
                related_name="documents",
                to="librarian.savedfile",
            ),
        ),
        migrations.AlterUniqueTogether(
            name="libraryuserrole",
            unique_together={("library", "user")},
        ),
    ]



=== Contents of django\librarian\migrations\0003_library_is_default_library.py ===
# Generated by Django 5.1 on 2024-08-14 17:50

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ("librarian", "0002_initial"),
    ]

    operations = [
        migrations.AddField(
            model_name="library",
            name="is_default_library",
            field=models.BooleanField(default=False),
        ),
    ]



=== Contents of django\librarian\migrations\0004_document_cost.py ===
# Generated by Django 5.1 on 2024-08-29 19:37

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ("librarian", "0003_library_is_default_library"),
    ]

    operations = [
        migrations.AddField(
            model_name="document",
            name="cost",
            field=models.DecimalField(decimal_places=6, max_digits=10, default=0),
        ),
    ]



=== Contents of django\librarian\migrations\0005_rename_cost_document_usd_cost.py ===
# Generated by Django 5.1 on 2024-09-03 20:32

from django.db import migrations


class Migration(migrations.Migration):

    dependencies = [
        ("librarian", "0004_document_cost"),
    ]

    operations = [
        migrations.RenameField(
            model_name="document",
            old_name="cost",
            new_name="usd_cost",
        ),
    ]



=== Contents of django\librarian\utils\process_engine.py ===
import hashlib
import io
import re
import uuid
from urllib.parse import urljoin

from django.conf import settings
from django.utils import timezone

import filetype
import requests
from bs4 import BeautifulSoup
from structlog import get_logger

from chat.models import Message
from librarian.models import Document
from otto.models import Cost, User

logger = get_logger(__name__)


def fetch_from_url(url):
    try:
        r = requests.get(url, allow_redirects=True)
        content_type = r.headers.get("content-type")
        if content_type is None:
            content_type = guess_content_type(r.content)
        return r.content, content_type

    except Exception as e:
        logger.error(f"Failed to fetch from URL: {e}")
        raise Exception(f"Failed to fetch from URL: {e}")


def generate_hash(content):
    if isinstance(content, str):
        sha256_hash = hashlib.sha256(content.encode("utf-8")).hexdigest()
    else:
        sha256_hash = hashlib.sha256(content).hexdigest()

    return sha256_hash


def extract_html_metadata(content):
    # Content is the binary data from response.content so convert it to a string
    soup = BeautifulSoup(content.decode("utf-8"), "html.parser")
    title_element = soup.find("title")
    title = title_element.get_text(strip=True) if title_element else None
    time_element = soup.find("time", {"property": "dateModified"})
    modified_at = (
        timezone.datetime.strptime(time_element.get_text(strip=True), "%Y-%m-%d")
        if time_element
        else None
    )
    return {
        "extracted_title": title,
        "extracted_modified_at": modified_at,
    }


def create_nodes(chunks, document):
    from llama_index.core.schema import NodeRelationship, RelatedNodeInfo, TextNode

    document_uuid = document.uuid_hex
    data_source_uuid = document.data_source.uuid_hex

    # Create a document (parent) node
    metadata = {"node_type": "document", "data_source_uuid": data_source_uuid}
    if document.title:
        metadata["title"] = document.title
    if document.url or document.filename:
        metadata["source"] = document.url or document.filename
    document_node = TextNode(text="", id_=document_uuid, metadata=metadata)
    document_node.relationships[NodeRelationship.SOURCE] = RelatedNodeInfo(
        node_id=document_node.node_id
    )

    # Create chunk (child) nodes
    metadata["node_type"] = "chunk"
    child_nodes = create_child_nodes(
        chunks, source_node_id=document_node.node_id, metadata=metadata
    )

    # Update node properties
    new_nodes = [document_node] + child_nodes
    for node in new_nodes:
        node.excluded_llm_metadata_keys = ["data_source_uuid"]
        node.excluded_embed_metadata_keys = ["data_source_uuid"]
        # The misspelling of "seperator" corresponds with the LlamaIndex codebase
        node.metadata_seperator = "\n"
        node.metadata_template = "{key}: {value}"
        node.text_template = "# {metadata_str}\ncontent:\n{content}\n\n"

    return new_nodes


# def process(content, fast=True, summarize=True, force=False):

#     if summarize:
#         self.description = document_summary(md)
#         self.generated_title = document_title(self.description)


def guess_content_type(content):
    # Check if the content is binary using filetype.guess
    detected_type = filetype.guess(content)
    if detected_type is not None:
        return detected_type.mime

    if isinstance(content, bytes):
        return None  # Unknown

    if content.startswith("<!DOCTYPE html>") or "<html" in content:
        return "text/html"

    if content.startswith("<?xml") or "<root" in content:
        return "application/xml"

    if content.startswith("{") or content.startswith("["):
        return "application/json"

    return "text/plain"


def get_process_engine_from_type(type):
    if "officedocument.wordprocessingml.document" in type:
        return "WORD"
    elif "officedocument.presentationml.presentation" in type:
        return "POWERPOINT"
    elif "application/pdf" in type:
        return "PDF"
    elif "text/html" in type:
        return "HTML"
    else:
        return "TEXT"


def extract_markdown(
    content, process_engine, fast=False, base_url=None, chunk_size=768, selector=None
):
    if process_engine == "PDF" and fast:
        md, md_chunks = fast_pdf_to_text(content, chunk_size)
        if len(md) < 10:
            # Fallback to Azure Document AI (fka Form Recognizer) if the fast method fails
            # since that probably means it needs OCR
            md, md_chunks = pdf_to_markdown(content, chunk_size)
    elif process_engine == "PDF":
        md, md_chunks = pdf_to_markdown(content, chunk_size)
    elif process_engine == "WORD":
        md, md_chunks = docx_to_markdown(content, chunk_size)
    elif process_engine == "POWERPOINT":
        md, md_chunks = pptx_to_markdown(content, chunk_size)
    elif process_engine == "HTML":
        md, md_chunks = html_to_markdown(
            content.decode("utf-8"), chunk_size, base_url, selector
        )
    elif process_engine == "TEXT":
        md, md_chunks = text_to_markdown(content.decode("utf-8"), chunk_size)

    # Sometimes HTML to markdown will result in zero chunks, even though there is text
    if not md_chunks:
        md_chunks = [md]

    return md, md_chunks


def pdf_to_markdown(content, chunk_size=768):
    html = _pdf_to_html_using_azure(content)
    md, nodes = _convert_html_to_markdown(html, chunk_size)
    return md, nodes


def fast_pdf_to_text(content, chunk_size=768):
    # Note: This method is faster than using Azure Form Recognizer
    # Expected it to work well for more generic scenarios but not for scanned PDFs, images, and handwritten text
    import fitz

    pdf = fitz.open(stream=io.BytesIO(content))
    text = ""
    for page_number in range(pdf.page_count):
        page = pdf.load_page(page_number)
        text += page.get_text("text")
    pdf.close()

    # We don't split the text into chunks here because it's done in create_child_nodes()
    return text, [text]


def html_to_markdown(content, chunk_size=768, base_url=None, selector=None):
    md, nodes = _convert_html_to_markdown(content, chunk_size, base_url, selector)
    return md, nodes


def text_to_markdown(content, chunk_size=768):
    # We don't split the text into chunks here because it's done in create_child_nodes()
    return content, [content]


def docx_to_markdown(content, chunk_size=768):
    import mammoth

    with io.BytesIO(content) as docx_file:
        result = mammoth.convert_to_html(docx_file)
    html = result.value
    md, nodes = _convert_html_to_markdown(html, chunk_size)
    return md, nodes


def pptx_to_markdown(content, chunk_size=768):
    import pptx

    pptx_file = io.BytesIO(content)
    prs = pptx.Presentation(pptx_file)

    # extract text from each slide
    html = ""
    for slide in prs.slides:
        for shape in slide.shapes:
            if not shape.has_text_frame:
                continue
            for paragraph in shape.text_frame.paragraphs:
                for run in paragraph.runs:
                    html += f"<p>{run.text}</p>"
        for note in slide.notes_slide.notes_text_frame.paragraphs:
            for run in note.runs:
                html += f"<p>{run.text}</p>"

    md, nodes = _convert_html_to_markdown(html, chunk_size)
    return md, nodes


def document_summary(content):
    from langchain.chains.summarize import load_summarize_chain
    from langchain.schema import Document
    from langchain_openai import AzureChatOpenAI

    llm = AzureChatOpenAI(
        azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
        azure_deployment=settings.DEFAULT_CHAT_MODEL,
        model=settings.DEFAULT_CHAT_MODEL,
        api_version=settings.AZURE_OPENAI_VERSION,
        api_key=settings.AZURE_OPENAI_KEY,
        temperature=0.1,
    )
    content = content[:5000]
    chain = load_summarize_chain(llm, chain_type="stuff")
    doc = Document(page_content=content, metadata={"source": "userinput"})
    summary = chain.run([doc])
    return summary


def document_title(content):
    from langchain.schema import HumanMessage
    from langchain_openai import AzureChatOpenAI

    llm = AzureChatOpenAI(
        azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
        azure_deployment=settings.DEFAULT_CHAT_MODEL,
        model=settings.DEFAULT_CHAT_MODEL,
        api_version=settings.AZURE_OPENAI_VERSION,
        api_key=settings.AZURE_OPENAI_KEY,
        temperature=0.1,
    )
    prompt = "Generate a short title fewer than 50 characters."
    content = content[:5000]
    title = llm([HumanMessage(content=content), HumanMessage(content=prompt)]).content[
        :254
    ]
    # Remove any double quotes wrapping the title, if any
    title = re.sub(r'^"|"$', "", title)
    return title


def create_child_nodes(text_strings, source_node_id, metadata=None):
    from llama_index.core.node_parser import SentenceSplitter
    from llama_index.core.schema import NodeRelationship, RelatedNodeInfo, TextNode

    def close_tags(html_string):
        soup = BeautifulSoup(html_string, "html.parser")
        return str(soup)

    splitter = SentenceSplitter(chunk_overlap=100, chunk_size=768)

    # Create TextNode objects
    nodes = []
    split_texts = []
    for i, text in enumerate(text_strings):
        split_texts += [close_tags(t) for t in splitter.split_text(text)]

    # Now all the chunks are at most 768 tokens long, but many are much shorter
    # We want to make them a uniform size, so we'll stuff them into the previous chunk
    # (making sure the previous chunk doesn't exceed 768 tokens)
    stuffed_texts = []
    current_text = ""
    for text in split_texts:
        if token_count(f"{current_text} {text}") > 768:
            stuffed_texts.append(current_text)
            current_text = text
        else:
            current_text += " " + text

    # Append the last stuffed text if it's not empty
    if current_text:
        stuffed_texts.append(current_text)

    for text in stuffed_texts:
        node = TextNode(text=text, id_=str(uuid.uuid4()))
        node.metadata = metadata
        node.relationships[NodeRelationship.SOURCE] = RelatedNodeInfo(
            node_id=source_node_id
        )
        nodes.append(node)

    # Handle the case when there's only one or zero elements
    if len(text_strings) < 2:
        return nodes

    # Set relationships
    for i in range(len(nodes) - 1):
        nodes[i].relationships[NodeRelationship.NEXT] = RelatedNodeInfo(
            node_id=nodes[i + 1].node_id
        )
        nodes[i + 1].relationships[NodeRelationship.PREVIOUS] = RelatedNodeInfo(
            node_id=nodes[i].node_id
        )

    return nodes


def token_count(string: str, model: str = "gpt-4") -> int:
    import tiktoken

    """Returns the number of tokens in a text string."""
    encoding = tiktoken.encoding_for_model(model)
    num_tokens = len(encoding.encode(string))
    return num_tokens


def _convert_html_to_markdown(
    source_html, chunk_size=768, base_url=None, selector=None
):
    import html2text

    model = settings.DEFAULT_CHAT_MODEL

    ## Keeping this here for posterity, but it didn't work well in experiments
    ## Used https://www.tbs-sct.canada.ca/agreements-conventions/view-visualiser-eng.aspx?id=4 as example:
    ## It cut off the text randomly after a long html was passed in
    ## It loses all the formatting (like headers)
    ## It loses all the links and/or doesn't format them properly
    # article = Article(" ", source_url=base_url)
    # article.set_html(text)
    # article.parse()
    # return article.text
    # TODO: Remove the following comments when completely sure the new approach works
    # if text contains html, convert it to markdown

    soup = BeautifulSoup(source_html, "html.parser")

    if selector:
        selected_html = soup.select_one(selector)
        if selected_html:
            soup = selected_html
        else:
            logger.warning(f"Selector {selector} not found in HTML")

    if not base_url:
        # find all anchor tags
        for anchor in soup.find_all("a"):
            # get the href attribute value
            href = anchor.get("href")
            # convert relative URLs to absolute URLs
            if href and not href.startswith("http"):
                absolute_url = urljoin(base_url, href)
                anchor["href"] = absolute_url

    # remove any javascript, css, images, svg, and comments from self.text
    text = re.sub(r"<script.*?</script>", "", str(soup), flags=re.DOTALL)
    text = re.sub(r"<style.*?</style>", "", text, flags=re.DOTALL)
    text = re.sub(r"<!--.*?-->", "", text, flags=re.DOTALL)
    text = re.sub(r"<img.*?>", "", text, flags=re.DOTALL)
    text = re.sub(r"<svg.*?</svg>", "", text, flags=re.DOTALL)
    # remove any attribute tags that start with javascript:
    text = re.sub(r"<[^>]+javascript:.*?>", "", text, flags=re.DOTALL)
    # remove any empty html tags from self.text
    text = re.sub(r"<[^/>][^>]*>\s*</[^>]+>", "", text, flags=re.DOTALL)

    # remove any header/footer/nav tags and the content within them
    text = re.sub(r"<header.*?</header>", "", text, flags=re.DOTALL)
    text = re.sub(r"<footer.*?</footer>", "", text, flags=re.DOTALL)
    text = re.sub(r"<nav.*?</nav>", "", text, flags=re.DOTALL)

    # Remove all the line breaks, carriage returns, and tabs
    text = re.sub(r"[\n\r\t]", "", text)

    h = html2text.HTML2Text()
    h.ignore_images = True
    h.skip_internal_links = True
    h.body_width = 0
    h.drop_white_space = True
    h.footnote = False

    # Recreate the soup object from the cleaned text
    cleaned_soup = BeautifulSoup(text, "html.parser")

    # Process paragraphs, lists, and tables
    nodes = []

    # Elements that are typically text
    header_node_names = ["h1", "h2", "h3", "h4", "h5", "h6"]
    section_node_names = ["section", "article"]
    text_node_names = ["p", "ul", "ol"]
    table_node_names = ["table"]

    # Accumulate text nodes until the chunk size is reached
    current_node = ""
    header_str = ""
    header_map = {f"h{i}": "" for i in range(1, 7)}
    for node in cleaned_soup.find_all(
        header_node_names + text_node_names + table_node_names
    ):

        # If it's a header, then append the current node and reset
        if node.name in header_node_names:
            nodes.append(h.handle(current_node).strip())

            # Update the header map with the current header
            header_map[node.name] = str(node)

            # Clear all the headers that are smaller than the current header
            for i in range(int(node.name[1]) + 1, 7):
                header_map[f"h{i}"] = ""

            # Create the header string from the header map
            header_str = "".join(header_map.values())
            current_node = header_str

        # If it's a section or article node, then append the current node and reset
        elif node.name in section_node_names:
            nodes.append(h.handle(current_node).strip())
            current_node = ""

        # If it's a text node, then accumulate the text until the chunk size is reached
        elif node.name in text_node_names:
            node_str = str(node)

            # Split the text by chunk size or if the node is a header
            tentative_node = h.handle(f"{current_node}{node_str}").strip()
            if token_count(tentative_node, model) > chunk_size:
                nodes.append(tentative_node)
                # Reset the current node and include the header again for context
                current_node = f"{header_str}{node_str}"
            else:
                current_node += node_str

        # If it's a table node, then split the table by chunk size
        elif node.name in table_node_names:

            # Append the current node to the nodes list and reset the current node
            if current_node:
                nodes.append(h.handle(current_node).strip())
                current_node = ""

            # Find the table caption and append it to the current node
            caption = node.select_one("caption")
            caption_str = str(caption) if caption else ""

            thead = node.select_one("thead")
            thead_str = str(thead) if thead else ""

            # if no thead, iterate through all the rows and find a row that has ONLY th tags as children
            if not thead:
                for row in node.find_all("tr"):
                    if all([child.name == "th" for child in row.children]):
                        thead_str = str(row)
                        break

            # Iterate through all other rows and append them to the data rows list
            data_rows = []
            for row in node.find_all("tr"):
                if str(row) not in thead_str:
                    data_rows.append(row)

            # Split the table by chunk size, preserving the header for each mini table
            current_node = f"{header_str}<p>{caption_str}</p><table>{thead_str}"
            for data_row in data_rows:
                data_str = str(data_row)

                # Split the table by chunk size
                tentative_node = h.handle(f"{current_node}{data_str}</table>").strip()
                if token_count(tentative_node, model) > chunk_size:
                    nodes.append(tentative_node)
                    current_node = f"{header_str}<p>{caption_str}</p><table>{thead_str}"
                else:
                    current_node += data_str

            # Append the last mini table to the nodes list
            nodes.append(h.handle(f"{current_node}</table>").strip())
            current_node = ""

    md = h.handle(text).strip()
    return md, nodes


def _pdf_to_html_using_azure(content):
    from azure.ai.formrecognizer import DocumentAnalysisClient
    from azure.core.credentials import AzureKeyCredential
    from shapely.geometry import Polygon

    # Note: This method handles scanned PDFs, images, and handwritten text better than pdfminer but costs money

    document_analysis_client = DocumentAnalysisClient(
        endpoint=settings.AZURE_COGNITIVE_SERVICE_ENDPOINT,
        credential=AzureKeyCredential(settings.AZURE_COGNITIVE_SERVICE_KEY),
    )

    poller = document_analysis_client.begin_analyze_document("prebuilt-layout", content)
    result = poller.result()

    num_pages = len(result.pages)
    cost = Cost.objects.new(cost_type="doc-ai-prebuilt", count=num_pages)

    # Extract table bounding regions
    table_bounding_regions = []
    for table in result.tables:
        for cell in table.cells:
            table_bounding_regions.append(cell.bounding_regions[0])

    table_chunks = []
    for _, table in enumerate(result.tables):
        page_number = table.bounding_regions[0].page_number

        # Generate table HTML syntax
        table_html = "<table>"
        for row in range(table.row_count):
            table_html += "<tr>"
            for col in range(table.column_count):
                try:
                    cell = next(
                        cell
                        for cell in table.cells
                        if cell.row_index == row and cell.column_index == col
                    )
                    table_html += "<td>{}</td>".format(cell.content)
                except StopIteration:
                    table_html += "<td></td>"
            table_html += "</tr>"
        table_html += "</table>"

        chunk = {
            "page_number": page_number,
            "x": table.bounding_regions[0].polygon[0].x,
            "y": table.bounding_regions[0].polygon[0].y,
            "text": table_html,
        }
        table_chunks.append(chunk)

    p_chunks = []
    for paragraph in result.paragraphs:
        paragraph_page_number = paragraph.bounding_regions[0].page_number
        paragraph_polygon = Polygon(
            [(point.x, point.y) for point in paragraph.bounding_regions[0].polygon]
        )

        # Check intersection between paragraph and table cells
        if any(
            paragraph_polygon.intersects(
                Polygon([point.x, point.y] for point in cell.polygon)
            )
            for cell in table_bounding_regions
            if cell.page_number == paragraph_page_number
        ):
            continue

        # If text contains words like :selected:, :checked:, or :unchecked:, then skip it
        if any(
            word in paragraph.content
            for word in [":selected:", ":checked:", ":unchecked:"]
        ):
            continue

        # Create Chunk object and append to chunks list
        chunk = {
            "page_number": paragraph_page_number,
            "x": paragraph_polygon.bounds[0],
            "y": paragraph_polygon.bounds[1],
            "text": "<p>" + paragraph.content + "</p>",
        }
        p_chunks.append(chunk)

    # Remove any duplicate chunks by looking at the text
    p_chunks = list({chunk.get("text"): chunk for chunk in p_chunks}.values())

    chunks = table_chunks + p_chunks

    # Sort chunks by page number, then by y coordinate, then by x coordinate
    chunks = sorted(
        chunks, key=lambda item: (item.get("page_number"), item.get("y"), item.get("x"))
    )
    html = ""
    for _, chunk in enumerate(chunks, 1):
        html += chunk.get("text")

    return html

    # def _fetch_from_file(self, force=False):
    #     # Logic for ChatFile fetch
    #     from chat.models import ChatFile

    #     file_obj = ChatFile.objects.get(id=self.reference)
    #     self._set_process_engine_from_type(file_obj.content_type)
    #     self.source_name = file_obj.name
    #     return file_obj.file.read()

    # Selection of hashing code from my other (incomplete) PR

    # sha256_hash = models.CharField(max_length=64, null=True, blank=True, db_index=True)
    # def generate_hash(self):
    #     if self.file:
    #         with self.file.open("rb") as f:
    #             sha256 = hashlib.sha256(f.read())
    #             self.sha256_hash = sha256.hexdigest()
    #             self.save()

    # self.fetched_from_source_at = timezone.now()
    # """



=== Contents of django\otto\__init__.py ===
from .celery import app as celery_app

__all__ = ("celery_app",)



=== Contents of django\otto\admin.py ===
from django.contrib import admin
from django.contrib.auth import get_user_model
from django.contrib.auth.admin import UserAdmin as BaseUserAdmin
from django.contrib.auth.forms import UserChangeForm, UserCreationForm

from modeltranslation.admin import TranslationAdmin

from otto.models import App

User = get_user_model()


class CustomUserChangeForm(UserChangeForm):
    class Meta(UserChangeForm.Meta):
        model = User


class CustomUserCreationForm(UserCreationForm):
    class Meta(UserCreationForm.Meta):
        model = User
        fields = ("upn",)


class CustomUserAdmin(BaseUserAdmin):
    form = CustomUserChangeForm
    add_form = CustomUserCreationForm

    list_display = ("email", "first_name", "last_name", "is_staff")
    list_filter = ("is_staff", "is_superuser", "is_active", "groups")
    search_fields = ("email", "first_name", "last_name")
    ordering = ("last_name", "first_name")
    fieldsets = (
        (None, {"fields": ("upn", "password")}),
        (
            "Personal info",
            {"fields": ("first_name", "last_name", "accepted_terms_date")},
        ),
        (
            "Permissions",
            {
                "fields": (
                    "is_active",
                    "is_staff",
                    "is_superuser",
                    "groups",
                    "user_permissions",
                )
            },
        ),
        ("Important dates", {"fields": ("last_login", "date_joined")}),
    )
    add_fieldsets = (
        (
            None,
            {
                "classes": ("wide",),
                "fields": ("upn", "password1", "password2"),
            },
        ),
    )


class AppAdmin(TranslationAdmin):
    pass


# AC-16 & AC-16(2): Allows authorized administrators to modify various security-related attributes of user accounts
admin.site.register(User, CustomUserAdmin)
admin.site.register(App, AppAdmin)



=== Contents of django\otto\asgi.py ===
"""
ASGI config for otto project.

It exposes the ASGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/4.1/howto/deployment/asgi/
"""

import logging
import os

from django.conf import settings
from django.core.asgi import get_asgi_application

from channels.routing import ProtocolTypeRouter

os.environ.setdefault("DJANGO_SETTINGS_MODULE", "otto.settings")

# Get the Django ASGI application
django_asgi_app = get_asgi_application()

# Define an ASGI application using ProtocolTypeRouter
application = ProtocolTypeRouter(
    {
        "http": django_asgi_app,
    }
)



=== Contents of django\otto\celery.py ===
import os
from logging.config import dictConfig

from django.conf import settings

from celery import Celery
from celery.schedules import crontab
from celery.signals import setup_logging
from django_structlog.celery.steps import DjangoStructLogInitStep

os.environ.setdefault("DJANGO_SETTINGS_MODULE", "otto.settings")

app = Celery("otto")
# initialize django-structlog
app.steps["worker"].add(DjangoStructLogInitStep)
app.config_from_object("django.conf:settings", namespace="CELERY")
app.autodiscover_tasks()

app.conf.beat_schedule = {
    # Sync entra users every day at 5 am UTC
    "sync-entra-users-every-morning": {
        "task": "otto.tasks.sync_users",
        "schedule": crontab(hour=5, minute=0),
    }
}


@setup_logging.connect
def config_loggers(*args, **kwargs):
    dictConfig(settings.LOGGING)



=== Contents of django\otto\context_processors.py ===
from django.conf import settings


def otto_version(request):
    return {"otto_version": f"{settings.OTTO_VERSION}/{settings.ENVIRONMENT.lower()}"}



=== Contents of django\otto\forms.py ===
from django import forms
from django.conf import settings
from django.contrib.auth import get_user_model
from django.contrib.auth.models import Group
from django.forms import ModelForm
from django.utils.translation import get_language
from django.utils.translation import gettext as _

from autocomplete import widgets

from chat.models import Message
from otto.models import App, Feedback, Pilot

User = get_user_model()


class FeedbackForm(ModelForm):
    app = forms.ChoiceField(
        choices=[],
        required=True,
        label=_(
            "Which application are you providing feedback or reporting an issue for?"
        ),
    )

    modified_by = forms.ModelChoiceField(queryset=None, required=True)
    chat_message = forms.ModelChoiceField(queryset=None, required=False)

    class Meta:
        model = Feedback
        fields = [
            "feedback_type",
            "feedback_message",
            "modified_by",
            "app",
            "chat_message",
            "otto_version",
        ]

        labels = {
            "feedback_type": _("Do you want to provide feedback or report an issue?"),
            "feedback_message": _(
                "If you have any specific suggestions or want to report an issue share them with us below:"
            ),
        }

    def __init__(self, user, message_id, *args, **kwargs):
        super(FeedbackForm, self).__init__(*args, **kwargs)
        self.fields["modified_by"].queryset = User.objects.filter(id=user.id)
        self.fields["modified_by"].initial = user
        self.fields["chat_message"].queryset = Message.objects.filter(id=message_id)
        self.fields["otto_version"].initial = settings.OTTO_VERSION

        if message_id is not None:
            self.initialize_chat_feedback(message_id)
        else:
            self.fields["app"].choices = [
                (app.name, app.name_fr if get_language() == "fr" else app.name_en)
                for app in App.objects.visible_to_user(user)
            ] + [("Otto", _("General (Otto)"))]

    def initialize_chat_feedback(self, message_id):
        self.fields["feedback_type"].initial = next(
            filter(
                lambda option: option[0] == "feedback", Feedback.FEEDBACK_TYPE_CHOICES
            )
        )
        self.fields["app"].choices = [("chat", "Chat")]
        self.fields["chat_message"].initial = Message.objects.get(id=message_id)


# AC-16 & AC-16(2): Enables the modification of user roles and group memberships
class UserGroupForm(forms.Form):
    email = forms.ModelMultipleChoiceField(
        queryset=User.objects.all(),
        label="Email",
        required=True,
        widget=widgets.Autocomplete(
            name="email",
            options={
                "item_value": User.id,
                "item_label": User.email,
                "multiselect": True,
                "minimum_search_length": 2,
                "model": User,
            },
        ),
    )
    group = forms.ModelMultipleChoiceField(
        queryset=Group.objects.all(),
        label="Roles",
        required=False,
        widget=widgets.Autocomplete(
            name="group",
            options={"multiselect": True, "minimum_search_length": 0, "model": Group},
        ),
    )
    pilot = forms.ModelChoiceField(
        queryset=Pilot.objects.all(),
        label="Pilot",
        required=False,
        widget=forms.Select(attrs={"class": "form-control"}),
        to_field_name="name",
    )


class PilotForm(forms.ModelForm):
    # Simple form with all the fields default widgets
    class Meta:
        model = Pilot
        fields = "__all__"
        # Add the bootstrap classes to the form fields and labels
        widgets = {
            "pilot_id": forms.TextInput(attrs={"class": "form-control"}),
            "name": forms.TextInput(attrs={"class": "form-control"}),
            "service_unit": forms.TextInput(
                attrs={"class": "form-control", "required": False}
            ),
            "description": forms.Textarea(
                attrs={"class": "form-control", "required": False, "rows": 3}
            ),
            "start_date": forms.DateInput(
                attrs={"class": "form-control", "type": "date", "required": False}
            ),
            "end_date": forms.DateInput(
                attrs={"class": "form-control", "type": "date", "required": False}
            ),
        }

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # For some reason, the required attribute is not being set in the widget
        # so we need to set it manually
        self.fields["start_date"].required = False
        self.fields["end_date"].required = False
        # If the instance is not None, then we are editing an existing pilot
        # So the pilot_id should be read-only
        if self.instance.pk:
            self.fields["pilot_id"].widget.attrs["readonly"] = True
            self.fields["pilot_id"].widget.attrs["disabled"] = True



=== Contents of django\otto\models.py ===
import datetime
import uuid

from django.conf import settings
from django.contrib.auth.models import (
    AbstractBaseUser,
    BaseUserManager,
    Group,
    PermissionsMixin,
)
from django.db import models
from django.utils.translation import gettext_lazy as _

from otto.utils.common import display_cad_cost


class CustomUserManager(BaseUserManager):
    def create_user(self, upn, password=None, **extra_fields):
        user = self.model(upn=upn, **extra_fields)
        user.save()
        return user

    def create_superuser(self, upn, password=None, **extra_fields):
        extra_fields.setdefault("is_staff", True)
        extra_fields.setdefault("is_superuser", True)
        return self.create_user(upn, password, **extra_fields)


class User(AbstractBaseUser, PermissionsMixin):
    # Always store lowercase email addresses. This is done when user is created.
    upn = models.CharField(max_length=255, unique=True)
    email = models.EmailField()
    oid = models.CharField(max_length=255, null=True)
    first_name = models.CharField(max_length=80)
    last_name = models.CharField(max_length=80)
    is_active = models.BooleanField(default=True)
    is_staff = models.BooleanField(default=False)
    date_joined = models.DateTimeField(auto_now_add=True)
    accepted_terms_date = models.DateField(null=True)
    pilot = models.ForeignKey("Pilot", on_delete=models.SET_NULL, null=True, blank=True)

    objects = CustomUserManager()

    USERNAME_FIELD = "upn"
    REQUIRED_FIELDS = []

    @property
    def accepted_terms(self):
        return self.accepted_terms_date is not None

    @property
    def lastname_firstname(self):
        return f"{self.last_name}, {self.first_name}"

    @property
    def full_name(self):
        return f"{self.first_name} {self.last_name}"

    @property
    def username(self):
        return self.email.split("@")[0]

    @property
    def num_messages(self):
        from chat.models import Chat, Message

        chats = Chat.objects.filter(user=self)
        return Message.objects.filter(chat__in=chats, is_bot=False).count()

    @property
    def roles(self):
        return self.groups.all()

    @property
    def total_cost(self):
        return display_cad_cost(Cost.objects.get_user_cost(self))

    def __str__(self):
        return f"{self.lastname_firstname} ({self.email})"

    class Meta:
        indexes = [
            models.Index(fields=["email"]),
        ]

    def make_otto_admin(self):
        self.groups.add(Group.objects.get(name="Otto admin"))


class UserOptions(models.Model):
    user = models.OneToOneField(User, on_delete=models.CASCADE)

    language = models.CharField(max_length=50, default="en")
    # Hide the settings sidebar by default
    chat_settings_width = models.IntegerField(default=0)

    def __str__(self):
        return f"Options for {self.user.upn}"


class AppManager(models.Manager):

    def create_from_yaml(self, app_data):
        if "user_group" in app_data["fields"]:
            # TODO: Handle user_group translations (may require extending Group model)
            user_group_name = app_data["fields"]["user_group"]
            app_data["fields"]["user_group"], _created = Group.objects.get_or_create(
                name=user_group_name
            )

        features = app_data["fields"].pop("features")
        app = super().create(**app_data["fields"])
        app.save()

        for feature_data in features:
            feature = Feature.objects.create(
                app=app,
                name=feature_data["fields"]["name_en"],
                description=feature_data["fields"]["description_en"],
                url=feature_data["fields"]["url"],
                category=feature_data["fields"]["category"],
                classification=feature_data["fields"].get("classification", ""),
                short_name=feature_data["fields"].get("short_name", None),
            )

            # Set French translations for features if available
            if "name_fr" in feature_data["fields"]:
                feature.name_fr = feature_data["fields"]["name_fr"]
            if "description_fr" in feature_data["fields"]:
                feature.description_fr = feature_data["fields"]["description_fr"]

            feature.save()

        return app

    def visible_to_user(self, user):
        return [app for app in self.all() if user.has_perm("otto.view_app", app)]

    def accessible_to_user(self, user):
        return [app for app in self.all() if user.has_perm("otto.access_app", app)]


class App(models.Model):
    # UUID for legacy reasons; hard to migrate back to int, so leaving it as-is.
    id = models.UUIDField(primary_key=True, editable=False, default=uuid.uuid4)
    objects = AppManager()
    handle = models.CharField(max_length=50, null=True, blank=True)
    name = models.CharField(max_length=200)
    prod_ready = models.BooleanField(default=False)
    visible_to_all = models.BooleanField(default=True)
    user_group = models.ForeignKey(
        "auth.Group", on_delete=models.SET_NULL, blank=True, null=True
    )

    def __str__(self):
        return self.name


class Feature(models.Model):

    CATEGORY_CHOICES = [
        ("ai_assistant", _("AI assistant")),
        ("monitoring", _("Monitoring")),
        ("reporting", _("Reporting")),
        ("other", _("Other")),
    ]

    app = models.ForeignKey(App, on_delete=models.CASCADE)
    name = models.CharField(max_length=200)
    short_name = models.CharField(max_length=50, unique=True, null=True)
    description = models.TextField()
    category = models.CharField(max_length=50, choices=CATEGORY_CHOICES)
    classification = models.CharField(max_length=50, blank=True, null=True)
    url = models.CharField(max_length=200)

    def __str__(self):
        return self.name


class UsageTerm(models.Model):
    term_text = models.CharField(max_length=2000)

    def __str__(self):
        return self.term_text


class Notification(models.Model):
    user = models.ForeignKey(
        settings.AUTH_USER_MODEL, on_delete=models.CASCADE, related_name="notifications"
    )
    text = models.CharField(max_length=255)
    created_at = models.DateTimeField(auto_now_add=True)

    # Optional fields; can be used for progress bars, links, adding an icon, etc.
    heading = models.CharField(max_length=255, blank=True, null=True)
    progress = models.IntegerField(blank=True, null=True)  # 0-100, or None if n/a
    link = models.CharField(max_length=255, blank=True, null=True)
    category = models.CharField(max_length=50, blank=True, null=True)
    level = models.CharField(max_length=50, blank=True, null=True)

    def __str__(self):
        return f"{self.heading} - {self.text[:50]}"


class Feedback(models.Model):
    FEEDBACK_TYPE_CHOICES = [
        ("feedback", _("Feedback")),
        ("issue", _("Issue")),
    ]

    feedback_type = models.CharField(
        max_length=50,
        choices=FEEDBACK_TYPE_CHOICES,
        blank=False,
        default=_("Please select an option"),
    )
    app = models.TextField(max_length=200, blank=False)
    otto_version = models.CharField(max_length=12, null=False)
    feedback_message = models.TextField(blank=False)
    chat_message = models.ForeignKey(
        "chat.Message", null=True, on_delete=models.SET_NULL, related_name="message"
    )

    created_at = models.DateTimeField(auto_now_add=True)
    modified_by = models.ForeignKey(
        settings.AUTH_USER_MODEL, on_delete=models.DO_NOTHING
    )


class SecurityLabel(models.Model):
    name = models.CharField(max_length=50, unique=True)
    description = models.TextField()
    acronym = models.CharField(max_length=10, unique=True)

    def __str__(self):
        return self.name

    @classmethod
    def default_security_label(cls):
        return cls.objects.get(acronym_en="UC")

    @classmethod
    def maximum_of(cls, acronyms):
        security_label = cls.objects.filter(acronym__in=acronyms).order_by("pk").last()
        if not security_label:
            security_label = SecurityLabel.default_security_label()
        return security_label


class CostType(models.Model):
    name = models.CharField(max_length=100)
    short_name = models.CharField(max_length=50, unique=True, null=True)
    description = models.TextField()
    # e.g. Token
    unit_name = models.CharField(max_length=50, default="units")
    # e.g. 0.00015 ($ USD)
    unit_cost = models.DecimalField(max_digits=10, decimal_places=6, default=1)
    # e.g. 1000
    unit_quantity = models.IntegerField(default=1)

    @property
    def cost_per_unit(self):
        return self.unit_cost / self.unit_quantity

    def __str__(self):
        return self.name


class CostManager(models.Manager):

    def new(self, cost_type: str, count: int) -> "Cost":
        from structlog.contextvars import get_contextvars

        from chat.models import Message
        from librarian.models import Document

        cost_type = CostType.objects.get(short_name=cost_type)

        # The rest of the fields are optional & stored in structlog request context
        request_context = get_contextvars()
        message_id = request_context.get("message_id")
        document_id = request_context.get("document_id")
        user_id = request_context.get("user_id")

        cost_object = self.create(
            cost_type=cost_type,
            count=count,
            usd_cost=(count * cost_type.unit_cost) / cost_type.unit_quantity,
            # Optional fields from request context
            feature=request_context.get("feature"),
            request_id=request_context.get("request_id"),
            user=User.objects.get(id=user_id) if user_id else None,
            message=Message.objects.get(id=message_id) if message_id else None,
            document=Document.objects.get(id=document_id) if document_id else None,
        )

        # Recalculate document and message costs, if applicable
        if cost_object.document:
            cost_object.document.calculate_costs()
        if cost_object.message:
            cost_object.message.calculate_costs()

        return cost_object

    def get_user_cost(self, user):
        # Total cost for a user
        return sum(cost.usd_cost for cost in self.filter(user=user))

    def get_user_cost_by_type(self, user, cost_type):
        # Total cost for a user by cost type
        return sum(
            cost.usd_cost for cost in self.filter(user=user, cost_type=cost_type)
        )

    def get_user_cost_by_feature(self, user, feature):
        # Total cost for a user by feature
        return sum(cost.usd_cost for cost in self.filter(user=user, feature=feature))

    def get_total_cost(self):
        # Total cost for all users
        return sum(cost.usd_cost for cost in self.all())

    def get_total_cost_by_type(self, cost_type):
        # Total cost for all users by cost type
        return sum(cost.usd_cost for cost in self.filter(cost_type=cost_type))

    def get_total_cost_by_feature(self, feature):
        # Total cost for all users by feature
        return sum(cost.usd_cost for cost in self.filter(feature=feature))

    def get_user_cost_today(self, user):
        # Total cost for a user today
        return sum(
            cost.usd_cost
            for cost in self.filter(
                user=user, date_incurred__date=datetime.date.today()
            )
        )

    def get_pilot_cost(self, pilot):
        # Total cost for a pilot
        return sum(cost.usd_cost for cost in self.filter(user__pilot=pilot))


FEATURE_CHOICES = [
    ("librarian", _("Librarian")),
    ("qa", _("Q&A")),
    ("chat", _("Chat")),
    ("translate", _("Translate")),
    ("summarize", _("Summarize")),
    ("template_wizard", _("Template wizard")),
    ("laws_query", _("Legislation search")),
    ("laws_load", _("Legislation loading")),
    ("case_prep", _("Case prep assistant")),
    ("text_extractor", _("Text extractor")),
]


class Cost(models.Model):
    """Tracks costs in US dollars for API calls"""

    # Required
    cost_type = models.ForeignKey(CostType, on_delete=models.CASCADE)
    count = models.IntegerField(default=1)

    # Automatically added/calculated
    date_incurred = models.DateField(auto_now_add=True)
    usd_cost = models.DecimalField(max_digits=12, decimal_places=6)

    # Optional, for aggregation and reporting
    user = models.ForeignKey(User, on_delete=models.CASCADE, null=True, blank=True)
    feature = models.CharField(
        max_length=50, null=True, blank=True, choices=FEATURE_CHOICES
    )

    # Optional, for debugging purposes
    request_id = models.CharField(max_length=50, null=True, blank=True)
    message = models.ForeignKey(
        "chat.Message", on_delete=models.CASCADE, null=True, blank=True
    )
    document = models.ForeignKey(
        "librarian.Document", on_delete=models.CASCADE, null=True, blank=True
    )

    objects = CostManager()

    def __str__(self):
        user_str = self.user.username if self.user else _("Otto")
        return f"{user_str} - {self.feature} - {self.cost_type.name} - {display_cad_cost(self.usd_cost)}"


class Pilot(models.Model):
    """For pilot governance. Pilot users will have a FK to this model."""

    pilot_id = models.CharField(max_length=50, unique=True)
    name = models.CharField(max_length=100)
    service_unit = models.TextField(null=True, blank=True)
    description = models.TextField(null=True, blank=True)
    start_date = models.DateField(null=True)
    end_date = models.DateField(null=True)

    def __str__(self):
        return self.name

    @property
    def user_count(self):
        return User.objects.filter(pilot=self).count()

    @property
    def total_cost(self):
        return display_cad_cost(Cost.objects.get_pilot_cost(self))



=== Contents of django\otto\rules.py ===
"""
Permissions-related rules for Otto apps
See https://github.com/dfunckt/django-rules
"""

from django.conf import settings

from rules import add_perm, is_group_member, predicate

from librarian.models import LibraryUserRole

# AC-16 & AC-16(2): Real-time enforcement of modified security attributes
# AC-3(7): Custom permission predicates and rules for role-based access control

ADMINISTRATIVE_PERMISSIONS = {
    "otto.manage_users",
    "librarian.manage_public_libraries",
    "librarian.manage_library_users",
}


@predicate
def accepted_terms(user):
    return user.accepted_terms_date is not None


# AC-16(2): Security Attribute Modification
# "is_group_member" returns a predicate
is_admin = is_group_member("Otto admin")
is_data_steward = is_group_member("Data steward")

add_perm("otto.manage_users", is_admin)
add_perm("otto.access_otto", accepted_terms)


@predicate
def can_view_app(user, app):
    if is_admin(user):
        return app.prod_ready or not settings.IS_PROD
    if settings.IS_PROD:
        return app.prod_ready and (app.visible_to_all or can_access_app(user, app))
    return app.visible_to_all or can_access_app(user, app)


@predicate
def can_access_app(user, app):
    if is_admin(user):
        return app.prod_ready or not settings.IS_PROD
    if settings.IS_PROD:
        return app.prod_ready and is_group_member(app.user_group.name)(user)
    return is_group_member(app.user_group.name)(user)


add_perm("otto.view_app", can_view_app)
add_perm("otto.access_app", can_access_app)


# AI Assistant
@predicate
def can_access_chat(user, chat):
    return chat.user == user


@predicate
def can_access_message(user, message):
    return message.chat.user == user


@predicate
def can_access_file(user, file):
    return file.message.chat.user == user


add_perm("chat.access_chat", can_access_chat)
add_perm("chat.access_message", can_access_message)
add_perm("chat.access_file", can_access_file)

# Template wizard
add_perm(
    "template_wizard.access_lex_wizard",
    is_group_member("Litigation briefing user") | is_admin,
)


# Librarian
@predicate
def is_library_viewer(user, library):
    return LibraryUserRole.objects.filter(
        user=user, library=library, role="viewer"
    ).exists()


@predicate
def is_library_contributor(user, library):
    return LibraryUserRole.objects.filter(
        user=user, library=library, role="contributor"
    ).exists()


@predicate
def is_library_admin(user, library):
    return LibraryUserRole.objects.filter(
        user=user, library=library, role="admin"
    ).exists()


@predicate
def is_library_user(user, library):
    return LibraryUserRole.objects.filter(user=user, library=library).exists()


@predicate
def can_manage_public_libraries(user):
    return is_admin(user) or is_data_steward(user)


@predicate
def can_change_publicity(user, library):
    if not library.id:
        return can_manage_public_libraries(user)
    return can_manage_public_libraries(user) and (
        is_library_admin(user, library) or is_admin(user)
    )


@predicate
def can_view_library(user, library):
    return library.is_public or is_library_user(user, library)


@predicate
def can_edit_library(user, library):
    if library.is_public:
        if is_admin(user):
            return True
        return can_manage_public_libraries(user) and (
            is_library_admin(user, library) or is_library_contributor(user, library)
        )
    return is_library_admin(user, library) or is_library_contributor(user, library)


@predicate
def can_delete_library(user, library):
    if library.is_default_library:
        return False
    if library.is_public:
        if is_admin(user):
            return True
        return can_manage_public_libraries(user) and is_library_admin(user, library)
    return is_library_admin(user, library)


@predicate
def can_edit_data_source(user, data_source):
    # If they can edit the library, they can edit a data_source
    return can_edit_library(user, data_source.library)


@predicate
def can_delete_data_source(user, data_source):
    if data_source.library.is_default_library:
        return is_admin(user)
    return can_edit_library(user, data_source.library)


@predicate
def can_edit_document(user, document):
    return can_edit_library(user, document.data_source.library)


@predicate
def can_delete_document(user, document):
    return can_edit_library(user, document.data_source.library)


@predicate
def can_manage_library_users(user, library):
    if library.is_public:
        if is_admin(user):
            return True
        return can_manage_public_libraries(user) and is_library_admin(user, library)
    return is_library_admin(user, library)


@predicate
def can_download_document(user, document):
    return can_view_library(user, document.data_source.library)


add_perm("librarian.manage_public_libraries", can_manage_public_libraries)
add_perm("librarian.change_publicity", can_change_publicity)
add_perm("librarian.view_library", can_view_library)
add_perm("librarian.edit_library", can_edit_library)
add_perm("librarian.delete_library", can_delete_library)
add_perm("librarian.edit_data_source", can_edit_data_source)
add_perm("librarian.delete_data_source", can_delete_data_source)
add_perm("librarian.edit_document", can_edit_document)
add_perm("librarian.delete_document", can_delete_document)
add_perm("librarian.manage_library_users", can_manage_library_users)
add_perm("librarian.download_document", can_download_document)



=== Contents of django\otto\secure_models.py ===
import uuid

from django.conf import settings
from django.contrib.auth import get_user_model
from django.contrib.auth.models import Permission
from django.contrib.contenttypes.models import ContentType
from django.core.exceptions import PermissionDenied
from django.db import models, transaction
from django.db.models import Q
from django.utils import timezone
from django.utils.translation import gettext_lazy as _

from structlog import get_logger

logger = get_logger(__name__)


class AccessKey:
    def __init__(self, user=None, bypass=False):
        if not user and not bypass:
            logger.error("User or bypass must be provided.")
            raise ValueError("User or bypass must be provided.")

        self.user = user
        self.bypass = bypass


class AccessControl(models.Model):
    CAN_VIEW = "can_view"
    CAN_CHANGE = "can_change"
    CAN_DELETE = "can_delete"

    PERMISSION_CHOICES = [
        (CAN_VIEW, "Can view"),
        (CAN_CHANGE, "Can change"),
        (CAN_DELETE, "Can delete"),
    ]

    user = models.ForeignKey(get_user_model(), on_delete=models.CASCADE)
    can_view = models.BooleanField(default=False)
    can_change = models.BooleanField(default=False)
    can_delete = models.BooleanField(default=False)
    content_type = models.ForeignKey(ContentType, on_delete=models.CASCADE)
    object_id = models.UUIDField()
    reason = models.CharField(max_length=255, blank=True, null=True)
    modified_at = models.DateTimeField(auto_now=True)
    modified_by = models.ForeignKey(
        settings.AUTH_USER_MODEL,
        on_delete=models.SET_NULL,
        blank=True,
        null=True,
        related_name="access_controls_modified_by",
    )

    class Meta:
        # Index the user and content object fields for faster lookups
        indexes = [models.Index(fields=["user", "object_id"])]
        unique_together = ("user", "object_id")

    def __str__(self):
        return f"{self.user.upn} - {self.content_type.model} Access"

    @transaction.atomic
    def save(self, *args, **kwargs):
        action = "C" if not self.pk else "U"
        super().save(*args, **kwargs)

        # Given self.content_type and object_id, get the content_object
        content_object = self.content_type.get_object_for_this_type(pk=self.object_id)

        AccessControlLog.objects.create(
            upn=self.user.upn,
            action=action,
            can_view=self.can_view,
            can_change=self.can_change,
            can_delete=self.can_delete,
            content_object=str(content_object),
            reason=self.reason,
            modified_by=self.modified_by.upn if self.modified_by else None,
            modified_at=timezone.now(),
        )

    @transaction.atomic
    def delete(self, reason, *args, **kwargs):
        # Log deletion before actual deletion
        AccessControlLog.objects.create(
            upn=self.user.upn,
            action="D",
            can_view=self.can_view,
            can_change=self.can_change,
            can_delete=self.can_delete,
            content_type=self.content_type,
            object_id=self.object_id,
            content_object=str(self.content_object),
            reason=reason,
            modified_by=self.modified_by.upn if self.modified_by else None,
            modified_at=timezone.now(),
        )

        super().delete(*args, **kwargs)

    @classmethod
    def valid_permissions(cls):
        return [cls.CAN_VIEW, cls.CAN_CHANGE, cls.CAN_DELETE]

    @classmethod
    @transaction.atomic
    def grant_permissions(
        cls,
        user,
        content_object,
        required_permissions,
        modified_by=None,
        reason=None,
    ):
        """
        Grant permissions
        AccessControl.grant_permissions(
            user,
            app_instance,
            required_permissions=['can_view', 'can_change', 'can_delete', 'can_add'],
            modified_by=current_user,
            reason="Granting permissions"
        )
        """

        # Ensure that at least one permission is specified
        if not required_permissions:
            logger.error("At least one permission should be granted.")
            raise ValueError("At least one permission should be granted.")

        # Validate that the provided permissions are valid
        valid_permissions = set(cls.valid_permissions())
        if not set(required_permissions).issubset(valid_permissions):
            logger.error("Invalid permissions specified.")
            raise ValueError("Invalid permissions specified.")

        access_control, created = cls.objects.get_or_create(
            user=user,
            content_type=ContentType.objects.get_for_model(content_object),
            object_id=content_object.pk,
            defaults={permission: True for permission in required_permissions},
            modified_by=modified_by,
            reason=reason,
        )

        if not created:
            # Update existing record with the new permissions
            for permission in valid_permissions:
                setattr(access_control, permission, permission in required_permissions)

            access_control.modified_by = modified_by
            access_control.reason = reason
            access_control.save()

        # Update the many-to-many relationship in the content_object
        content_object.access_controls.add(access_control)

        return

    @classmethod
    @transaction.atomic
    def revoke_permissions(
        cls,
        user,
        content_object,
        revoked_permissions=None,
        modified_by=None,
        reason=None,
    ):
        """
        Revoke permissions
        AccessControl.revoke_permissions(
            user,
            app_instance,
            revoked_permissions=['can_view', 'can_change', 'can_delete'],
            modified_by=current_user,
            reason="Revoking permissions"
        )
        """

        # If revoked_permissions is not provided, revoke all permissions
        if revoked_permissions is None:
            revoked_permissions = cls.valid_permissions()

        # Validate that the provided permissions are valid
        valid_permissions = set(cls.valid_permissions())
        if not set(revoked_permissions).issubset(valid_permissions):
            logger.error("Invalid permissions specified.")
            raise ValueError("Invalid permissions specified.")

        access_control = cls.objects.filter(
            user=user,
            content_type=ContentType.objects.get_for_model(content_object),
            object_id=content_object.id,
        ).first()

        if access_control:
            # Revoke the specified permissions
            for permission in revoked_permissions:
                setattr(access_control, permission, False)

                # Dynamically generate the permission string for the revoked permission
                permission_string = f"{content_object._meta.app_label}.{permission}_{content_object._meta.model_name}"

                # Remove the permission from the user
                user.user_permissions.remove(
                    Permission.objects.get(codename=permission_string)
                )

            # Set modified_by and reason if provided
            access_control.modified_by = modified_by
            access_control.reason = reason
            access_control.save()

            # Update the many-to-many relationship in the content_object
            content_object.access_controls.remove(access_control)

            # Check if all can_ fields are False, then delete the record
            if all(
                not getattr(access_control, permission)
                for permission in valid_permissions
            ):
                access_control.delete()

    @classmethod
    def check_permissions(cls, user, content_object, required_permissions):
        """
        Check permissions
        required_permissions = ['can_view', 'can_add']
        if AccessControl.check_permissions(user, app_instance, required_permissions):
            # User has the required permissions
            pass
        """

        access_control = cls.objects.filter(
            user=user,
            content_type=ContentType.objects.get_for_model(content_object),
            object_id=content_object.id,
        ).first()

        if access_control:
            return all(
                getattr(access_control, permission)
                for permission in required_permissions
            )

        return False


class AccessControlLog(models.Model):
    ACTION_CHOICES = [
        ("C", _("Create")),
        ("U", _("Update")),
        ("D", _("Delete")),
    ]
    upn = models.CharField(max_length=255)
    action = models.CharField(max_length=1, choices=ACTION_CHOICES)
    can_view = models.BooleanField(default=False)
    can_change = models.BooleanField(default=False)
    can_delete = models.BooleanField(default=False)
    content_object = models.CharField(max_length=255)
    reason = models.CharField(max_length=255, blank=True, null=True)
    modified_by = models.CharField(max_length=255, blank=True, null=True)
    modified_at = models.DateTimeField(auto_now_add=True)

    def __str__(self):
        timestamp = self.modified_at.strftime("%Y-%m-%d %H:%M:%S")
        return f"{timestamp} - {self.get_action_display()}: {self.upn} - {self.content_object}"


class SecureManager(models.Manager):

    def _apply_row_level_security(self, access_key: AccessKey, query: Q):
        if not access_key.bypass:
            query &= Q(
                access_controls__user=access_key.user,
                access_controls__content_type=ContentType.objects.get_for_model(
                    self.model
                ),
                access_controls__object_id=models.F("id"),
                access_controls__can_view=True,
            )
        return query

    def all(self, access_key: AccessKey, **kwargs):
        query = self._apply_row_level_security(access_key, Q(**kwargs))
        return super().filter(query)

    def get(self, access_key: AccessKey, **kwargs):
        query = self._apply_row_level_security(access_key, Q(**kwargs))
        return super().get(query)

    def filter(self, access_key: AccessKey, **kwargs):
        query = self._apply_row_level_security(access_key, Q(**kwargs))
        return super().filter(query)

    def create(self, access_key: AccessKey, **kwargs):
        if not access_key.bypass:

            permission = Permission.objects.get(
                content_type=ContentType.objects.get_for_model(self.model),
                codename=f"add_{self.model._meta.model_name}",
            )

            if permission not in access_key.user.user_permissions.all():
                raise PermissionError(
                    "You do not have permission to create this object."
                )

        kwargs["id"] = uuid.uuid4()
        instance = self.model(**kwargs)
        instance.save(AccessKey(bypass=True))
        if not access_key.bypass:
            instance.grant_ownership_to(
                access_key,
                modified_by=access_key.user,
                reason="Owner of the object.",
            )
        return instance


class SecureModel(models.Model):
    # Primary key needs to be UUID for secure model to minimize the risk of ID guessing
    id = models.UUIDField(primary_key=True, editable=False)
    objects = SecureManager()
    access_controls = models.ManyToManyField(AccessControl)

    class Meta:
        abstract = True

    def _check_permissions(self, access_key: AccessKey, permission: "str"):
        if not access_key or access_key.bypass:
            return

        if not AccessControl.check_permissions(access_key.user, self, [permission]):
            raise PermissionError(
                f"You do not have permission to {permission.lower()} this object."
            )

    def save(self, access_key: AccessKey, **kwargs):
        self._check_permissions(access_key, AccessControl.CAN_CHANGE)
        super().save(**kwargs)

    def delete(self, access_key: AccessKey, **kwargs):
        self._check_permissions(access_key, AccessControl.CAN_DELETE)
        super().delete(**kwargs)

    def _grant_permissions(self, user, permission, modified_by=None, reason=None):
        AccessControl.grant_permissions(
            user,
            self,
            required_permissions=[permission],
            modified_by=modified_by,
            reason=reason,
        )

    def _revoke_permissions(self, user, permission, modified_by=None, reason=None):
        AccessControl.revoke_permissions(
            user,
            self,
            revoked_permissions=[permission],
            modified_by=modified_by,
            reason=reason,
        )

    def grant_ownership_to(self, access_key: AccessKey, modified_by=None, reason=None):
        valid_permissions = AccessControl.valid_permissions()
        AccessControl.grant_permissions(
            access_key.user,
            self,
            required_permissions=valid_permissions,
            modified_by=modified_by,
            reason=reason,
        )

    def grant_view_to(self, access_key: AccessKey, modified_by=None, reason=None):
        self._grant_permissions(
            access_key.user, AccessControl.CAN_VIEW, modified_by, reason
        )

    @classmethod
    def grant_create_to(cls, access_key: AccessKey):
        user = access_key.user
        permission = Permission.objects.get(
            content_type=ContentType.objects.get_for_model(cls),
            codename=f"add_{cls._meta.model_name}",
        )
        user.user_permissions.add(permission)
        user.refresh_from_db()

    def grant_change_to(self, access_key: AccessKey, modified_by=None, reason=None):
        self._grant_permissions(
            access_key.user, AccessControl.CAN_CHANGE, modified_by, reason
        )

    def grant_delete_to(self, access_key: AccessKey, modified_by=None, reason=None):
        self._grant_permissions(
            access_key.user, AccessControl.CAN_DELETE, modified_by, reason
        )

    def revoke_view_from(self, access_key: AccessKey, modified_by=None, reason=None):
        self._revoke_permissions(
            access_key.user, AccessControl.CAN_VIEW, modified_by, reason
        )

    @classmethod
    def revoke_create_from(cls, access_key: AccessKey):
        user = access_key.user
        permission = Permission.objects.get(
            content_type=ContentType.objects.get_for_model(cls),
            codename=f"add_{cls._meta.model_name}",
        )
        user.user_permissions.remove(permission)
        user.refresh_from_db()

    def revoke_change_from(self, access_key: AccessKey, modified_by=None, reason=None):
        self._revoke_permissions(
            access_key.user, AccessControl.CAN_CHANGE, modified_by, reason
        )

    def revoke_delete_from(self, access_key: AccessKey, modified_by=None, reason=None):
        self._revoke_permissions(
            access_key.user, AccessControl.CAN_DELETE, modified_by, reason
        )

    @classmethod
    def can_be_created_by(cls, access_key: AccessKey):
        user = access_key.user
        permission = Permission.objects.get(
            content_type=ContentType.objects.get_for_model(cls),
            codename=f"add_{cls._meta.model_name}",
        )
        return permission in user.user_permissions.all()

    def can_be_viewed_by(self, access_key: AccessKey):
        return AccessControl.check_permissions(
            access_key.user, self, [AccessControl.CAN_VIEW]
        )

    def can_be_changed_by(self, access_key: AccessKey):
        return AccessControl.check_permissions(
            access_key.user, self, [AccessControl.CAN_CHANGE]
        )

    def can_be_deleted_by(self, access_key: AccessKey):
        return AccessControl.check_permissions(
            access_key.user, self, [AccessControl.CAN_DELETE]
        )


class SecureRelatedManager(models.Manager):
    def _apply_row_level_security(self, access_key: AccessKey, queryset, permission):
        if not access_key.bypass:
            # Collect parent IDs that the user has permission to access
            parent_ids = set()
            parents = []
            for obj in queryset:
                parents = obj.get_permission_parents()
                parent_ids.update(
                    parent.id
                    for parent in parents
                    if AccessControl.check_permissions(
                        access_key.user, parent, [permission]
                    )
                )

            # Dynamically determine the related field names and apply the filter
            parent_field_names = [
                field.name
                for field in queryset.model._meta.fields
                if isinstance(field, models.ForeignKey)
                and field.related_model in [parent.__class__ for parent in parents]
            ]

            # Apply the filter for each parent field name
            filter_conditions = {
                f"{field_name}__id__in": parent_ids for field_name in parent_field_names
            }
            queryset = queryset.filter(**filter_conditions)

        return queryset

    def all(self, access_key: AccessKey, **kwargs):
        queryset = super().all(**kwargs)
        return self._apply_row_level_security(
            access_key, queryset, AccessControl.CAN_VIEW
        )

    def get(self, access_key: AccessKey, **kwargs):
        queryset = super().filter(**kwargs)
        queryset = self._apply_row_level_security(
            access_key, queryset, AccessControl.CAN_VIEW
        )
        try:
            return queryset.get()
        except queryset.model.DoesNotExist:
            raise PermissionDenied("You do not have permission to view this object.")

    def filter(self, access_key: AccessKey, **kwargs):
        queryset = super().filter(**kwargs)
        return self._apply_row_level_security(
            access_key, queryset, AccessControl.CAN_VIEW
        )

    def create(self, access_key: AccessKey, **kwargs):

        instance = self.model(**kwargs)

        if not access_key.bypass:

            # Check if the user's access key has permission to the parent objects
            for parent in instance.get_permission_parents():
                if not AccessControl.check_permissions(
                    access_key.user, parent, [AccessControl.CAN_CHANGE]
                ):
                    raise PermissionDenied(
                        "You do not have permission to create this object."
                    )

        instance.save(AccessKey(bypass=True))
        return instance


class SecureRelatedModel(models.Model):
    objects = SecureRelatedManager()

    class Meta:
        abstract = True

    def get_permission_parents(self):
        """
        Method to be overridden by subclasses to return the parent objects
        against which permissions should be checked.
        """
        logger.error("Subclasses must implement get_permission_parents method.")
        raise NotImplementedError(
            "Subclasses must implement get_permission_parents method."
        )

    def check_related_permissions(self, access_key, permission):
        if access_key.bypass:
            return

        for parent in self.get_permission_parents():
            if not AccessControl.check_permissions(
                access_key.user, parent, [permission]
            ):
                logger.error(
                    f"Invalid permission ({permission.lower()}) to object for {access_key.user}."
                )
                raise PermissionDenied(
                    f"You do not have permission to {permission.lower()} this object."
                )

    def save(self, access_key: AccessKey, *args, **kwargs):
        self.check_related_permissions(access_key, AccessControl.CAN_CHANGE)
        super().save(*args, **kwargs)

    def delete(self, access_key: AccessKey, *args, **kwargs):
        self.check_related_permissions(access_key, AccessControl.CAN_DELETE)
        super().delete(*args, **kwargs)



=== Contents of django\otto\settings.py ===
"""
Django settings for otto project.

Generated by 'django-admin startproject' using Django 4.1.4.

For more information on this file, see
https://docs.djangoproject.com/en/4.1/topics/settings/

For the full list of settings and their values, see
https://docs.djangoproject.com/en/4.1/ref/settings/
"""

import logging
import os
import sys
from pathlib import Path
from urllib.parse import quote, urlparse, urlunparse

import structlog
import yaml
from dotenv import load_dotenv
from storages.backends.azure_storage import AzureStorage

from .utils import logging as logging_utils

BASE_DIR = Path(__file__).resolve().parent.parent

# Set the logging level for all azure-* libraries
logger = logging.getLogger("azure.identity")
logger.setLevel(logging.ERROR)

OTTO_VERSION = "v0"

# Load the version from the version.yaml file
version_file_path = os.path.join(BASE_DIR, "version.yaml")
if os.path.exists(version_file_path):
    with open(version_file_path, "r") as file:
        data = yaml.safe_load(file)
        OTTO_VERSION = data.get("version")

# Load environment variables from .env file
load_dotenv(os.path.join(BASE_DIR, ".env"))
# Check for a variable we only set in the .env file to see if it exists
if os.environ.get("DJANGODB_NAME") is None:
    try:
        # These are enough to run the CI tests
        load_dotenv(os.path.join(BASE_DIR, ".env.example"))
        print("Using .env.example")
    except:
        raise Exception("No .env or .env.example file found. Shutting down.")

ENVIRONMENT = os.environ.get("ENV", "LOCAL").upper()
IS_RUNNING_IN_CELERY = sys.argv and "celery" in sys.argv[0]
IS_RUNNING_IN_GITHUB = "GITHUB_ACTIONS" in os.environ
IS_RUNNING_IN_DEVOPS = "DEVOPS_PIPELINES" in os.environ
IS_RUNNING_TESTS = "test" in sys.argv or any("pytest" in arg for arg in sys.argv)
# Needs to be here for some rules checks. Just keep False for now.
IS_PROD = False

SITE_URL = urlparse(os.environ.get("SITE_URL"))

AZURE_OPENAI_KEY = os.environ.get("AZURE_OPENAI_KEY")
AZURE_COGNITIVE_SERVICE_KEY = os.environ.get("AZURE_COGNITIVE_SERVICE_KEY")
SECRET_KEY = os.environ.get("DJANGO_SECRET_KEY", "django-secret-key")
AZURE_ACCOUNT_KEY = os.environ.get(
    "AZURE_ACCOUNT_KEY"
)  # Azure as default storage requires this name to be AZURE_ACCOUNT_KEY

# AC-2: Entra Integration
ENTRA_CLIENT_ID = os.environ.get("ENTRA_CLIENT_ID")
ENTRA_CLIENT_SECRET = os.environ.get("ENTRA_CLIENT_SECRET")
ENTRA_AUTHORITY = os.environ.get("ENTRA_AUTHORITY")
ENTRA_REDIRECT_URI = SITE_URL.geturl() + os.environ.get("ENTRA_REDIRECT_URI")
AZURE_AUTH = {
    "CLIENT_ID": ENTRA_CLIENT_ID,
    "CLIENT_SECRET": ENTRA_CLIENT_SECRET,
    "REDIRECT_URI": ENTRA_REDIRECT_URI,
    "SCOPES": ["User.Read"],
    "AUTHORITY": ENTRA_AUTHORITY,
    "USERNAME_ATTRIBUTE": "userPrincipalName",  # The AAD attribute or ID token claim you want to use as the value for the user model `USERNAME_FIELD`
    "PUBLIC_PATHS": [os.environ.get("ENTRA_REDIRECT_URI"), "/welcome/"],
    "USER_MAPPING_FN": "otto.utils.auth.map_entra_to_django_user",  # Optional, path to the function used to map the AAD to Django attributes
}
LOGIN_URL = "/azure_auth/login"
LOGIN_REDIRECT_URL = "/"  # Or any other endpoint

# Session timeout. 24 hours is allowed for WCAG and meets security requirement
SESSION_COOKIE_AGE = 60 * 60 * 24  # 24 hours, in seconds
SESSION_SAVE_EVERY_REQUEST = True  # Reset the timeout on every request

# OpenAI
AZURE_OPENAI_ENDPOINT = os.environ.get("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_VERSION = os.environ.get("AZURE_OPENAI_VERSION")
# TODO: Replace with Cost model (this is used in Template Wizard)
OPENAI_COST_PER_TOKEN = 0.0020 / 1000
OPENAI_EMBEDDING_COST_PER_TOKEN = 0.0004 / 1000

DEFAULT_CHAT_MODEL = "gpt-4o"
USD_TO_CAD = 1.36


# Azure Cognitive Services
AZURE_COGNITIVE_SERVICE_ENDPOINT = os.environ.get("AZURE_COGNITIVE_SERVICE_ENDPOINT")
AZURE_COGNITIVE_SERVICE_REGION = os.environ.get("AZURE_COGNITIVE_SERVICE_REGION")

AZURE_ACCOUNT_NAME = os.environ.get(
    "AZURE_STORAGE_ACCOUNT_NAME", ""
)  # Azure as default storage requires this name to be AZURE_ACCOUNT_NAME
AZURE_CONTAINER = os.environ.get(
    "AZURE_STORAGE_CONTAINER", ""
)  # Azure as default storage requires this name to be AZURE_STORAGE_CONTAINER

DEBUG = os.environ.get("DEBUG", "False") == "True"
DEBUG_PROPAGATE_EXCEPTIONS = True

ALLOWED_HOSTS = [SITE_URL.hostname, "localhost", "127.0.0.1"]

# AC-2: Entra Integration Helper App Configuration
AUTHENTICATION_BACKENDS = [
    "azure_auth.backends.AzureBackend",
    "rules.permissions.ObjectPermissionBackend",
]

if IS_RUNNING_TESTS:
    AUTHENTICATION_BACKENDS = [
        "django.contrib.auth.backends.ModelBackend",
        "rules.permissions.ObjectPermissionBackend",
    ]

# Application definition
INSTALLED_APPS = [
    # Third-party apps
    "daphne",
    "django_structlog",
    "modeltranslation",
    "django_prometheus",
    "django.contrib.admin",
    "django.contrib.auth",
    "django.contrib.contenttypes",
    "django.contrib.sessions",
    "django.contrib.messages",
    "django.contrib.staticfiles",
    "django.contrib.postgres",
    "corsheaders",
    "autocomplete",
    "rules.apps.AutodiscoverRulesConfig",
    "azure_auth",  # AC-2: Entra Integration Helper App
    # Otto apps
    "otto",
    "librarian",
    "chat",
    "laws",
    "case_prep",
    "template_wizard",
    # Third-party apps
    "channels",
    "django_cleanup.apps.CleanupConfig",
    "text_extractor",
    "django_celery_beat",
]

MIDDLEWARE = [
    "corsheaders.middleware.CorsMiddleware",
    "django_prometheus.middleware.PrometheusBeforeMiddleware",
    "django.middleware.security.SecurityMiddleware",
    "django.contrib.sessions.middleware.SessionMiddleware",
    # AC-2 & AC-3: Authentication, AC-14: Limited Access
    "django.contrib.auth.middleware.AuthenticationMiddleware",
    # Static files
    "whitenoise.middleware.WhiteNoiseMiddleware",
    # AC-3 & AC-14: Limited Access to handle login flows: redirect to login page, use Azure login, accept terms to use
    # AC-3(7): Custom middleware for enforcing role-based access control
    "otto.utils.auth.RedirectToLoginMiddleware",
    # AC-2 & AC-14: Azure AD Integration to protect entire site by default
    "azure_auth.middleware.AzureMiddleware",
    "otto.utils.auth.AcceptTermsMiddleware",
    "django.middleware.common.CommonMiddleware",
    "django.middleware.csrf.CsrfViewMiddleware",
    "django.contrib.messages.middleware.MessageMiddleware",
    "django.middleware.clickjacking.XFrameOptionsMiddleware",
    "django.middleware.locale.LocaleMiddleware",
    "django_prometheus.middleware.PrometheusAfterMiddleware",
    # AU-6: Aupports structured logging, facilitating the review and analysis of audit records for inappropriate or unusual activity
    "django_structlog.middlewares.RequestMiddleware",
]

if IS_RUNNING_TESTS:
    MIDDLEWARE.remove("azure_auth.middleware.AzureMiddleware")

CORS_ORIGIN_ALLOW_ALL = False
CORS_ORIGIN_WHITELIST = [
    "http://localhost:9000",
    "https://justipedia.gc.ca",
]


DEBUG_TOOLBAR = (
    os.environ.get("DEBUG_TOOLBAR", "False") == "True" and not IS_RUNNING_IN_CELERY
)

# If DEBUG_TOOLBAR is enabled, configure debug toolbar settings
if DEBUG_TOOLBAR:
    INSTALLED_APPS.append("debug_toolbar")
    MIDDLEWARE.append("debug_toolbar.middleware.DebugToolbarMiddleware")

    # Set INTERNAL_IPS based on DEBUG_TOOLBAR_IP_LIST or default to "127.0.0.1"
    INTERNAL_IPS = os.environ.get("DEBUG_TOOLBAR_IP_LIST", "127.0.0.1").split(",")

    # If DEBUG_TOOLBAR_IP_LIST is set to 127.0.0.1 and DEBUG_TOOLBAR is True,
    # the debug toolbar will only be visible for requests originating from the server machine (localhost),
    # restricting access to external devices and ensuring it's only available in local development environments.
    DEBUG_TOOLBAR_CONFIG = {
        "SHOW_COLLAPSED": True,
        "UPDATE_ON_FETCH": True,
        "RENDER_PANELS": False,
    }


ROOT_URLCONF = "otto.urls"

TEMPLATES = [
    {
        "BACKEND": "django.template.backends.django.DjangoTemplates",
        "DIRS": [os.path.join(BASE_DIR, "otto", "templates")],
        "APP_DIRS": True,
        "OPTIONS": {
            "context_processors": [
                "django.template.context_processors.debug",
                "django.template.context_processors.request",
                "django.contrib.auth.context_processors.auth",
                "django.contrib.messages.context_processors.messages",
                "otto.context_processors.otto_version",
            ],
        },
    },
]

WSGI_APPLICATION = "otto.wsgi.application"

ASGI_APPLICATION = "otto.asgi.application"


CHANNEL_LAYERS = {
    "default": {
        "BACKEND": "channels.layers.InMemoryChannelLayer",
    },
}

# Database
# https://docs.djangoproject.com/en/4.1/ref/settings/#databases

DATABASES = {
    "default": {
        "ENGINE": "django.db.backends.sqlite3",
        "NAME": BASE_DIR / "db.sqlite3",
        "TEST": {"NAME": "otto_test"},
    },
    "vector_db": {
        "ENGINE": "django.db.backends.sqlite3",
        "NAME": BASE_DIR / "db.sqlite3",
    },
}

# If the database is set in the environment variables, use that instead
if os.environ.get("DJANGODB_ENGINE") is not None:
    DATABASES["default"] = {
        "ENGINE": os.environ.get("DJANGODB_ENGINE"),
        "NAME": os.environ.get("DJANGODB_NAME"),
        "USER": os.environ.get("DJANGODB_USER"),
        # CosmosDB can't have the password quoted; it seems to handle this natively. TODO: Investigate to understand better
        "PASSWORD": os.environ.get("DJANGODB_PASSWORD", ""),
        "HOST": os.environ.get("DJANGODB_HOST"),
    }

    # Add the PORT and SSLMODE for CosmosDB, which only exist for DEV, UAT, and PROD
    if ENVIRONMENT in ["DEV", "UAT", "PROD"]:
        DATABASES["default"]["PORT"] = os.environ.get("DJANGODB_PORT")
        DATABASES["default"]["SSLMODE"] = "require"

if os.environ.get("VECTORDB_ENGINE") is not None:
    DATABASES["vector_db"] = {
        "ENGINE": os.environ.get("VECTORDB_ENGINE"),
        "NAME": os.environ.get("VECTORDB_NAME"),
        "USER": os.environ.get("VECTORDB_USER"),
        # Passwords for Postgres need to be quoted to handle special characters
        "PASSWORD": quote(os.environ.get("VECTORDB_PASSWORD", "")),
        "HOST": os.environ.get("VECTORDB_HOST"),
    }


# Password validation
# https://docs.djangoproject.com/en/4.1/ref/settings/#auth-password-validators

AUTH_PASSWORD_VALIDATORS = []


TIME_ZONE = "UTC"


REST_FRAMEWORK = {
    "DEFAULT_RENDERER_CLASSES": [
        "rest_framework.renderers.JSONRenderer",
        "rest_framework.renderers.BrowsableAPIRenderer",
    ],
}


# Internationalization
# https://docs.djangoproject.com/en/4.1/topics/i18n/

LANGUAGE_CODE = "en-ca"

TIME_ZONE = "UTC"

USE_I18N = True
USE_L10N = True
LANGUAGES = [
    ("en", "English"),
    ("fr", "French"),
]
LOCALE_PATHS = [
    os.path.join(BASE_DIR, "locale"),
]

USE_TZ = True


# Static files (CSS, JavaScript, Images)
# https://docs.djangoproject.com/en/4.1/howto/static-files/

PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))


STATIC_ROOT = os.path.join(BASE_DIR, "staticfiles")
STATIC_URL = "/static/"
# forever-cacheable files and compression support
STATICFILES_STORAGE = "whitenoise.storage.CompressedManifestStaticFilesStorage"

# Extra places for collectstatic to find static files.
STATICFILES_DIRS = []


X_FRAME_OPTIONS = "SAMEORIGIN"  # Required for iframe on same origin

# Default primary key field type
# https://docs.djangoproject.com/en/4.1/ref/settings/#default-auto-field

DEFAULT_AUTO_FIELD = "django.db.models.BigAutoField"

SESSION_ENGINE = "django.contrib.sessions.backends.db"

# Security

if SITE_URL.scheme == "https" and SITE_URL.port == None:
    CSRF_TRUSTED_ORIGINS = [urlunparse(SITE_URL)]
    SECURE_SSL_REDIRECT = True
    SESSION_COOKIE_SECURE = True
    CSRF_COOKIE_SECURE = True
    USE_X_FORWARDED_HOST = True
    SECURE_PROXY_SSL_HEADER = ("HTTP_X_FORWARDED_PROTO", "https")
    print("Using HTTPS")
else:
    CSRF_TRUSTED_ORIGINS = [urlunparse(SITE_URL)]
    SECURE_SSL_REDIRECT = False
    SESSION_COOKIE_SECURE = False
    CSRF_COOKIE_SECURE = False

# Default Storage needs to be a local directory for append to work
DEFAULT_FILE_STORAGE = "django.core.files.storage.FileSystemStorage"

# Azure blob storage needed for Translation
# We have already set AZURE_ACCOUNT_KEY, AZURE_ACCOUNT_NAME, AZURE_CONTAINER
AZURE_STORAGE = AzureStorage(
    account_name=AZURE_ACCOUNT_NAME,
    account_key=AZURE_ACCOUNT_KEY,
    azure_container=AZURE_CONTAINER,
)

# Media storage
MEDIA_ROOT = os.path.join(BASE_DIR, os.environ.get("MEDIA_ROOT", "media"))
if not os.path.exists(MEDIA_ROOT):
    os.makedirs(MEDIA_ROOT)

AUTH_USER_MODEL = "otto.User"

# REDIS

REDIS_URL = "redis://{host}:{port}/0".format(
    host=os.environ.get("REDIS_HOST", "redis"),
    port=os.environ.get("REDIS_PORT", "6379"),
)

# CELERY

CELERY_BROKER_URL = REDIS_URL
CELERY_RESULT_BACKEND = REDIS_URL
CELERY_ACCEPT_CONTENT = ["application/json"]
CELERY_TASK_SERIALIZER = "json"
CELERY_RESULT_SERIALIZER = "json"
CELERY_TIMEZONE = "UTC"

if IS_RUNNING_IN_GITHUB:
    CACHES = {
        "default": {
            "BACKEND": "otto.utils.cache.LocMemCache",
        }
    }
else:
    CACHES = {
        "default": {
            "BACKEND": "django_redis.cache.RedisCache",
            "LOCATION": REDIS_URL,
            "OPTIONS": {
                "CLIENT_CLASS": "django_redis.client.DefaultClient",
            },
            "KEY_PREFIX": f"otto_{ENVIRONMENT}",
        }
    }


DATA_UPLOAD_MAX_NUMBER_FIELDS = 10000
DATA_UPLOAD_MAX_NUMBER_FILES = 2000

# Logging

LOG_LEVEL = os.environ.get("LOG_LEVEL", "INFO")
CELERY_LOG_LEVEL = os.environ.get("CELERY_LOG_LEVEL", "INFO")
DJANGO_STRUCTLOG_CELERY_ENABLED = True
DJANGO_STRUCTLOG_COMMAND_LOGGING_ENABLED = True

LOGGING = {
    "version": 1,
    "disable_existing_loggers": True,
    "formatters": {
        "json_formatter": {
            "()": structlog.stdlib.ProcessorFormatter,
            "processor": structlog.processors.JSONRenderer(),
        },
        "console": {
            "()": structlog.stdlib.ProcessorFormatter,
            "processor": structlog.dev.ConsoleRenderer(),
        },
    },
    "handlers": {
        "console": {
            "class": "logging.StreamHandler",
            "formatter": "console",
        },
        "json": {
            "class": "logging.StreamHandler",
            "formatter": "json_formatter",
        },
        "null": {
            "class": "logging.NullHandler",
        },
    },
    "root": {
        "handlers": ["json"],
        "level": LOG_LEVEL,
        "stream": sys.stdout,
    },
}

if ENVIRONMENT == "LOCAL":
    LOGGING["root"]["handlers"] = ["console"]
elif IS_RUNNING_TESTS:
    LOGGING["root"]["handlers"] = ["null"]

# AU-6 & AU-7: Allows for the adjustment of log levels based on the environment and operational needs
structlog.configure(
    processors=[
        structlog.contextvars.merge_contextvars,
        structlog.stdlib.filter_by_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.CallsiteParameterAdder(
            [
                structlog.processors.CallsiteParameter.PATHNAME,
                structlog.processors.CallsiteParameter.FUNC_NAME,
                structlog.processors.CallsiteParameter.LINENO,
            ]
        ),
        logging_utils.merge_pathname_lineno_function_to_location,
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.stdlib.ProcessorFormatter.wrap_for_formatter,
    ],
    logger_factory=structlog.stdlib.LoggerFactory(),
    cache_logger_on_first_use=True,
)



=== Contents of django\otto\tasks.py ===
from django.core.management import call_command

from celery import shared_task


@shared_task
def sync_users():
    call_command("sync_users")



=== Contents of django\otto\translation.py ===
from modeltranslation.translator import TranslationOptions, register

from .models import App, CostType, Feature, SecurityLabel, UsageTerm


@register(App)
class AppTranslationOptions(TranslationOptions):
    fields = ("name",)


@register(Feature)
class FeatureTranslationOptions(TranslationOptions):
    fields = ("name", "description")


@register(UsageTerm)
class UsageTermTranslationOptions(TranslationOptions):
    fields = ("term_text",)


@register(SecurityLabel)
class SecurityLabelTranslationOptions(TranslationOptions):
    fields = ("name", "description", "acronym")


@register(CostType)
class CostTypeTranslationOptions(TranslationOptions):
    fields = ("name", "description", "unit_name")


# TODO: Seperate heading and text from model.

# @register(Notification)
# class NotificationTranslationOptions(TranslationOptions):
#     fields = ("heading", "text")



=== Contents of django\otto\urls.py ===
from django.conf import settings
from django.conf.urls.static import static
from django.contrib import admin
from django.urls import include, path
from django.views import defaults as default_views

from autocomplete import HTMXAutoComplete
from azure_auth.views import azure_auth_callback

from . import views

urlpatterns = [
    path("", views.index, name="index"),
    path("search/", views.topnav_search_inner, name="search_inner"),
    path("welcome/", views.welcome, name="welcome"),
    # AC-2: Entra Integration Helper App Configuration
    # AC-14: Login Page Accessibility
    path("azure_auth/login", views.login, name="login"),
    path("azure_auth/", include("azure_auth.urls")),
    path("accounts/login/callback/", azure_auth_callback, name="callback"),
    # path("admin/", admin.site.urls),
    path("librarian/", include("librarian.urls")),
    path("laws/", include("laws.urls")),
    path("case_prep/", include("case_prep.urls")),
    path("text_extractor/", include("text_extractor.urls")),
    path("template_wizard/", include("template_wizard.urls")),
    path("user_management/", views.manage_users, name="manage_users"),
    path("user_management/form/", views.manage_users_form, name="manage_users_form"),
    path(
        "user_management/form/<user_id>/",
        views.manage_users_form,
        name="manage_users_form",
    ),
    path("user_management/upload/", views.manage_users_upload, name="upload_users"),
    path(
        "user_management/download/", views.manage_users_download, name="download_users"
    ),
    path("user_management/pilots/", views.manage_pilots, name="manage_pilots"),
    path(
        "user_management/pilots/form/",
        views.manage_pilots_form,
        name="manage_pilots_form",
    ),
    path(
        "user_management/pilots/form/<pilot_id>/",
        views.manage_pilots_form,
        name="manage_pilots_form",
    ),
    path("user_management/costs/", views.cost_dashboard, name="cost_dashboard"),
    path("accept_terms/", views.accept_terms, name="accept_terms"),
    path("feedback/", views.message_feedback, name="user_feedback"),
    path("feedback/<message_id>/", views.message_feedback, name="user_feedback"),
    path("feedback_success/", views.feedback_success, name="feedback_success"),
    path(
        "notifications/<int:notification_id>/", views.notification, name="notification"
    ),
    path("notifications/", views.notifications, name="notifications"),
    path("i18n/", include("django.conf.urls.i18n")),
    path("chat/", include("chat.urls")),
    # exposes /metrics endpoint, accessible by anonymous users, restricted by ip addresses. See metrics/web.config and IIS's IP Address and Domain Restrictions
    path("", include("django_prometheus.urls")),
    *HTMXAutoComplete.url_dispatcher("ac"),
] + static(settings.STATIC_URL, document_root=settings.STATIC_ROOT)

if settings.DEBUG_TOOLBAR:
    urlpatterns.append(
        path("__debug__/", include("debug_toolbar.urls")),
    )

if settings.DEBUG:
    urlpatterns += [
        path(
            "400/",
            default_views.bad_request,
            kwargs={"exception": Exception("Bad Request")},
        ),
        path(
            "403/",
            default_views.permission_denied,
            kwargs={"exception": Exception("Permission Denied")},
        ),
        path(
            "404/",
            default_views.page_not_found,
            kwargs={"exception": Exception("Page Not Found")},
        ),
        path("500/", default_views.server_error),
    ]



=== Contents of django\otto\views.py ===
import csv
import io
from collections import defaultdict
from datetime import date, timedelta

from django.conf import settings
from django.contrib import messages
from django.contrib.auth import get_user_model
from django.contrib.auth.decorators import login_required
from django.contrib.auth.models import Group
from django.core.exceptions import ObjectDoesNotExist, ValidationError
from django.core.validators import validate_email
from django.db import models
from django.http import HttpRequest, HttpResponse
from django.shortcuts import get_object_or_404, redirect, render
from django.urls import reverse
from django.utils import timezone
from django.utils.translation import check_for_language, get_language
from django.utils.translation import gettext_lazy as _
from django.views.decorators.csrf import csrf_protect
from django.views.decorators.http import require_POST

from azure_auth.views import azure_auth_login as azure_auth_login
from structlog import get_logger

from otto.forms import FeedbackForm, PilotForm, UserGroupForm
from otto.metrics.activity_metrics import otto_access_total
from otto.metrics.feedback_metrics import otto_feedback_submitted_with_comment_total
from otto.models import FEATURE_CHOICES, App, Cost, CostType, Feature, Pilot, UsageTerm
from otto.utils.common import cad_cost, display_cad_cost
from otto.utils.decorators import permission_required

logger = get_logger(__name__)

User = get_user_model()


def welcome(request):
    # Bilingual landing page with login button
    return render(request, "welcome.html", {"next_url": request.GET.get("next", "/")})


def login(request: HttpRequest):
    # Wraps azure_auth login to allow for language selection
    lang_code = request.GET.get("lang")
    response = azure_auth_login(request)
    # See django.views.i18n.set_language for the source of this code
    if lang_code and check_for_language(lang_code):
        response.set_cookie(
            settings.LANGUAGE_COOKIE_NAME,
            lang_code,
            max_age=settings.LANGUAGE_COOKIE_AGE,
            path=settings.LANGUAGE_COOKIE_PATH,
            domain=settings.LANGUAGE_COOKIE_DOMAIN,
            secure=settings.LANGUAGE_COOKIE_SECURE,
            httponly=settings.LANGUAGE_COOKIE_HTTPONLY,
            samesite=settings.LANGUAGE_COOKIE_SAMESITE,
        )
    return response


def get_categorized_features(user):
    categories = defaultdict(list)
    category_choices = dict(Feature.CATEGORY_CHOICES)

    # Fetch all features along with their related apps
    features = Feature.objects.select_related("app").order_by("id")

    # Loop over the features and add them to the appropriate category
    for feature in features:
        if user.has_perm("otto.view_app", feature.app):
            categories[feature.category].append(feature)

    # Now create the new list of dicts with updated category titles
    categorized_features = [
        {
            "category_id": category,
            "category_title": category_choices.get(category, category.capitalize()),
            "features": features,
        }
        for category, features in categories.items()
    ]

    return categorized_features


def index(request):
    otto_access_total.labels(user=request.user.upn).inc()
    return render(
        request,
        "index.html",
        {
            "hide_breadcrumbs": True,
            "categorized_features": get_categorized_features(request.user),
        },
    )


def topnav_search_inner(request):
    return render(
        request,
        "components/search_inner.html",
        {"categorized_features": get_categorized_features(request.user)},
    )


@csrf_protect
def accept_terms(request):

    if request.method == "POST":
        logger.info("Terms of conditions were accepted")
        request.user.accepted_terms_date = timezone.now()
        request.user.save()

        redirect_url = request.POST.get("redirect_url") or "/"
        return redirect(redirect_url)

    redirect_url = request.GET.get("next", "/")
    usage_terms = UsageTerm.objects.all()

    return render(
        request,
        "accept_terms.html",
        {
            "hide_breadcrumbs": True,
            "redirect_url": redirect_url,
            "usage_terms": usage_terms,
        },
    )


@csrf_protect
@login_required
def message_feedback(request: HttpRequest, message_id=None):
    if request.method == "POST":
        logger.info("Feedback form submitted", message_id=message_id)
        form = FeedbackForm(request.user, message_id, request.POST)

        if form.is_valid():
            date_and_time = timezone.now().strftime("%Y%m%d-%H%M%S")
            form.cleaned_data["created_at"] = date_and_time
            form.save()

            otto_feedback_submitted_with_comment_total.labels(
                user=request.user.upn
            ).inc()

            if message_id is None:
                return redirect("feedback_success")
            else:
                return HttpResponse()
    else:
        form = FeedbackForm(request.user, message_id)

    return render(
        request,
        "feedback.html",
        {
            "form": form,
            "message_id": message_id,
            "hide_breadcrumbs": True,
            "hide_nav": message_id is not None,
        },
    )


@login_required
def feedback_success(request):
    return render(request, "feedback_success.html")


@login_required
def notification(request, notification_id):
    """
    For handling deleting of notifications
    """
    notification = request.user.notifications.get(id=notification_id)
    if request.method == "DELETE":
        notification.delete()
    no_more_notifications = not request.user.notifications.exists()
    logger.debug("no more notifications?", has_notifications=no_more_notifications)
    return notifications(request, hide=no_more_notifications)


@login_required
def notifications(request, hide=False):
    """
    Updates the notifications badge and list of notifications
    e.g. on page load, after notification icon clicked, during polling, etc.
    """
    return render(
        request,
        "components/notifications_update.html",
        {
            "notifications": request.user.notifications.all().order_by("-created_at"),
            # Expand the notifications dropdown if there are any errors
            "show_notifications": request.user.notifications.filter(
                category="error"
            ).exists(),
            "hide_notifications": hide,
        },
    )


# AC-3(7), AC-16, & AC-16(2): Allows authorized administrators to modify user groups and roles
@permission_required("otto.manage_users")
def manage_users(request):
    if request.method == "POST":
        form = UserGroupForm(request.POST)
        if form.is_valid():
            # The form contains users (multiple choice, named "email" but value is "id")
            # and groups (multiple choice, named "group" but value is "id")
            # We want to add the selected groups to the selected users
            users = form.cleaned_data["email"]
            groups = form.cleaned_data["group"]
            for user in users:
                logger.info("Updating user groups", user=user, groups=groups)
                user.groups.clear()
                user.groups.add(*groups)
                if "pilot" in form.cleaned_data:
                    user.pilot = form.cleaned_data["pilot"]
                    user.save()
        else:
            raise ValueError(form.errors)

    context = {
        # Show the users who have already at least 1 group
        "users": User.objects.filter(groups__isnull=False)
        .distinct()
        .order_by("last_name", "first_name"),
        "roles": Group.objects.all(),
        "form": UserGroupForm(),
    }
    return render(request, "manage_users.html", context)


@permission_required("otto.manage_users")
def manage_users_form(request, user_id=None):
    if user_id:
        logger.info("Accessing user roles form", update_user_id=user_id)
        user = User.objects.get(id=user_id)
        form = UserGroupForm(
            initial={"email": [user], "group": user.groups.all(), "pilot": user.pilot}
        )
    else:
        form = UserGroupForm()
    return render(request, "components/user_roles_modal.html", {"form": form})


@permission_required("otto.manage_users")
@require_POST
def manage_users_upload(request):
    roles = Group.objects.all()
    if request.method == "POST":
        csv_file = request.FILES.get("csv_file", None)
        if csv_file is not None:
            data_set = csv_file.read().decode("UTF-8")
            io_string = io.StringIO(data_set)
            reader = csv.DictReader(io_string)
            for row in reader:
                try:
                    # Process your row here
                    upn = row["upn"]
                    dot_name = upn.split("@")[0]
                    given_name = dot_name.split(".")[0]
                    surname = dot_name.split(".")[1]
                    try:
                        validate_email(upn)
                        email = upn
                    except ValidationError as e:
                        email = ""
                        logger.error(f"Invalid email address {upn}: {e}")
                        continue
                    # Get or create the pilot
                    pilot_id = row.get("pilot_id", None)
                    if pilot_id:
                        try:
                            pilot = Pilot.objects.get(pilot_id=pilot_id)
                        except ObjectDoesNotExist:
                            # Create a new pilot
                            pilot = Pilot.objects.create(
                                pilot_id=pilot_id,
                                name=pilot_id.replace("_", " ").capitalize(),
                            )
                    user, created = User.objects.get_or_create(upn=upn)
                    if created:
                        user.email = email
                        user.first_name = given_name
                        user.last_name = surname
                        if pilot_id:
                            user.pilot = pilot
                        user.save()
                    if not created:
                        user.groups.clear()
                        if pilot_id:
                            user.pilot = pilot
                            user.save()
                    for role in row["roles"].split("|"):
                        role = role.strip()
                        try:
                            group = roles.get(name__iexact=role)
                            user.groups.add(group)
                        except ObjectDoesNotExist:
                            pass
                except Exception as e:
                    logger.error(f"Error processing row {row}: {e}")

        else:
            logger.info("No csv file found in the submitted form.")

    # Redirect to manage_users
    return redirect("manage_users")


@permission_required("otto.manage_users")
def manage_users_download(request):
    response = HttpResponse(content_type="text/csv")
    response["Content-Disposition"] = 'attachment; filename="otto_users.csv"'

    writer = csv.writer(response)
    writer.writerow(["upn", "pilot_id", "roles"])

    # Only get users who have roles
    for user in User.objects.filter(groups__isnull=False).order_by("last_name"):
        roles = "|".join(user.groups.values_list("name", flat=True))
        pilot_id = user.pilot.pilot_id if user.pilot else ""
        writer.writerow([user.upn, pilot_id, roles])

    return response


@permission_required("otto.manage_users")
def manage_pilots(request):
    if request.method == "POST":
        pilot_id = request.POST.get("id")
        if pilot_id:
            pilot = get_object_or_404(Pilot, pk=pilot_id)
            form = PilotForm(request.POST, instance=pilot)
        else:
            form = PilotForm(request.POST)

        if form.is_valid():
            form.save()
        else:
            messages.error(request, form.errors)

    context = {
        "pilots": Pilot.objects.order_by("name"),
        "form": PilotForm(),
    }
    return render(request, "manage_pilots.html", context)


@permission_required("otto.manage_users")
def manage_pilots_form(request, pilot_id=None):
    if pilot_id and request.method == "DELETE":
        pilot = Pilot.objects.get(id=pilot_id)
        pilot.delete()
        response = HttpResponse()
        # Add hx-redirect header to trigger HTMX redirect
        response["hx-redirect"] = reverse("manage_pilots")
        return response
    if pilot_id:
        pilot = Pilot.objects.get(id=pilot_id)
        form = PilotForm(instance=pilot)
    else:
        form = PilotForm()
    return render(request, "components/pilot_modal.html", {"form": form})


def aggregate_costs(costs, x_axis="day"):
    # Aggregate the costs by the selected x-axis
    if x_axis == "feature":
        costs = costs.values("feature").annotate(total_cost=models.Sum("usd_cost"))
    elif x_axis == "pilot":
        costs = costs.values("user__pilot__name").annotate(
            total_cost=models.Sum("usd_cost")
        )
        costs = [{**c, "pilot": c.pop("user__pilot__name")} for c in costs]
    elif x_axis == "user":
        costs = costs.values("user__upn").annotate(total_cost=models.Sum("usd_cost"))
        costs = [{**c, "user": c.pop("user__upn")} for c in costs]
    elif x_axis == "cost_type":
        costs = costs.values("cost_type__name").annotate(
            total_cost=models.Sum("usd_cost")
        )
        costs = [{**c, "cost_type": c.pop("cost_type__name")} for c in costs]
    else:
        # Special handling for dates
        costs = costs.values("date_incurred").annotate(
            total_cost=models.Sum("usd_cost")
        )
        costs = [{**c, "day": c.pop("date_incurred")} for c in costs]
        # Fill missing dates (if any) with zero costs, up until today's date
        if costs:
            start_date = costs[0]["day"]
        else:
            start_date = timezone.now().date()
        end_date = timezone.now().date()
        date_range = [
            start_date + timedelta(days=x)
            for x in range((end_date - start_date).days + 1)
        ]
        costs_dict = {c["day"]: c for c in costs}
        costs = [
            costs_dict.get(date, {"day": date, "total_cost": 0}) for date in date_range
        ]
        if x_axis == "week":
            costs = [
                {
                    "week": c["day"].strftime("%Y-%W"),
                    "total_cost": c["total_cost"],
                }
                for c in costs
            ]
        elif x_axis == "month":
            costs = [
                {
                    "month": c["day"].strftime("%Y-%m"),
                    "total_cost": c["total_cost"],
                }
                for c in costs
            ]
        if x_axis in ["week", "month"]:
            # Sum the costs for each week or month
            costs = [
                {
                    f"{x_axis}": week_or_month,
                    "total_cost": sum(
                        c["total_cost"] for c in costs if c[x_axis] == week_or_month
                    ),
                }
                for week_or_month in set(c[x_axis] for c in costs)
            ]
    return costs


# AU-7: Aggregates and presents cost data in a dashboard
@permission_required("otto.manage_users")
def cost_dashboard(request):
    """
    Displays a responsive dashboard with cost data.
    X axis aggregations can be:
    feature (e.g. "chat", "qa", "summarize") - in constant FEATURE_CHOICES
    individual users (i.e. top X users) or pilot groups - in models User, Pilot
    cost type (e.g. "GPT-4 input tokens", "embedding tokens", "file translation pages") - in model CostType
    date aggregation (daily, weekly, monthly) (Cost.date_incurred) - usually primary aggregation
    """

    x_axis_labels = {
        "day": _("Day"),
        "week": _("Week"),
        "month": _("Month"),
        "feature": _("Feature"),
        "pilot": _("Pilot"),
        "user": _("User"),
        "cost_type": _("Cost type"),
    }

    group_labels = {
        "none": _("None"),
        "feature": _("Feature"),
        "pilot": _("Pilot"),
        "cost_type": _("Cost type"),
    }

    bar_chart_type_labels = {
        "grouped": _("Grouped"),
        "stacked": _("Stacked"),
    }

    # Options for the dropdowns
    pilot_options = {"all": _("All pilots")}
    pilot_options.update({p.id: p.name for p in list(Pilot.objects.all())})
    feature_options = {"all": _("All features")}
    feature_options.update({f[0]: f[1] for f in FEATURE_CHOICES})
    cost_type_options = {"all": _("All cost types")}
    cost_type_options.update({c.id: c.name for c in list(CostType.objects.all())})

    # Get the filters / groupings from the query string
    x_axis = request.GET.get("x_axis", "day")
    group = request.GET.get("group", "feature")
    bar_chart_type = request.GET.get("bar_chart_type", "stacked")
    pilot = request.GET.get("pilot", "all")
    feature = request.GET.get("feature", "all")
    cost_type = request.GET.get("cost_type", "all")

    # First, filter the costs by the selected options
    raw_costs = Cost.objects.all()
    if pilot != "all":
        raw_costs = raw_costs.filter(user__pilot__id=pilot)
    if feature != "all":
        raw_costs = raw_costs.filter(feature=feature)
    if cost_type != "all":
        raw_costs = raw_costs.filter(cost_type__id=cost_type)

    if x_axis in ["day", "week", "month"]:
        raw_costs = raw_costs.order_by("date_incurred")

    # Total costs, to display in the lead numbers
    total_cost_today = display_cad_cost(
        sum(c.usd_cost for c in raw_costs.filter(date_incurred=timezone.now().date()))
    )
    total_costs_alltime = display_cad_cost(sum(c.usd_cost for c in raw_costs))

    if group == "feature":
        group_costs = [
            {"label": feature_label, "costs": raw_costs.filter(feature=feature_id)}
            for feature_id, feature_label in dict(FEATURE_CHOICES).items()
        ]
    elif group == "pilot":
        group_costs = [
            {"label": pilot.name, "costs": raw_costs.filter(user__pilot=pilot)}
            for pilot in list(Pilot.objects.all())
        ]
    elif group == "cost_type":
        group_costs = [
            {"label": cost_type.name, "costs": raw_costs.filter(cost_type=cost_type)}
            for cost_type in list(CostType.objects.all())
        ]

    costs = aggregate_costs(raw_costs, x_axis)
    chart_x_keys = sorted([c[x_axis] for c in costs])
    # Pretty labels
    chart_x_labels = chart_x_keys
    if x_axis == "feature":
        chart_x_labels = [feature_options.get(c, c) for c in chart_x_labels]
    elif x_axis == "pilot":
        chart_x_labels = [pilot_options.get(c, c) for c in chart_x_labels]
    elif x_axis == "cost_type":
        chart_x_labels = [cost_type_options.get(c, c) for c in chart_x_labels]

    if group == "none":
        # Now, we have the costs aggregated by the selected x-axis
        # Let's format the data for the table
        column_headers = [x_axis_labels[x_axis], _("Total cost (CAD)")]
        rows = []
        for cost in costs:
            if x_axis == "day":
                rows.append(
                    [
                        cost["day"].strftime("%Y-%m-%d"),
                        f"${cad_cost(cost['total_cost']):.2f}",
                    ]
                )
            elif x_axis == "feature":
                rows.append(
                    [
                        feature_options.get(cost[x_axis], cost[x_axis]),
                        f"${cad_cost(cost['total_cost']):.2f}",
                    ]
                )
            else:
                rows.append([cost[x_axis], f"${cad_cost(cost['total_cost']):.2f}"])

        chart_y_groups = [
            {
                "label": _("Total cost (CAD)"),
                "values": [cad_cost(c["total_cost"]) for c in costs],
            }
        ]
    else:
        group_costs = [
            {
                "label": group_cost["label"],
                "costs": aggregate_costs(group_cost["costs"], x_axis),
            }
            for group_cost in group_costs
        ]
        # Remove group_costs which have no cost objects at all
        group_costs = [
            s for s in group_costs if sum(cost["total_cost"] for cost in s["costs"]) > 0
        ]
        # Fill in missing x-axis values with zero costs (chart_x_keys)
        for group_cost in group_costs:
            costs_dict = {c[x_axis]: c["total_cost"] for c in group_cost["costs"]}
            new_costs = [
                {
                    x_axis: x,
                    "total_cost": costs_dict.get(x, 0),
                }
                for x in chart_x_keys
            ]
            group_cost["costs"] = new_costs

        column_headers = [
            x_axis_labels[x_axis],
            group_labels[group],
            _("Total cost (CAD)"),
        ]
        rows = []
        for group_cost in group_costs:
            for cost in group_cost["costs"]:
                if cost["total_cost"] == 0:
                    continue
                if x_axis == "day":
                    rows.append(
                        [
                            cost["day"].strftime("%Y-%m-%d"),
                            group_cost["label"],
                            f"${cad_cost(cost['total_cost']):.2f}",
                        ]
                    )
                elif x_axis == "feature":
                    rows.append(
                        [
                            feature_options.get(cost[x_axis], cost[x_axis]),
                            group_cost["label"],
                            f"${cad_cost(cost['total_cost']):.2f}",
                        ]
                    )
                else:
                    rows.append(
                        [
                            cost[x_axis],
                            group_cost["label"],
                            f"${cad_cost(cost['total_cost']):.2f}",
                        ]
                    )
        rows = sorted(rows, key=lambda r: r[0])

        chart_y_groups = sorted(
            [
                {
                    "label": group_cost["label"],
                    "values": [cad_cost(c["total_cost"]) for c in group_cost["costs"]],
                }
                for group_cost in group_costs
            ],
            key=lambda g: g["label"],
        )

    context = {
        "column_headers": column_headers,
        "rows": rows,
        "lead_number": total_cost_today,
        "lead_number_title": _("Today"),
        "secondary_number": total_costs_alltime,
        "secondary_number_title": _("All time"),
        "chart_x_labels": chart_x_labels,
        "chart_y_groups": chart_y_groups,
        "x_axis": x_axis,
        "group": group,
        "bar_chart_type": bar_chart_type,
        "pilot": pilot,
        "feature": feature,
        "cost_type": cost_type,
        "x_axis_options": x_axis_labels,
        "group_options": group_labels,
        "bar_chart_type_options": bar_chart_type_labels,
        "pilot_options": pilot_options,
        "feature_options": feature_options,
        "cost_type_options": cost_type_options,
    }
    return render(request, "cost_dashboard.html", context)



=== Contents of django\otto\wsgi.py ===
"""
WSGI config for otto project.

It exposes the WSGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/4.1/howto/deployment/wsgi/
"""

import os

os.environ.setdefault("DJANGO_SETTINGS_MODULE", "otto.settings")

from django.core.wsgi import get_wsgi_application

application = get_wsgi_application()



=== Contents of django\otto\management\commands\cleanup_vector_store.py ===
import datetime
import os

# settings
from django.conf import settings
from django.core.management.base import BaseCommand

from django_extensions.management.utils import signalcommand
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker

from librarian.models import Document, Library


class Command(BaseCommand):
    help = (
        "Delete entries in vector store that don't have a corresponding Django object.\n"
        "This should not be needed in practice (if Library delete methods are working correctly), but is a safety measure."
    )

    @signalcommand
    def handle(self, *args, **options):
        # Make a list of database tables that are used by the vector store
        # and that have a corresponding Django model.
        keep_tables = [
            f"data_{uuid_hex}"
            for uuid_hex in Library.objects.values_list("uuid_hex", flat=True)
        ] + ["data_laws_lois__"]

        db = settings.DATABASES["vector_db"]
        connection_string = f"postgresql+psycopg2://{db['USER']}:{db['PASSWORD']}@{db['HOST']}:5432/{db['NAME']}"
        engine = create_engine(connection_string)
        Session = sessionmaker(bind=engine)

        session = Session()
        # Get a list of tables in the database
        vector_db_tables = [
            table[0]
            for table in session.execute(
                text(
                    "SELECT table_name FROM information_schema.tables WHERE table_schema='public'"
                )
            ).fetchall()
        ]
        print("Tables in vector db:")
        for table in vector_db_tables:
            print(table)
        print("\nTables that should be kept, based on Django:")
        for table in keep_tables:
            print(table)

        # Delete tables that are not in the keep_tables list
        delete_tables = set(vector_db_tables) - set(keep_tables)
        deleted_count = 0
        print("\nTables to delete:")
        for table in delete_tables:
            print(table)
        for table in delete_tables:
            session.execute(text(f"DROP TABLE IF EXISTS {table} CASCADE"))
            deleted_count += 1
        session.commit()
        print(f"\nDeleted {deleted_count} tables.")

        # For each Django library, find documents that should be deleted
        print("\nChecking for documents to delete in individual libraries...")
        for library in Library.objects.all():
            library_uuid_hex = library.uuid_hex
            library_documents = Document.objects.filter(
                data_source__in=library.data_sources.all()
            )
            library_document_hexes = set(
                [document.uuid_hex for document in library_documents]
            )
            library_vector_table = f"data_{library_uuid_hex}"
            print(f"\nLibrary: {library}")
            print(f"Library vector table: {library_vector_table}")

            # Get a list of document hexes in the vector store
            # These are found in each row's metadata_ column, property "ref_doc_id"
            vector_store_document_hexes = set(
                [
                    row[0]
                    for row in session.execute(
                        text(
                            f"SELECT metadata_ -> 'ref_doc_id' FROM {library_vector_table}"
                        )
                    ).fetchall()
                ]
            )

            print(f"Documents in vector store: {len(vector_store_document_hexes)}")
            print(f"Documents in Django: {len(library_document_hexes)}")

            # Find documents that are in the vector store but not in Django
            delete_document_hexes = vector_store_document_hexes - library_document_hexes
            print(f"Documents to delete: {len(delete_document_hexes)}")

            # Delete documents that are in the vector store but not in Django
            deleted_count = 0
            for document_hex in delete_document_hexes:
                print(f"Deleting document {document_hex}...")
                stmt = text(
                    f"DELETE FROM {library_vector_table} where "
                    f"(metadata_->>'doc_id')::text = '{document_hex}' "
                )
                session.execute(stmt)
                deleted_count += 1

            session.commit()
            print(f"Deleted {deleted_count} documents.")

        session.close()



=== Contents of django\otto\management\commands\delete_empty_chats.py ===
import datetime
import os

# settings
from django.conf import settings
from django.core.management.base import BaseCommand

from django_extensions.management.utils import signalcommand

from chat.models import Chat


class Command(BaseCommand):
    help = "Delete empty chat files more than 1 day old."

    def add_arguments(self, parser):
        # Delete all
        parser.add_argument(
            "--all",
            action="store_true",
            help="Delete all empty chats, regardless of age.",
        )

    @signalcommand
    def handle(self, *args, **options):
        delete_from = datetime.datetime.now() - datetime.timedelta(days=1)

        if options["all"]:
            chats = Chat.objects.filter(messages__isnull=True)
        else:
            chats = Chat.objects.filter(
                created_at__lt=delete_from, messages__isnull=True
            )

        num_chats = chats.count()
        chats.delete()

        self.stdout.write(self.style.SUCCESS(f"Deleted {num_chats} chats"))



=== Contents of django\otto\management\commands\delete_old_chat_files.py ===
import datetime
import os

from django.conf import settings
from django.core.management.base import BaseCommand

from django_extensions.management.utils import signalcommand

from chat.models import ChatFile


def get_dir_size(path="."):
    total = 0
    with os.scandir(path) as it:
        for entry in it:
            if entry.is_file():
                total += entry.stat().st_size
            elif entry.is_dir():
                total += get_dir_size(entry.path)
    return total


class Command(BaseCommand):
    help = "Delete chat files more than 7 days old."

    def add_arguments(self, parser):
        # Delete all
        parser.add_argument(
            "--all",
            action="store_true",
            help="Delete all chat files, regardless of age.",
        )
        # before date
        parser.add_argument(
            "--before",
            type=str,
            help="Delete chat files older than this date. Format: YYYY-MM-DD",
        )
        # Purge the entire folder through OS (not recommended)
        parser.add_argument(
            "--purge",
            action="store_true",
            help="Delete all uploaded files, regardless of age, using OS commands (DANGER - this will also delete QA files!).",
        )

    @signalcommand
    def handle(self, *args, **options):
        # If "before" flag, delete before that date
        if options["before"]:
            delete_from = datetime.datetime.strptime(options["before"], "%Y-%m-%d")
        # By default, delete before 1 week ago
        else:
            delete_from = datetime.datetime.now() - datetime.timedelta(days=7)

        # Find ChatFile objects with 'created_at' property older than 'delete_from'
        if options["all"]:
            chat_files = ChatFile.objects.all()
        else:
            chat_files = ChatFile.objects.filter(created_at__lt=delete_from)

        space_freed = 0
        files_deleted = 0
        # Delete the files and SavedFile objects
        for chat_file in chat_files:
            if chat_file.saved_file is not None:
                file_field = chat_file.saved_file.file
                try:
                    space_freed += file_field.size / 1024
                    file_field.delete()
                    files_deleted += 1
                except:
                    # File must have already been deleted? Just mark as none
                    pass
                chat_file.saved_file.delete()

        self.stdout.write(
            self.style.SUCCESS(
                f"Deleted {files_deleted} files and freed up {space_freed:.2f} kb."
            )
        )

        if options["purge"]:
            chat_files_dir = os.path.join(settings.MEDIA_ROOT, "files")
            # Calculate size of chat_files folder
            try:
                directory_size = get_dir_size(chat_files_dir)
            except FileNotFoundError:
                self.stdout.write(
                    self.style.WARNING(f"Directory {chat_files_dir} not found.")
                )
                return
            # Delete the entire folder
            os.system(f"rm -rf {chat_files_dir}")
            self.stdout.write(
                self.style.WARNING(
                    f"Purged {chat_files_dir} and freed up {directory_size:.2f} kb."
                )
            )



=== Contents of django\otto\management\commands\delete_unused_libraries.py ===
import datetime

from django.core.management.base import BaseCommand

from django_extensions.management.utils import signalcommand

from chat.models import AnswerSource
from librarian.models import DataSource, Document, Library


class Command(BaseCommand):
    help = "Delete libraries which haven't been used in a QA answer for a certain period of time (default: 90 days)"

    def add_arguments(self, parser):
        # before date
        parser.add_argument(
            "--before",
            type=str,
            help="Delete libraries not accessed since this date. Format: YYYY-MM-DD",
        )

    @signalcommand
    def handle(self, *args, **options):
        # If "before" flag, delete before that date
        if options["before"]:
            delete_from = datetime.datetime.strptime(options["before"], "%Y-%m-%d")
        # By default, delete before 1 week ago
        else:
            delete_from = datetime.datetime.now() - datetime.timedelta(days=90)

        libraries_deleted = 0
        documents_deleted = 0

        # Get all libraries that haven't been accessed since the delete_from date
        # We have to check each Document answersource_set - for each answer, the message.date_created
        # is the date the answer was created
        # Also keep documents that have modified_at gte delete_from

        # Get document IDs that meet the criteria
        document_ids = list(
            AnswerSource.objects.filter(
                message__date_created__gte=delete_from, document_id__isnull=False
            ).values_list("document_id", flat=True)
        )

        # Get documents that have been modified since delete_from
        modified_documents = list(
            Document.objects.filter(modified_at__gte=delete_from).values_list(
                "id", flat=True
            )
        )

        # Combine the two sets of document IDs
        keep_documents = list(set(document_ids + modified_documents))

        # Get data source IDs for the kept documents
        keep_data_sources = list(
            Document.objects.filter(id__in=keep_documents).values_list(
                "data_source_id", flat=True
            )
        )

        # Get data sources that have been modified since delete_from
        modified_data_sources = list(
            DataSource.objects.filter(modified_at__gte=delete_from).values_list(
                "id", flat=True
            )
        )

        # Combine the two sets of data source IDs
        keep_data_sources = list(set(keep_data_sources + modified_data_sources))

        # Get library IDs for the kept data sources
        keep_libraries = list(
            DataSource.objects.filter(id__in=keep_data_sources).values_list(
                "library_id", flat=True
            )
        )

        # Get libraries that have been modified since delete_from
        modified_libraries = list(
            Library.objects.filter(modified_at__gte=delete_from).values_list(
                "id", flat=True
            )
        )

        # Combine the two sets of library IDs
        keep_libraries = list(set(keep_libraries + modified_libraries))

        # Get libraries to delete
        delete_libraries = Library.objects.exclude(id__in=keep_libraries)
        documents_deleted = Document.objects.filter(
            data_source__library__in=delete_libraries
        ).count()
        for library in delete_libraries:
            library.delete()
            libraries_deleted += 1

        self.stdout.write(
            self.style.SUCCESS(
                f"Deleted {libraries_deleted} libraries containing {documents_deleted} documents"
            )
        )



=== Contents of django\otto\management\commands\load_app_localization.py ===
import os
import sys

from django.conf import settings
from django.core.management import call_command
from django.core.management.base import BaseCommand, CommandError

from django_extensions.management.utils import signalcommand
from polib import pofile

from otto.management.commands import make_messages
from otto.utils.localization import LocaleTranslator


class Command(BaseCommand):
    help = "Translate .po file."

    def add_arguments(self, parser):
        parser.add_argument(
            "--no-translation",
            help="Skips translation steps.",
            action="store_true",
        )
        parser.add_argument(
            "--no-po",
            help="Skips step to generate the localization Portable object (.po) file.",
            action="store_true",
        )
        parser.add_argument(
            "--no-mo",
            help="Skips step to generate the localization Machine object (.mo) file.",
            action="store_true",
        )

    @signalcommand
    def handle(self, *args, **options):
        no_po = options["no_po"]
        no_translation = options["no_translation"]
        no_mo = options["no_mo"]

        if no_mo and no_po and no_translation:
            raise CommandError(
                "Type '%s help %s' for usage information."
                % (os.path.basename(sys.argv[0]), sys.argv[1])
            )

        if not no_po:
            call_command("make_messages", locale=["fr"], no_fuzzy_matching=True)
            self.stdout.write(self.style.SUCCESS(".po file generated successfully."))

        if not no_translation:
            base_path = os.path.join(settings.BASE_DIR, "locale")
            translations_path = os.path.join(
                base_path, "translation", "translations.json"
            )
            po_file_path = os.path.join(base_path, "fr", "LC_MESSAGES", "django.po")

            if not os.path.isfile(translations_path):
                self.stderr.write(f"The file at {translations_path} does not exist.")
                return
            if not os.path.isfile(po_file_path):
                self.stderr.write(f"The file at {po_file_path} does not exist.")
                return

            translator_client = LocaleTranslator(
                settings.AZURE_COGNITIVE_SERVICE_KEY,
                settings.AZURE_COGNITIVE_SERVICE_REGION,
                settings.AZURE_COGNITIVE_SERVICE_ENDPOINT,
            )
            try:
                translator_client.update_translations(
                    os.path.join(settings.BASE_DIR, "locale"),
                )
            except Exception as e:
                self.stderr.write(e)

            self.stdout.write(self.style.SUCCESS("Files translated successfully."))

        if not no_mo:
            po_file_path = os.path.join(
                settings.BASE_DIR, "locale", "fr", "LC_MESSAGES", "django.po"
            )
            self.correct_po_file(po_file_path)
            call_command("compilemessages")
            self.stdout.write(self.style.SUCCESS(".mo file generated successfully."))

    def correct_po_file(self, po_file_path):
        po = pofile(po_file_path)
        for entry in po:
            if entry.msgid and entry.msgstr:
                try:
                    entry.msgid % {}
                    entry.msgstr % {}
                except (KeyError, ValueError):
                    entry.msgstr = (
                        entry.msgid
                    )  # Copy msgid to msgstr to avoid format issues
        po.save()
        self.stdout.write(self.style.SUCCESS(f"Corrected .po file at {po_file_path}."))



=== Contents of django\otto\management\commands\load_corporate_library.py ===
from django.core.management.base import BaseCommand

from django_extensions.management.utils import signalcommand

from librarian.models import Library


class Command(BaseCommand):
    help = "Load the corporate library"

    # Get force argument
    def add_arguments(self, parser):
        parser.add_argument(
            "--force",
            action="store_true",
            help="Force the load of the corporate library",
        )

    @signalcommand
    def handle(self, *args, **options):
        Library.objects.get(name="Corporate").process_all(force=options["force"])
        self.stdout.write(self.style.SUCCESS("Corporate library loaded successfully."))



=== Contents of django\otto\management\commands\make_messages.py ===
from django.core.management.commands import makemessages

from django_extensions.management.utils import signalcommand


class Command(makemessages.Command):
    msgmerge_options = makemessages.Command.msgmerge_options + ["--no-fuzzy-matching"]
    # We only want to look into certain directories; the rest are not relevant for translation
    msgmerge_options += [
        "-D",
        "librarian",
        "-D",
        "otto",
        "-D",
        "chat",
    ]

    @signalcommand
    def add_arguments(self, parser):
        super().add_arguments(parser=parser)
        parser.add_argument(
            "--no-fuzzy-matching",
            action="store_true",
            help="Do not use fuzzy matching in msgmerge.",
        )



=== Contents of django\otto\management\commands\reset_app_data.py ===
import os
import subprocess

from django.conf import settings
from django.contrib.auth import get_user_model
from django.contrib.auth.models import Group, Permission
from django.core.management import call_command
from django.core.management.base import BaseCommand

import yaml
from django_extensions.management.utils import signalcommand

from librarian.models import DataSource, Document, Library
from otto.models import App, UsageTerm


class Command(BaseCommand):
    help = "Reset otto and librarian model instances based on YAML configuration"

    def add_arguments(self, parser):
        parser.add_argument(
            "objects",
            nargs="*",
            type=str,
            help="Specify objects to reset (apps, terms, groups, libraries, library_mini, security_labels, cost_types)",
        )
        parser.add_argument("--all", action="store_true", help="Reset all objects")

    @signalcommand
    def handle(self, *args, **options):
        reset_all = options.get("all", False)
        objects_to_reset = options.get("objects", [])

        # Create the database DATABASES["vector_db"] if it doesn't exist
        vector_db_name = settings.DATABASES["vector_db"]["NAME"]
        vector_db_user = settings.DATABASES["vector_db"]["USER"]
        vector_db_password = settings.DATABASES["vector_db"]["PASSWORD"]
        vector_db_host = settings.DATABASES["vector_db"]["HOST"]

        # Set system-wide environment variable PGPASSWORD to avoid password prompt
        os.environ["PGPASSWORD"] = vector_db_password

        try:
            # Create the database
            subprocess.run(
                [
                    "psql",
                    "-U",
                    vector_db_user,
                    "-h",
                    vector_db_host,
                    "-d",
                    "postgres",
                    "-c",
                    f"CREATE DATABASE {vector_db_name}",
                ],
                check=True,
            )
        except subprocess.CalledProcessError:
            self.stdout.write(
                self.style.WARNING(
                    f"Database {vector_db_name} already exists. Skipping creation."
                )
            )

        if reset_all:
            self.reset_groups()
            self.reset_apps()
            self.reset_usage_terms()
            self.reset_security_labels()
            self.reset_libraries()
            self.reset_cost_types()
        else:
            if "groups" in objects_to_reset:
                self.reset_groups()

            if "apps" in objects_to_reset:
                self.reset_apps()

            if "terms" in objects_to_reset:
                self.reset_usage_terms()

            if "cost_types" in objects_to_reset:
                self.reset_cost_types()

            if "security_labels" in objects_to_reset:
                self.reset_security_labels()

            if "libraries" in objects_to_reset:
                self.reset_libraries()

            if "library_mini" in objects_to_reset:
                self.reset_libraries("library_mini.yaml")

    def reset_apps(self):
        yaml_file_path = os.path.join(
            settings.BASE_DIR, "otto", "fixtures", "apps.yaml"
        )

        with open(yaml_file_path, "r", encoding="utf-8") as yaml_file:
            apps_data = yaml.safe_load(yaml_file)

        if not apps_data:
            self.stdout.write(
                self.style.WARNING(
                    "No data found in the YAML file. Nothing to reset for Apps."
                )
            )
            return

        # Clear out existing App instances
        App.objects.all().delete()

        # Create new App instances based on YAML data
        for app_data in apps_data:
            App.objects.create_from_yaml(app_data)

        self.stdout.write(self.style.SUCCESS("Apps reset successfully."))

    def reset_usage_terms(self):
        yaml_file_path = os.path.join(
            settings.BASE_DIR, "otto", "fixtures", "terms.yaml"
        )

        with open(yaml_file_path, "r", encoding="utf-8") as yaml_file:
            terms_data = yaml.safe_load(yaml_file)

        if not terms_data:
            self.stdout.write(
                self.style.WARNING(
                    "No data found in the YAML file. Nothing to reset for UsageTerms."
                )
            )
            return

        # Clear out existing UsageTerm instances
        UsageTerm.objects.all().delete()

        # Create new UsageTerm instances based on YAML data
        for term_data in terms_data:
            term_fields = term_data.get("fields", {})
            UsageTerm.objects.create(**term_fields)

        self.stdout.write(self.style.SUCCESS("UsageTerms reset successfully."))

    def reset_groups(self):
        yaml_file_path = os.path.join(
            settings.BASE_DIR, "otto", "fixtures", "groups.yaml"
        )

        with open(yaml_file_path, "r", encoding="utf-8") as yaml_file:
            groups_data = yaml.safe_load(yaml_file)

        if not groups_data:
            self.stdout.write(
                self.style.WARNING(
                    "No data found in the YAML file. Nothing to reset for groups."
                )
            )
            return

        # Clear out existing groups and user groups
        Group.objects.all().delete()

        # Create new groups based on YAML data
        for group_data in groups_data:
            group_fields = group_data.get("fields", {})
            group_instance = Group.objects.create(**group_fields)

            # Add permissions to the group if specified in the YAML file
            permissions = group_data.get("permissions", [])
            for codename in permissions:
                # Retrieve the permission instance
                permission_instance = Permission.objects.get(codename=codename)
                group_instance.permissions.add(permission_instance)

            # Add users to the group if specified in the YAML file
            users = group_data.get("users", [])
            for upn in users:
                user_instance = (
                    get_user_model().objects.filter(upn=upn).first()
                ) or get_user_model().objects.create_user(upn)
                group_instance.user_set.add(user_instance)

        self.stdout.write(
            self.style.SUCCESS("Groups and user groups reset successfully.")
        )

    def reset_libraries(self, yaml_file_name="library.yaml"):
        yaml_file_path = os.path.join(
            settings.BASE_DIR, "librarian", "fixtures", yaml_file_name
        )

        with open(yaml_file_path, "r", encoding="utf-8") as yaml_file:
            libraries_data = yaml.safe_load(yaml_file)

        if not libraries_data:
            self.stdout.write(
                self.style.WARNING(
                    "No data found in the YAML file. Nothing to reset for libraries."
                )
            )
            return

        # Clear out existing instances
        Document.objects.all().delete()
        DataSource.objects.all().delete()
        Library.objects.all().delete()

        Library.objects.reset_vector_store()

        for item in libraries_data:
            if item["model"] != "librarian.library":
                continue

            library_fields = item.get("fields", {})
            data_sources = library_fields.pop("data_sources", [])

            library_instance = Library.objects.create(**library_fields)

            for data_source in data_sources:
                data_source_fields = data_source.get("fields", {})
                documents = data_source_fields.pop("documents", [])

                data_source_instance = DataSource.objects.create(
                    library=library_instance, **data_source_fields
                )

                for document in documents:
                    document_fields = document.get("fields", {})
                    Document.objects.create(
                        data_source=data_source_instance, **document_fields
                    )

        self.stdout.write(
            self.style.SUCCESS(
                "Libraries, DataSources, and Documents reset successfully."
            )
        )

    def reset_security_labels(self):
        # Simply call manage.py loaddata security_labels.yaml
        call_command("loaddata", "security_labels.yaml")
        self.stdout.write(self.style.SUCCESS("Security labels reset successfully."))

    def reset_cost_types(self):
        # Simply call manage.py loaddata cost_types.yaml
        call_command("loaddata", "cost_types.yaml")
        self.stdout.write(self.style.SUCCESS("Cost types reset successfully."))



=== Contents of django\otto\management\commands\reset_database.py ===
# call command
import os
import subprocess

from django.conf import settings
from django.core.management import call_command
from django.core.management.base import BaseCommand
from django.db import connection

from django_extensions.management.utils import signalcommand


class Command(BaseCommand):
    help = "Delete every database table, then migrate again."

    # Get force argument
    def add_arguments(self, parser):
        parser.add_argument(
            "--yes",
            action="store_true",
            help="Skip confirmation and delete the database.",
        )

    @signalcommand
    def handle(self, *args, **options):
        tables = connection.introspection.table_names()
        if not options["yes"]:
            confirm = input(
                "Delete all data in the Otto database? YOU HAVE BEEN WARNED! (yes/no): "
            )
            if confirm != "yes":
                self.stdout.write("Aborting.")
                return
        with connection.cursor() as cursor:
            for table in tables:
                cursor.execute(f"DROP TABLE {table} CASCADE")
        self.stdout.write("All tables dropped.")
        self.stdout.write("Running migrations...")
        call_command("migrate")
        self.stdout.write("Done deleting Otto database.")
        # Delete vector database
        if not options["yes"]:
            confirm = input(
                "Delete all data in the Vector database? YOU HAVE BEEN WARNED! (yes/no): "
            )
            if confirm != "yes":
                self.stdout.write("Aborting.")
                return
        # Use settings.DATABASES["vector_db"]
        vector_db_name = settings.DATABASES["vector_db"]["NAME"]
        vector_db_user = settings.DATABASES["vector_db"]["USER"]
        vector_db_password = settings.DATABASES["vector_db"]["PASSWORD"]
        vector_db_host = settings.DATABASES["vector_db"]["HOST"]

        # Set system-wide environment variable PGPASSWORD to avoid password prompt
        os.environ["PGPASSWORD"] = vector_db_password

        try:
            # Drop the database
            subprocess.run(
                [
                    "psql",
                    "-U",
                    vector_db_user,
                    "-h",
                    vector_db_host,
                    "-d",
                    "postgres",
                    "-c",
                    f"DROP DATABASE {vector_db_name}",
                ],
                check=True,
            )
        except subprocess.CalledProcessError:
            self.stdout.write(
                self.style.WARNING(f"Database {vector_db_name} could not be deleted.")
            )
        self.stdout.write("Done deleting Vector database.")

        self.stdout.write(
            "All done. Recommend running `bash initial_setup.sh` from django root."
        )



=== Contents of django\otto\management\commands\set_admin_user.py ===
from django.core.exceptions import ObjectDoesNotExist
from django.core.management import call_command
from django.core.management.base import BaseCommand

from otto.models import Group, User


class Command(BaseCommand):
    help = "Sync users and set a user as Otto admin based on their UPN"

    def add_arguments(self, parser):
        parser.add_argument(
            "upn",
            type=str,
            help="The User Principal Name (UPN) of the user to be set as admin",
        )

    def handle(self, *args, **options):
        upn = options["upn"]

        # Find the user and make them an admin
        try:
            user = User.objects.get(upn__iexact=upn)
            user.make_otto_admin()
            self.stdout.write(
                self.style.SUCCESS(
                    f"User '{user.full_name}' ({user.upn}) has been set as Otto admin."
                )
            )
        except ObjectDoesNotExist:
            self.stdout.write(self.style.ERROR(f"No user found with UPN: {upn}"))
        except Group.DoesNotExist:
            self.stdout.write(
                self.style.ERROR(
                    "Otto admin group does not exist. Please create it first."
                )
            )
        except Exception as e:
            self.stdout.write(self.style.ERROR(f"An error occurred: {str(e)}"))



=== Contents of django\otto\management\commands\sync_users.py ===
# settings
import asyncio

from django.core.management.base import BaseCommand

from django_extensions.management.utils import signalcommand

from otto.utils.entra import sync_users_with_entra_async


class Command(BaseCommand):
    help = "Sync users between Otto and Entra"

    @signalcommand
    def handle(self, *args, **options):
        loop = asyncio.get_event_loop()
        loop.run_until_complete(sync_users_with_entra_async())
        self.stdout.write(self.style.SUCCESS("Users sync completed successfully."))



=== Contents of django\otto\metrics\__init__.py ===



=== Contents of django\otto\metrics\activity_metrics.py ===
from prometheus_client import Counter

# AU-7: Custom metrics that can be used for generating reports on system usage and user interactions

otto_access_total = Counter(
    name="otto_access_total",
    documentation="number of times the otto application pages have been accessed by users",
    labelnames=["user"],
)



=== Contents of django\otto\metrics\feedback_metrics.py ===
from prometheus_client import Counter

# AU-7: Custom metrics that can be used for generating reports on system usage and user interactions

otto_feedback_submitted_total = Counter(
    "otto_feedback_submitted_total", "number of feedback submitted", labelnames=["user"]
)
otto_feedback_submitted_with_comment_total = Counter(
    "otto_feedback_submitted_with_comment_total",
    "number of feedback submitted with comment",
    labelnames=["user"],
)



=== Contents of django\otto\migrations\__init__.py ===



=== Contents of django\otto\migrations\0001_initial.py ===
# Generated by Django 5.0.7 on 2024-07-25 20:33

import django.db.models.deletion
import uuid
from django.conf import settings
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        ("auth", "0012_alter_user_first_name_max_length"),
        ("chat", "0002_initial"),
        ("contenttypes", "0002_remove_content_type_name"),
    ]

    operations = [
        migrations.CreateModel(
            name="AccessControlLog",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("upn", models.CharField(max_length=255)),
                (
                    "action",
                    models.CharField(
                        choices=[("C", "Create"), ("U", "Update"), ("D", "Delete")],
                        max_length=1,
                    ),
                ),
                ("can_view", models.BooleanField(default=False)),
                ("can_change", models.BooleanField(default=False)),
                ("can_delete", models.BooleanField(default=False)),
                ("content_object", models.CharField(max_length=255)),
                ("reason", models.CharField(blank=True, max_length=255, null=True)),
                (
                    "modified_by",
                    models.CharField(blank=True, max_length=255, null=True),
                ),
                ("modified_at", models.DateTimeField(auto_now_add=True)),
            ],
        ),
        migrations.CreateModel(
            name="SecurityLabel",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("name", models.CharField(max_length=50, unique=True)),
                ("name_en", models.CharField(max_length=50, null=True, unique=True)),
                ("name_fr", models.CharField(max_length=50, null=True, unique=True)),
                ("description", models.TextField()),
                ("description_en", models.TextField(null=True)),
                ("description_fr", models.TextField(null=True)),
                ("acronym", models.CharField(max_length=10, unique=True)),
                ("acronym_en", models.CharField(max_length=10, null=True, unique=True)),
                ("acronym_fr", models.CharField(max_length=10, null=True, unique=True)),
            ],
        ),
        migrations.CreateModel(
            name="UsageTerm",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("term_text", models.CharField(max_length=2000)),
                ("term_text_en", models.CharField(max_length=2000, null=True)),
                ("term_text_fr", models.CharField(max_length=2000, null=True)),
            ],
        ),
        migrations.CreateModel(
            name="User",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("password", models.CharField(max_length=128, verbose_name="password")),
                (
                    "last_login",
                    models.DateTimeField(
                        blank=True, null=True, verbose_name="last login"
                    ),
                ),
                (
                    "is_superuser",
                    models.BooleanField(
                        default=False,
                        help_text="Designates that this user has all permissions without explicitly assigning them.",
                        verbose_name="superuser status",
                    ),
                ),
                ("upn", models.CharField(max_length=255, unique=True)),
                ("email", models.EmailField(max_length=254)),
                ("oid", models.CharField(max_length=255, null=True)),
                ("first_name", models.CharField(max_length=80)),
                ("last_name", models.CharField(max_length=80)),
                ("is_active", models.BooleanField(default=True)),
                ("is_staff", models.BooleanField(default=False)),
                ("date_joined", models.DateTimeField(auto_now_add=True)),
                ("accepted_terms_date", models.DateField(null=True)),
                (
                    "groups",
                    models.ManyToManyField(
                        blank=True,
                        help_text="The groups this user belongs to. A user will get all permissions granted to each of their groups.",
                        related_name="user_set",
                        related_query_name="user",
                        to="auth.group",
                        verbose_name="groups",
                    ),
                ),
                (
                    "user_permissions",
                    models.ManyToManyField(
                        blank=True,
                        help_text="Specific permissions for this user.",
                        related_name="user_set",
                        related_query_name="user",
                        to="auth.permission",
                        verbose_name="user permissions",
                    ),
                ),
            ],
        ),
        migrations.CreateModel(
            name="AccessControl",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("can_view", models.BooleanField(default=False)),
                ("can_change", models.BooleanField(default=False)),
                ("can_delete", models.BooleanField(default=False)),
                ("object_id", models.UUIDField()),
                ("reason", models.CharField(blank=True, max_length=255, null=True)),
                ("modified_at", models.DateTimeField(auto_now=True)),
                (
                    "content_type",
                    models.ForeignKey(
                        on_delete=django.db.models.deletion.CASCADE,
                        to="contenttypes.contenttype",
                    ),
                ),
                (
                    "modified_by",
                    models.ForeignKey(
                        blank=True,
                        null=True,
                        on_delete=django.db.models.deletion.SET_NULL,
                        related_name="access_controls_modified_by",
                        to=settings.AUTH_USER_MODEL,
                    ),
                ),
                (
                    "user",
                    models.ForeignKey(
                        on_delete=django.db.models.deletion.CASCADE,
                        to=settings.AUTH_USER_MODEL,
                    ),
                ),
            ],
        ),
        migrations.CreateModel(
            name="App",
            fields=[
                (
                    "id",
                    models.UUIDField(
                        default=uuid.uuid4,
                        editable=False,
                        primary_key=True,
                        serialize=False,
                    ),
                ),
                ("handle", models.CharField(blank=True, max_length=50, null=True)),
                ("name", models.CharField(max_length=200)),
                ("name_en", models.CharField(max_length=200, null=True)),
                ("name_fr", models.CharField(max_length=200, null=True)),
                ("prod_ready", models.BooleanField(default=False)),
                ("visible_to_all", models.BooleanField(default=True)),
                (
                    "user_group",
                    models.ForeignKey(
                        blank=True,
                        null=True,
                        on_delete=django.db.models.deletion.SET_NULL,
                        to="auth.group",
                    ),
                ),
            ],
        ),
        migrations.CreateModel(
            name="Feature",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("name", models.CharField(max_length=200)),
                ("name_en", models.CharField(max_length=200, null=True)),
                ("name_fr", models.CharField(max_length=200, null=True)),
                ("description", models.TextField()),
                ("description_en", models.TextField(null=True)),
                ("description_fr", models.TextField(null=True)),
                (
                    "category",
                    models.CharField(
                        choices=[
                            ("ai_assistant", "AI assistant"),
                            ("monitoring", "Monitoring"),
                            ("reporting", "Reporting"),
                            ("other", "Other"),
                        ],
                        max_length=50,
                    ),
                ),
                (
                    "classification",
                    models.CharField(blank=True, max_length=50, null=True),
                ),
                ("url", models.CharField(max_length=200)),
                (
                    "app",
                    models.ForeignKey(
                        on_delete=django.db.models.deletion.CASCADE, to="otto.app"
                    ),
                ),
            ],
        ),
        migrations.CreateModel(
            name="Feedback",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                (
                    "feedback_type",
                    models.CharField(
                        choices=[("feedback", "Feedback"), ("issue", "Issue")],
                        default="Please select an option",
                        max_length=50,
                    ),
                ),
                ("app", models.TextField(max_length=200)),
                ("otto_version", models.CharField(max_length=12)),
                ("feedback_message", models.TextField()),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                (
                    "chat_message",
                    models.ForeignKey(
                        null=True,
                        on_delete=django.db.models.deletion.SET_NULL,
                        related_name="message",
                        to="chat.message",
                    ),
                ),
                (
                    "modified_by",
                    models.ForeignKey(
                        on_delete=django.db.models.deletion.DO_NOTHING,
                        to=settings.AUTH_USER_MODEL,
                    ),
                ),
            ],
        ),
        migrations.CreateModel(
            name="Notification",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("text", models.CharField(max_length=255)),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                ("heading", models.CharField(blank=True, max_length=255, null=True)),
                ("progress", models.IntegerField(blank=True, null=True)),
                ("link", models.CharField(blank=True, max_length=255, null=True)),
                ("category", models.CharField(blank=True, max_length=50, null=True)),
                ("level", models.CharField(blank=True, max_length=50, null=True)),
                (
                    "user",
                    models.ForeignKey(
                        on_delete=django.db.models.deletion.CASCADE,
                        related_name="notifications",
                        to=settings.AUTH_USER_MODEL,
                    ),
                ),
            ],
        ),
        migrations.CreateModel(
            name="UserOptions",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("language", models.CharField(default="en", max_length=50)),
                ("chat_settings_width", models.IntegerField(default=0)),
                (
                    "user",
                    models.OneToOneField(
                        on_delete=django.db.models.deletion.CASCADE,
                        to=settings.AUTH_USER_MODEL,
                    ),
                ),
            ],
        ),
        migrations.AddIndex(
            model_name="user",
            index=models.Index(fields=["email"], name="otto_user_email_c51a30_idx"),
        ),
        migrations.AddIndex(
            model_name="accesscontrol",
            index=models.Index(
                fields=["user", "object_id"], name="otto_access_user_id_b55faa_idx"
            ),
        ),
        migrations.AlterUniqueTogether(
            name="accesscontrol",
            unique_together={("user", "object_id")},
        ),
    ]



=== Contents of django\otto\migrations\0002_costtype_feature_short_name_cost.py ===
# Generated by Django 5.1 on 2024-08-28 18:16

import django.db.models.deletion
from django.conf import settings
from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ("otto", "0001_initial"),
    ]

    operations = [
        migrations.CreateModel(
            name="CostType",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("name", models.CharField(max_length=100)),
                ("name_en", models.CharField(max_length=100, null=True)),
                ("name_fr", models.CharField(max_length=100, null=True)),
                ("short_name", models.CharField(max_length=50, null=True, unique=True)),
                ("description", models.TextField()),
                ("description_en", models.TextField(null=True)),
                ("description_fr", models.TextField(null=True)),
                ("unit_name", models.CharField(default="units", max_length=50)),
                (
                    "unit_name_en",
                    models.CharField(default="units", max_length=50, null=True),
                ),
                (
                    "unit_name_fr",
                    models.CharField(default="units", max_length=50, null=True),
                ),
                (
                    "unit_cost",
                    models.DecimalField(decimal_places=6, default=1, max_digits=10),
                ),
                ("unit_quantity", models.IntegerField(default=1)),
            ],
        ),
        migrations.AddField(
            model_name="feature",
            name="short_name",
            field=models.CharField(max_length=50, null=True, unique=True),
        ),
        migrations.CreateModel(
            name="Cost",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("count", models.IntegerField(default=1)),
                ("usd_cost", models.DecimalField(decimal_places=6, max_digits=12)),
                ("date_incurred", models.DateTimeField(auto_now_add=True)),
                (
                    "feature",
                    models.ForeignKey(
                        on_delete=django.db.models.deletion.CASCADE, to="otto.feature"
                    ),
                ),
                (
                    "user",
                    models.ForeignKey(
                        blank=True,
                        null=True,
                        on_delete=django.db.models.deletion.CASCADE,
                        to=settings.AUTH_USER_MODEL,
                    ),
                ),
                (
                    "cost_type",
                    models.ForeignKey(
                        on_delete=django.db.models.deletion.CASCADE, to="otto.costtype"
                    ),
                ),
            ],
        ),
    ]



=== Contents of django\otto\migrations\0003_cost_document_cost_message_cost_request_id_and_more.py ===
# Generated by Django 5.1 on 2024-09-03 20:32

import django.db.models.deletion
from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ("chat", "0013_rename_cost_message_usd_cost"),
        ("librarian", "0005_rename_cost_document_usd_cost"),
        ("otto", "0002_costtype_feature_short_name_cost"),
    ]

    operations = [
        migrations.AddField(
            model_name="cost",
            name="document",
            field=models.ForeignKey(
                blank=True,
                null=True,
                on_delete=django.db.models.deletion.CASCADE,
                to="librarian.document",
            ),
        ),
        migrations.AddField(
            model_name="cost",
            name="message",
            field=models.ForeignKey(
                blank=True,
                null=True,
                on_delete=django.db.models.deletion.CASCADE,
                to="chat.message",
            ),
        ),
        migrations.AddField(
            model_name="cost",
            name="request_id",
            field=models.CharField(blank=True, max_length=50, null=True),
        ),
        migrations.AlterField(
            model_name="cost",
            name="feature",
            field=models.CharField(
                blank=True,
                choices=[
                    ("librarian", "Librarian"),
                    ("qa", "Q&A"),
                    ("chat", "Chat"),
                    ("translate", "Translate"),
                    ("summarize", "Summarize"),
                    ("template_wizard", "Template wizard"),
                    ("laws_query", "Legislation search"),
                    ("laws_load", "Legislation loading"),
                    ("case_prep", "Case prep assistant"),
                    ("text_extractor", "Text extractor"),
                ],
                max_length=50,
                null=True,
            ),
        ),
    ]



=== Contents of django\otto\migrations\0004_pilot_user_pilot.py ===
# Generated by Django 5.1 on 2024-09-05 13:55

import django.db.models.deletion
from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ("otto", "0003_cost_document_cost_message_cost_request_id_and_more"),
    ]

    operations = [
        migrations.CreateModel(
            name="Pilot",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                ("pilot_id", models.CharField(max_length=50, unique=True)),
                ("name", models.CharField(max_length=100)),
                ("service_unit", models.TextField(blank=True, null=True)),
                ("description", models.TextField(blank=True, null=True)),
                ("start_date", models.DateField(null=True)),
                ("end_date", models.DateField(null=True)),
            ],
        ),
        migrations.AddField(
            model_name="user",
            name="pilot",
            field=models.ForeignKey(
                blank=True,
                null=True,
                on_delete=django.db.models.deletion.SET_NULL,
                to="otto.pilot",
            ),
        ),
    ]



=== Contents of django\otto\migrations\0005_alter_cost_date_incurred.py ===
# Generated by Django 5.1 on 2024-09-05 14:46

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ("otto", "0004_pilot_user_pilot"),
    ]

    operations = [
        migrations.AlterField(
            model_name="cost",
            name="date_incurred",
            field=models.DateField(auto_now_add=True),
        ),
    ]



=== Contents of django\otto\templatetags\__init__.py ===



=== Contents of django\otto\templatetags\filters.py ===
from django import template

register = template.Library()


@register.filter(name="addcss")
def addcss(field, cssArg):
    return field.as_widget(attrs={"class": cssArg})


@register.filter
def iso_date(value):
    if not value:
        return value
    return value.isoformat()



=== Contents of django\otto\templatetags\tags.py ===
from django import template
from django.urls import reverse

register = template.Library()


@register.simple_tag
def get_librarian_modal_url(item_type, item_id):
    url_mapping = {
        "library": "librarian:modal_edit_library",
        "data_source": "librarian:modal_edit_data_source",
        "document": "librarian:modal_edit_document",
    }

    url_name = url_mapping.get(item_type)
    if url_name:
        return reverse(url_name, kwargs={f"{item_type}_id": item_id})
    return "#"



=== Contents of django\otto\utils\auth.py ===
from django.conf import settings
from django.http import HttpResponseRedirect
from django.urls import reverse

from structlog import get_logger

logger = get_logger(__name__)


def map_entra_to_django_user(**fields):
    """
    Used by the Django-Azure-Auth library to map OAuth fields to the Django User model.
    The USERNAME_FIELD is already mapped in settings.py: AZURE_AUTH["USERNAME_ATTRIBUTE"]
    """
    debug_output = "\n ----------------------------- \n OAuth response from Entra: \n ----------------------------- \n"
    for field in fields:
        debug_output += f"{field}: {fields[field]}\n"

    logger.debug(debug_output)

    django_user = {
        # UPN is already mapped in settings.py
        # "upn": fields["userPrincipalName"],
        "email": fields["mail"],
        "first_name": fields["givenName"],
        "last_name": fields["surname"],
        "oid": fields["oid"],
    }
    return django_user


PUBLIC_PATHS = [
    "/azure_auth/login",
    "/azure_auth/logout",
    "/accounts/login/callback",
    "/welcome",
    "/search",
    "/notifications",
]

NO_TERMS_PATHS = PUBLIC_PATHS + ["/", "/accept_terms", "/i18n/setlang", "/feedback"]


class RedirectToLoginMiddleware:
    def __init__(self, get_response):
        self.get_response = get_response

    def __call__(self, request):
        no_trailing_dash_path = request.path.rstrip("/") or "/"
        if no_trailing_dash_path in PUBLIC_PATHS:
            return self.get_response(request)
        # AC-2: User Authentication (Can't be anonymous)
        if not request.user.is_authenticated or request.user.is_anonymous:
            return HttpResponseRedirect(reverse("welcome") + "?next=" + request.path)

        return self.get_response(request)


class AcceptTermsMiddleware:
    def __init__(self, get_response):
        self.get_response = get_response

    def __call__(self, request):
        no_trailing_dash_path = request.path.rstrip("/") or "/"
        if no_trailing_dash_path in NO_TERMS_PATHS:
            return self.get_response(request)
        if not request.user.accepted_terms:
            return HttpResponseRedirect(
                reverse("accept_terms") + "?next=" + request.path
            )

        return self.get_response(request)



=== Contents of django\otto\utils\cache.py ===
"Thread-safe in-memory cache backend."
"!MODIFIED TO REMOVE PICKLING!"
import time
from collections import OrderedDict
from threading import Lock

from django.core.cache.backends.base import DEFAULT_TIMEOUT, BaseCache

# Global in-memory store of cache data. Keyed by name, to provide
# multiple named local memory caches.
_caches = {}
_expire_info = {}
_locks = {}


class LocMemCache(BaseCache):

    def __init__(self, name, params):
        super().__init__(params)
        self._cache = _caches.setdefault(name, OrderedDict())
        self._expire_info = _expire_info.setdefault(name, {})
        self._lock = _locks.setdefault(name, Lock())

    def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):
        key = self.make_and_validate_key(key, version=version)
        with self._lock:
            if self._has_expired(key):
                self._set(key, value, timeout)
                return True
            return False

    def get(self, key, default=None, version=None):
        key = self.make_and_validate_key(key, version=version)
        with self._lock:
            if self._has_expired(key):
                self._delete(key)
                return default
            value = self._cache[key]
            self._cache.move_to_end(key, last=False)
        return value

    def _set(self, key, value, timeout=DEFAULT_TIMEOUT):
        if len(self._cache) >= self._max_entries:
            self._cull()
        self._cache[key] = value
        self._cache.move_to_end(key, last=False)
        self._expire_info[key] = self.get_backend_timeout(timeout)

    def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):
        key = self.make_and_validate_key(key, version=version)
        with self._lock:
            self._set(key, value, timeout)

    def touch(self, key, timeout=DEFAULT_TIMEOUT, version=None):
        key = self.make_and_validate_key(key, version=version)
        with self._lock:
            if self._has_expired(key):
                return False
            self._expire_info[key] = self.get_backend_timeout(timeout)
            return True

    def incr(self, key, delta=1, version=None):
        key = self.make_and_validate_key(key, version=version)
        with self._lock:
            if self._has_expired(key):
                self._delete(key)
                raise ValueError("Key '%s' not found" % key)
            value = self._cache[key]
            new_value = value + delta
            self._cache[key] = new_value
            self._cache.move_to_end(key, last=False)
        return new_value

    def has_key(self, key, version=None):
        key = self.make_and_validate_key(key, version=version)
        with self._lock:
            if self._has_expired(key):
                self._delete(key)
                return False
            return True

    def _has_expired(self, key):
        exp = self._expire_info.get(key, -1)
        return exp is not None and exp <= time.time()

    def _cull(self):
        if self._cull_frequency == 0:
            self._cache.clear()
            self._expire_info.clear()
        else:
            count = len(self._cache) // self._cull_frequency
            for i in range(count):
                key, _ = self._cache.popitem()
                del self._expire_info[key]

    def _delete(self, key):
        try:
            del self._cache[key]
            del self._expire_info[key]
        except KeyError:
            return False
        return True

    def delete(self, key, version=None):
        key = self.make_and_validate_key(key, version=version)
        with self._lock:
            return self._delete(key)

    def clear(self):
        with self._lock:
            self._cache.clear()
            self._expire_info.clear()



=== Contents of django\otto\utils\common.py ===
from django.conf import settings


def file_size_to_string(filesize):
    from django.utils.translation import gettext_lazy as _

    if filesize >= 1024 * 1024:
        return f"{filesize / 1024 / 1024:.2f} {_('MB')}"
    elif filesize >= 1024:
        return f"{filesize / 1024:.2f} {_('KB')}"
    else:
        return f"{filesize} {_('bytes')}"


def display_cad_cost(usd_cost):
    """
    Converts a USD cost to CAD and returns a formatted string
    """
    approx_cost_cad = float(usd_cost) * settings.USD_TO_CAD
    if approx_cost_cad < 0.01:
        return "< $0.01"
    return f"${approx_cost_cad:.2f}"


def cad_cost(usd_cost):
    """
    Converts a USD cost to CAD and returns a float
    """
    approx_cost_cad = float(usd_cost) * settings.USD_TO_CAD
    return approx_cost_cad


def set_costs(object):
    """
    Sums cost.usd_cost from the object's cost_set and assigns total to object.usd_cost
    """
    object.usd_cost = sum([cost.usd_cost for cost in object.cost_set.all()])
    object.save()



=== Contents of django\otto\utils\decorators.py ===
from functools import wraps

from django.contrib.auth import REDIRECT_FIELD_NAME
from django.core.exceptions import PermissionDenied
from django.shortcuts import redirect
from django.urls import reverse
from django.utils.translation import gettext as _

from structlog import get_logger

from otto.models import App, Notification
from otto.rules import ADMINISTRATIVE_PERMISSIONS

logger = get_logger(__name__)


# AC-3: Enforce access controls on specific views and functions
def app_access_required(app_handle):
    def decorator(func):
        @wraps(func)
        def wrapper(request, *args, **kwargs):
            if not request.user.is_authenticated:
                logger.info("User is not authenticated", category="security")
                return redirect(reverse("index"))

            app = App.objects.get(handle=app_handle)
            if not request.user.has_perm("otto.access_app", app):
                logger.info(
                    "User does not have permission to access app",
                    category="security",
                    app=app.name,
                )
                Notification.objects.create(
                    user=request.user,
                    heading=_("Access controls"),
                    text=_("You are not authorized to access") + f" {app.name}",
                    category="error",
                )
                return redirect(reverse("index"))

            return func(request, *args, **kwargs)

        return wrapper

    return decorator


# AC-3: Enforce access controls on specific views and functions
def permission_required(
    perm,
    fn=None,
    login_url=None,
    raise_exception=False,
    redirect_field_name=REDIRECT_FIELD_NAME,
):
    # Modification of rules.contrib.views.permission_required
    def decorator(view_func):
        @wraps(view_func)
        def _wrapped_view(request, *args, **kwargs):
            # Normalize to a list of permissions
            if isinstance(perm, str):
                perms = (perm,)
            else:
                perms = perm

            # Get the object to check permissions against
            if callable(fn):
                obj = fn(request, *args, **kwargs)
            else:  # pragma: no cover
                obj = fn

            # Get the user
            user = request.user

            # Check for permissions and return a response
            if not user.has_perms(perms, obj):
                logger.info(
                    "User does not have permission",
                    admin=bool(ADMINISTRATIVE_PERMISSIONS.intersection(perms)),
                    category="security",
                    path=request.path,
                    perms=perms,
                )
                # User does not have a required permission
                if raise_exception:
                    raise PermissionDenied()
                else:
                    Notification.objects.create(
                        user=request.user,
                        heading="Access controls",
                        text=_(f"Unauthorized access of URL:") + f" {request.path}",
                        category="error",
                    )
                    return redirect(reverse("index"))
            else:
                # User has all required permissions -- allow the view to execute
                if bool(ADMINISTRATIVE_PERMISSIONS.intersection(perms)):
                    logger.info(
                        "Administrative access granted",
                        admin=True,
                        category="security",
                        path=request.path,
                        perms=perms,
                    )
                return view_func(request, *args, **kwargs)

        return _wrapped_view

    return decorator



=== Contents of django\otto\utils\entra.py ===
import os

from django.conf import settings

from asgiref.sync import sync_to_async
from attr import dataclass
from azure.identity import ClientSecretCredential
from kiota_abstractions.api_error import APIError
from msgraph import GraphServiceClient
from msgraph.generated.users.users_request_builder import UsersRequestBuilder
from structlog import get_logger

from otto.models import User

credential = ClientSecretCredential(
    tenant_id=settings.ENTRA_AUTHORITY.split("/")[-1],
    client_id=settings.ENTRA_CLIENT_ID,
    client_secret=settings.ENTRA_CLIENT_SECRET,
)

client = GraphServiceClient(credential)
logger = get_logger(__name__)


@dataclass
class EntraUser:
    id: str
    upn: str
    email: str
    display_name: str
    first_name: str
    last_name: str


async def get_entra_users_async():

    page_size = 100

    query_params = UsersRequestBuilder.UsersRequestBuilderGetQueryParameters(
        select=[
            "id",
            "mail",
            "givenName",
            "displayName",
            "accountEnabled",
            "surname",
            "userprincipalname",
        ],
        top=page_size,
        filter="accountEnabled eq true",
        count=True,
    )
    request_configuration = (
        UsersRequestBuilder.UsersRequestBuilderGetRequestConfiguration(
            query_parameters=query_params
        )
    )
    request_configuration.headers.add("ConsistencyLevel", "eventual")

    entra_users_list = []
    batch_number = 1

    try:
        logger.debug(f"Processing batch {batch_number}")
        result = await client.users.get(request_configuration)
        total_count = round(result.odata_count / page_size)
        batch_number += 1

        entra_users_list = __filter_users(result.value)

        next_iteration = result.odata_next_link

        while next_iteration:
            logger.debug(f"Processing batch {batch_number} of {total_count}")
            result = await client.users.with_url(next_iteration).get()
            entra_users_list += __filter_users(result.value)
            next_iteration = result.odata_next_link
            batch_number += 1
    except APIError as e:
        logger.error(
            f"Error trying to retrieve batch {batch_number} of entra users: {e.error.message}"
        )

    return entra_users_list


async def get_entra_user_async(user_id: str) -> EntraUser:
    result = await client.users.by_user_id(user_id).get()
    result = EntraUser(
        result.id,
        result.user_principal_name,
        result.mail,
        result.display_name,
        result.given_name,
        result.surname,
    )

    return result


async def sync_users_with_entra_async():
    """Syncs entra users with Otto. Users in Otto not present in entra are flagged as inactive."""

    users = await get_entra_users_async()

    logger.info("Updating Otto...")
    for user in users:
        await User.objects.aupdate_or_create(
            upn=user.upn,
            defaults={
                "oid": user.id,
                "upn": user.upn,
                "email": user.email,
                "last_name": user.last_name,
                "first_name": user.first_name,
                "is_active": True,
            },
        )

    await set_inactive_users_async(users)


async def set_inactive_users_async(users):
    logger.info("Setting Inactive Users...")
    users_upn = [user.upn for user in users]
    inactive_users = await sync_to_async(User.objects.exclude)(upn__in=users_upn)

    async for inactive_user in inactive_users:
        inactive_user.is_active = False

    await User.objects.abulk_update(inactive_users, ["is_active"])


def __filter_users(users) -> list[EntraUser]:
    users_list = []
    for user in users:
        if user.user_principal_name and user.account_enabled:
            upn = user.user_principal_name.lower()

            if (
                "disabled" not in upn
                and ".ndr" not in upn
                and "admin." not in upn
                and "#" not in upn
                and "," in user.display_name
                and user.given_name
                and user.surname
            ):
                users_list.append(
                    EntraUser(
                        user.id,
                        user.user_principal_name,
                        user.mail,
                        user.display_name,
                        user.given_name,
                        user.surname,
                    )
                )
    return users_list



=== Contents of django\otto\utils\localization.py ===
import json
import os
from uuid import uuid4

import polib
import requests


class LocaleTranslator:

    def __init__(self, key: str, region: str, endpoint: str) -> None:
        self.key = key
        self.region = region
        self.endpoint = endpoint

    def update_translations(self, locale_dir) -> None:

        translations_file = os.path.join(locale_dir, "translation", "translations.json")
        translations = self.__load_translations(translations_file)

        self.__update_po_file(locale_dir, translations)

        self.__save_translations(translations_file, translations)

    # Might be better to move this in a general translation class with all other translation methods.
    def translate_text(self, text: str) -> str:
        engine = "azure"

        # Build the request
        params = {"api-version": "3.0", "to": "fr-ca"}

        headers = {
            "Ocp-Apim-Subscription-Key": self.key,
            "Ocp-Apim-Subscription-Region": self.region,
            "Content-Type": "application/json",
            "X-ClientTraceId": str(uuid4().hex),
            # Visual Studio Enterprise
            "X-MS-CLIENT-PRINCIPAL-NAME": "41ede1ad-d5e6-4b6f-bd8e-979eb3813b47",
        }
        body = [{"Text": text}]

        # Send the request and get response
        url = f"{self.endpoint}/translator/text/v3.0/translate"
        response = requests.post(url, params=params, headers=headers, json=body)

        # Get translation
        translation = response.json()[0]["translations"][0]["text"]
        return translation

    def __load_translations(self, translations_file):
        with open(translations_file, "r", encoding="utf-8") as json_file:
            translations = json.load(json_file)
        return translations

    def __save_translations(self, translations_file, translations):
        with open(translations_file, "w", encoding="utf-8") as json_file:
            json.dump(translations, json_file, ensure_ascii=False, indent=4)

    def __update_po_file(self, dir, translations_reference):
        po_file_path = os.path.join(dir, "fr", "LC_MESSAGES", "django.po")
        po_file = polib.pofile(po_file_path)

        valid_entries = [entry for entry in po_file if not entry.obsolete]
        print(f"Loaded {len(valid_entries)} entries.")

        for entry in valid_entries:
            translation_id = entry.msgid
            fr = ""
            fr_auto = ""
            if translation_id in translations_reference:
                fr = translations_reference[translation_id].get("fr")
                fr_auto = translations_reference[translation_id].get("fr_auto")

                if fr:
                    fr = fr
                    fr_auto = fr_auto
                    print(f'Using manual translation for "{translation_id}."')
                elif entry.msgstr:
                    fr = ""
                    fr_auto = entry.msgstr
                    print(
                        f'Machine translation entry for "{translation_id}" already exists.'
                    )
                elif fr_auto:
                    fr = ""
                    fr_auto = fr_auto
                    print(
                        f'Machine translation entry for "{translation_id}" already exists.'
                    )
                else:
                    fr = ""
                    fr_auto = self.translate_text(translation_id)
                    print(f'Translating "{translation_id}."')
            else:
                fr = ""
                fr_auto = (
                    entry.msgstr
                    if entry.msgstr
                    else self.translate_text(translation_id)
                )
                print(f'Creating and translating entry "{translation_id}".')

            translations_reference[translation_id] = {"fr": fr, "fr_auto": fr_auto}
            entry.msgstr = fr if fr else fr_auto

        print(f"Updating file at path: {po_file_path}.")
        po_file.save(po_file_path)



=== Contents of django\otto\utils\logging.py ===
from typing import Any, Mapping, MutableMapping

from django.dispatch import receiver

import structlog
from django_structlog.signals import bind_extra_request_metadata
from structlog.processors import CallsiteParameter


@receiver(bind_extra_request_metadata)
def bind_username(request, logger, log_kwargs, **kwargs):
    if request.user.is_authenticated:
        structlog.contextvars.bind_contextvars(upn=getattr(request.user, "upn", None))


# Helper formatting function found here: https://github.com/jrobichaud/django-structlog/issues/29
def merge_pathname_lineno_function_to_location(
    logger: structlog.BoundLogger, name: str, event_dict: MutableMapping[str, Any]
) -> Mapping[str, Any]:
    pathname = event_dict.pop(CallsiteParameter.PATHNAME.value, None)
    lineno = event_dict.pop(CallsiteParameter.LINENO.value, None)
    func_name = event_dict.pop(CallsiteParameter.FUNC_NAME.value, None)
    event_dict["location"] = f"{pathname}:{lineno}({func_name})"
    return event_dict



=== Contents of django\otto\utils\mark_docx.py ===
"""
Recursively search for .docx files in the given directory and add headers/footers to them.
By default, the script will replace the header and footer in document with the text "AI-generated content".
Arguments:
    dir: The directory to search for .docx files. (positional, required)
    mark_text: The text to add to the header and footer. Default is "AI-generated content". (2nd position, optional)
    areas: The areas to add the mark text to. Default is ["header", "footer"]. (3rd position, optional)
"""

import argparse
import os

from docx import Document
from docx.shared import Pt, RGBColor


def mark_docx(docx_path, mark_text="AI-generated content", areas=["header", "footer"]):
    doc = Document(docx_path)
    for section in doc.sections:
        for el in [getattr(section, area) for area in areas]:
            if el is not None:
                el.is_linked_to_previous = False
                el.paragraphs[0].clear()
                run = el.paragraphs[0].add_run(mark_text)
                run.bold = True
                run.font.color.rgb = RGBColor(128, 128, 128)  # Set RGB color to grey
                run.font.size = Pt(18)  # Set font size to 24
                el.paragraphs[0].alignment = 1
    doc.save(docx_path)


def main():
    parser = argparse.ArgumentParser(
        description="Recursively search for .docx files in the given directory and add headers/footers to them."
    )
    parser.add_argument("dir", help="The directory to search for .docx files.")
    parser.add_argument(
        "mark_text",
        nargs="?",
        default="AI-generated content",
        help="The text to add to the header and/or footer. Default is 'AI-generated content'.",
    )
    parser.add_argument(
        "areas",
        nargs="*",
        default=["header", "footer"],
        help="The areas to add the mark text to. Default is ['header', 'footer'].",
    )
    args = parser.parse_args()
    for root, dirs, files in os.walk(args.dir):
        for file in files:
            if file.endswith(".docx"):
                mark_docx(os.path.join(root, file), args.mark_text, args.areas)



=== Contents of django\otto\utils\notification.py ===
from django.conf import settings

import requests


def send_via_gc_notify(data):
    api_key = settings.GC_NOTIFY_KEY
    url = "https://api.notification.canada.ca/v2/notifications/email"

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"ApiKey-v1 {api_key}",
    }

    response = requests.post(url, json=data, headers=headers)
    return response



=== Contents of django\otto\utils\sql_utils.py ===
from django.db import connections


def execute_query(connection, query, params=None):
    with connections[connection].cursor() as cursor:
        if params is None:
            cursor.execute(query)
        else:
            cursor.execute(query, params)
        rows = cursor.fetchall()
        columns = [col[0] for col in cursor.description]
        results = [dict(zip(columns, row)) for row in rows]
        return results



=== Contents of django\template_wizard\__init__.py ===



=== Contents of django\template_wizard\admin.py ===
from django.contrib import admin

# Register your models here.



=== Contents of django\template_wizard\apps.py ===
import os

from django.apps import AppConfig
from django.conf import settings


class TemplateWizardConfig(AppConfig):
    default_auto_field = "django.db.models.BigAutoField"
    name = "template_wizard"

    def ready(self):
        # This line ensures that the import happens when the app is ready,
        # preventing any AppRegistryNotReady exception.
        from django.core.files.storage import default_storage as storage

        # Define the path for the wizard_input_path directory
        wizard_input_path = os.path.join(settings.MEDIA_ROOT, "uploads")

        # Check if the directory exists, and create it if it doesn't
        if not storage.exists(wizard_input_path):
            os.makedirs(wizard_input_path, exist_ok=True)

        # Define the path for the wizard_output_path directory
        wizard_output_path = os.path.join(settings.MEDIA_ROOT, "generated_reports")

        # Check if the directory exists, and create it if it doesn't
        if not storage.exists(wizard_output_path):
            os.makedirs(wizard_output_path, exist_ok=True)



=== Contents of django\template_wizard\models.py ===
from django.db import models

from otto.secure_models import SecureModel


class Report(SecureModel):
    name = models.CharField(max_length=255, default="Untitled report")
    wizard = models.CharField(max_length=255)
    data = models.JSONField(null=True, blank=True)
    created_at = models.DateTimeField(auto_now_add=True)

    def __str__(self):
        return f"{self.name} - {self.created_at.strftime('%Y-%m-%d %H:%M:%S')}"



=== Contents of django\template_wizard\translation.py ===



=== Contents of django\template_wizard\urls.py ===
from django.urls import include, path

from . import views

app_name = "template_wizard"

urlpatterns = [
    path("", views.index, name="index"),
    path("<str:report_id>/select-data", views.select_data, name="select_data"),
    path(
        "<str:report_id>/pick-template",
        views.pick_template,
        name="pick_template",
    ),
    path(
        "<str:report_id>/delete-report",
        views.delete_report,
        name="delete_report",
    ),
    path(
        "<str:report_id>/canlii_wizard/",
        include("template_wizard.wizards.canlii_wizard.urls"),
    ),
]



=== Contents of django\template_wizard\views.py ===
# views.py

from django.conf import settings
from django.shortcuts import redirect, render

from structlog import get_logger

from otto.secure_models import AccessKey
from otto.utils.decorators import app_access_required, permission_required
from template_wizard.metrics.template_wizard_activity_metrics import (
    template_wizard_access_total,
)

from .models import Report

logger = get_logger(__name__)

app_name = "template_wizard"

WIZARD_CHOICES = [
    {
        "handle": "canlii_wizard",
        "name": "CanLii case summarizer",
        "description": "Extract immigration data from case files and populate a template for document review and processing.",
    },
    # {
    #     "handle": "lex_wizard",
    #     "name": "LEX case summarizer",
    #     "description": "Extract litigation details from LEX, build an event calendar, and populate a template for organized case-specific reports.",
    #     "permission_check": "template_wizard.access_lex_wizard",
    # },
]


@app_access_required(app_name)
def index(request):

    # usage metrics
    template_wizard_access_total.labels(user=request.user.upn).inc()

    access_key = AccessKey(user=request.user)

    if request.method == "POST":
        new_or_open = request.POST.get("new_or_open", "new")

        if new_or_open == "new":
            # Make sure the user has add permission to create Reports
            if not Report.can_be_created_by(access_key):
                Report.grant_create_to(access_key)
            report = Report.objects.create(access_key)
            report.wizard = request.POST.get("wizard")
            report.save(access_key)
        else:
            report_id = request.POST.get("report_id")
            report = Report.objects.get(access_key, id=report_id)

        return redirect("template_wizard:select_data", report.id)

    reports = Report.objects.all(access_key)

    # For each of the reports, lookup the wizard name and add it to the report object
    for report in reports:
        try:
            report.wizard_name = next(
                wizard["name"]
                for wizard in WIZARD_CHOICES
                if wizard["handle"] == report.wizard
            )
        except StopIteration:
            report.wizard_name = "Unknown"

    permitted_wizard_choices = [
        wizard
        for wizard in WIZARD_CHOICES
        if (not wizard.get("permission_check"))
        or request.user.has_perm(wizard["permission_check"])
    ]

    context = {
        "active_step": 1,
        "wizards": permitted_wizard_choices,
        "reports": reports,
        "hide_breadcrumbs": True,
    }

    return render(request, "template_wizard/get_started.html", context)


@app_access_required(app_name)
def select_data(request, report_id):
    access_key = AccessKey(user=request.user)

    report = Report.objects.get(access_key, id=report_id)

    if request.method == "POST":
        return redirect("template_wizard:pick_template", report_id)

    # if report.wizard == "lex_wizard":

    #     from .wizards.lex_wizard.views import select_data

    #     context = select_data(request, report)
    #     context.update(
    #         {
    #             "active_step": 2,
    #             "report": report,
    #             "hide_breadcrumbs": True,
    #             "wizard_name": "LEX case summarizer",
    #         }
    #     )

    #     return render(request, "template_wizard/lex_wizard/select_data.html", context)

    if report.wizard == "canlii_wizard":

        from .wizards.canlii_wizard.views import select_data

        context = select_data(request, report)
        context.update(
            {
                "active_step": 2,
                "report": report,
                "hide_breadcrumbs": True,
                "wizard_name": "CanLii case summarizer",
            }
        )
        return render(
            request, "template_wizard/canlii_wizard/select_data.html", context
        )


@app_access_required(app_name)
def delete_report(request, report_id):
    access_key = AccessKey(user=request.user)

    logger.info(f"Deleting report {report_id}")

    report = Report.objects.get(access_key, id=report_id)
    report.delete(access_key)

    # Render the existing_reports_partial.html template and return it as HttpResponse
    reports = Report.objects.all(access_key)

    # For each of the reports, lookup the wizard name and add it to the report object
    for report in reports:
        try:
            report.wizard_name = next(
                wizard["name"]
                for wizard in WIZARD_CHOICES
                if wizard["handle"] == report.wizard
            )
        except StopIteration:
            report.wizard_name = "Unknown"

    context = {
        "reports": reports,
        "hide_breadcrumbs": True,
    }

    return render(request, "template_wizard/existing_reports_partial.html", context)


@app_access_required(app_name)
def pick_template(request, report_id):
    access_key = AccessKey(user=request.user)

    logger.info(f"Picking template for report {report_id}")

    report = Report.objects.get(access_key, id=report_id)

    # if report.wizard == "lex_wizard":

    #     from .wizards.lex_wizard.views import pick_template

    #     context = pick_template(request, report)
    #     context.update(
    #         {
    #             "active_step": 3,
    #             "report": report,
    #             "hide_breadcrumbs": True,
    #             "wizard_name": "LEX case summarizer",
    #         }
    #     )

    #     return render(request, "template_wizard/lex_wizard/pick_template.html", context)

    if report.wizard == "canlii_wizard":

        from .wizards.canlii_wizard.views import pick_template

        context = pick_template(request, report)
        context.update(
            {
                "active_step": 3,
                "report": report,
                "hide_breadcrumbs": True,
                "wizard_name": "CanLii case summarizer",
            }
        )
        return render(
            request, "template_wizard/canlii_wizard/pick_template.html", context
        )



=== Contents of django\template_wizard\metrics\__init__.py ===



=== Contents of django\template_wizard\metrics\template_wizard_activity_metrics.py ===
from prometheus_client import Counter

template_wizard_access_total = Counter(
    name="template_wizard_access_total",
    documentation="number of times the template wizard has been accessed by users",
    labelnames=["user"],
)



=== Contents of django\template_wizard\migrations\__init__.py ===



=== Contents of django\template_wizard\migrations\0001_initial.py ===
# Generated by Django 5.0.7 on 2024-07-25 20:33

from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        ("otto", "0001_initial"),
    ]

    operations = [
        migrations.CreateModel(
            name="Report",
            fields=[
                (
                    "id",
                    models.UUIDField(editable=False, primary_key=True, serialize=False),
                ),
                ("name", models.CharField(default="Untitled report", max_length=255)),
                ("wizard", models.CharField(max_length=255)),
                ("data", models.JSONField(blank=True, null=True)),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                ("access_controls", models.ManyToManyField(to="otto.accesscontrol")),
            ],
            options={
                "abstract": False,
            },
        ),
    ]



=== Contents of django\template_wizard\wizards\__init__.py ===



=== Contents of django\template_wizard\wizards\canlii_wizard\__init__.py ===



=== Contents of django\template_wizard\wizards\canlii_wizard\urls.py ===
# urls.py

from django.urls import path

from . import views

urlpatterns = [
    path(
        "add_report_data", views.add_report_data, name="canlii_wizard_add_report_data"
    ),
    path(
        "pick_template",
        views.pick_template,
        name="canlii_wizard_pick_template",
    ),
    path(
        "generate_report",
        views.generate_report,
        name="canlii_wizard_generate_report",
    ),
    path(
        "download_generated_report/<str:generated_report_id>",
        views.download_generated_report,
        name="canlii_wizard_download_generated_report",
    ),
    path(
        "delete_generated_report/<str:generated_report_id>",
        views.delete_generated_report,
        name="canlii_wizard_delete_generated_report",
    ),
]



=== Contents of django\template_wizard\wizards\canlii_wizard\utils.py ===
import asyncio
import concurrent.futures
import io
import math
import os
import re
import tempfile
from datetime import datetime as dt
from uuid import uuid4

from django.conf import settings

import docx
import fitz
import markdown
import tiktoken
from bs4 import BeautifulSoup
from docxtpl import DocxTemplate
from langchain.chains import ReduceDocumentsChain
from langchain.chains.combine_documents.stuff import StuffDocumentsChain
from langchain.chains.llm import LLMChain
from langchain.prompts import PromptTemplate
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import AzureChatOpenAI
from openai import AzureOpenAI
from pptx import Presentation

client = AzureOpenAI(
    api_key=settings.AZURE_OPENAI_KEY,
    api_version=settings.AZURE_OPENAI_VERSION,
    azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
)

model_str = settings.DEFAULT_CHAT_MODEL

system_prompt = {
    "en": "You are a legal professional who is tasked with reviewing a case and writing legal case reports. You're going to extract and write information from the following content and will only use the facts provided in the content I provide you. When providing responses, please use paragraphs instead of bullet points. Do not include question marks or exclamation marks, and ensure a constant professional style of writing throughout all your responses.",
    "fr": "Vous tes un professionnel du droit charg d'examiner un dossier et de rdiger des rapports juridiques. Vous allez extraire et rdiger des informations  partir du contenu suivant et n'utiliserez que les faits fournis dans le contenu que je vous fournis. Lorsque vous fournissez des rponses, veuillez utiliser des paragraphes au lieu de points de puce. N'incluez pas de points d'interrogation ou d'exclamation, et assurez-vous d'avoir un style d'criture professionnel constant dans toutes vos rponses.",
}

# use this for french months
months_in_french = {
    "january": "janvier",
    "february": "fvrier",
    "march": "mars",
    "april": "avril",
    "may": "mai",
    "june": "juin",
    "july": "juillet",
    "august": "aot",
    "september": "septembre",
    "october": "octobre",
    "november": "novembre",
    "december": "dcembre",
}
acronym_dict = {
    "IRB": "Immigration and Refugee Board",
    "RPD": "Refugee Protection Division of the IRB",
    "RAD": "Refugee Appeal Division of the IRB",
    "ID": "Immigration Division of the IRB",
    "IAD": "Immigration Appeal Division of the IRB",
    "IRCC": "Immigration, Refugees and Citizenship Canada",
    "IRPA": "Immigration and Refugee Protection Act",
    "IRP Regulations": "Immigration and Refugee Protection Regulations",
    "FOSS": "Field Operational Support System",
    "CAIPS": "Computer Assisted Immigration Processing System",
    "GCMS": "Global Case Management System",
    "MCI": "Minister of Citizenship and Immigration",
    "CIC": "Citizenship and Immigration Canada",
    "PRRA": "Pre-Removal Risk Assessment",
    "H&amp;C": "Humanitarian and Compassionate",
    "BIOC": "Best interests of the child",
    "DCO": "Designated Country of Origin",
    "MPSEP": "Minister of Public Safety and Emergency Preparedness",
    "CBSA": "Canada Border Services Agency",
}


def map_reduce(text, language, model_str):

    length_prompt_en = "Write down a long document with large paragraphs containing multiple sentences that detail all important details of the text (in English). Simply rewrite; do not say 'This document is about...' etc, this not just a summary but a detailed rewording of the information presented. There is no length limit - be as detailed as possible. However, **do not extrapolate** on the text. The document that you will write must be factual and not introduce any new ideas. Remember, do not list information in bullet points, make sure the response is in the form of a long documents with multiple paragraphs."

    length_prompt_fr = "crivez un long document avec de grands paragraphes contenant plusieurs phrases qui dtaillent tous les dtails importants du texte (en anglais). Il suffit de le rcrire; ne dites pas 'Ce document parle de...' etc, ce n'est pas seulement un rsum mais une reformulation dtaille des informations prsentes. Il n'y a pas de limite de longueur - soyez aussi dtaill que possible. Cependant, n'extrapolez pas sur le texte. Le document que vous crirez doit tre factuel et ne doit introduire aucune nouvelle ide. N'oubliez pas, ne rpertoriez pas les informations sous forme de points, assurez-vous que la rponse est sous forme d'un long document avec plusieurs paragraphes."

    llm = AzureChatOpenAI(
        azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
        azure_deployment=model_str,
        model=model_str,
        api_version=settings.AZURE_OPENAI_VERSION,
        api_key=settings.AZURE_OPENAI_KEY,
        temperature=0.3,
    )

    reduce_template_en = (
        "The following are parts of a larger document:\n\n"
        "{docs}\n\n"
        f"{length_prompt_en}. Return it in markdown format.\n"
        "Helpful Answer:"
    )
    reduce_template_fr = (
        "Les rsums suivants ont t gnrs  partir d'un document:\n\n"
        "{docs}\n\n"
        f"Prenez-les et rcrivez-le en un rsum final. {length_prompt_fr}. Renvoyez-le au format markdown.\n"
        "Rponse utile:"
    )
    reduce_template = reduce_template_fr if language == "fr" else reduce_template_en
    reduce_prompt = PromptTemplate.from_template(reduce_template)

    # Run chain
    reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)

    # Takes a list of documents, combines them into a single string, and passes this to an LLMChain
    combine_documents_chain = StuffDocumentsChain(
        llm_chain=reduce_chain, document_variable_name="docs"
    )

    # Combines and iteratively reduces the mapped documents
    reduce_documents_chain = ReduceDocumentsChain(
        # This is final chain that is called.
        combine_documents_chain=combine_documents_chain,
        # If documents exceed context for `StuffDocumentsChain`
        collapse_documents_chain=combine_documents_chain,
        # The maximum number of tokens to group documents into.
        token_max=15000,
    )

    # Split the text into chunks
    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
        chunk_size=12000, chunk_overlap=100
    )

    docs = [Document(page_content=text, metadata={"source": "userinput"})]

    split_docs = text_splitter.split_documents(docs)

    async def run_map_reduce():

        # Run the chain asynchronously and return the result when it's done
        return await reduce_documents_chain.arun(split_docs)

    response = asyncio.run(run_map_reduce())

    return response


def trim_to_tokens(text, max_tokens=15000):
    # Initialize the tokenizer with the specified encoding
    enc = tiktoken.get_encoding("cl100k_base")

    # Encode the input text, getting token IDs
    token_ids = enc.encode(text)

    # Trim token IDs to get the beginning and end parts as specified
    tokens_beginning = (
        token_ids[:max_tokens] if len(token_ids) > max_tokens else token_ids
    )
    tokens_end = token_ids[-max_tokens:] if len(token_ids) > max_tokens else []

    # Decode the trimmed token IDs back into text
    trimmed_beginning = enc.decode(tokens_beginning)
    trimmed_end = enc.decode(tokens_end) if tokens_end else ""

    return trimmed_beginning, trimmed_end


def extract_text_from_pdf(pdf_file):
    # Save file to temporary storage and get the path
    with tempfile.NamedTemporaryFile(delete=False) as temp_file:
        for chunk in pdf_file.chunks():
            temp_file.write(chunk)
        temp_file_path = temp_file.name
    doc = fitz.open(temp_file_path)
    text = "\n".join(page.get_text() for page in doc)
    doc.close()
    os.unlink(temp_file_path)  # delete the temporary file
    return text


def convert_to_text(file, content_type=None):
    text = ""
    if content_type is None:
        content_type = file.content_type
    if (
        content_type
        == "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    ):
        doc = docx.Document(file)
        fullText = []
        for para in doc.paragraphs:
            fullText.append(para.text)
        text = "\n".join(fullText)
        text = text.replace(".", ". ")

    elif content_type == "application/pdf":
        text = extract_text_from_pdf(file)

    elif content_type == "text/plain":
        text = file.read().decode("utf-8")

    # Extract text from PowerPoint file
    elif (
        content_type
        == "application/vnd.openxmlformats-officedocument.presentationml.presentation"
    ):
        prs = Presentation(file)
        text = ""
        for slide in prs.slides:
            for shape in slide.shapes:
                if hasattr(shape, "text"):
                    text += shape.text + " "

    elif content_type == "text/html":
        file_content = file.read()
        soup = BeautifulSoup(file_content, "html.parser")

        # kill all script and style elements
        for script in soup(["script", "style"]):
            script.decompose()  # rip it out

        # get text
        text = soup.get_text()
        text = text.replace(".", ". ")

        # break into lines and remove leading and trailing space on each
        lines = (line.strip() for line in text.splitlines())
        # break multi-headlines into a line each
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        # drop blank lines
        text = "\n".join(chunk for chunk in chunks if chunk)

    return text


def extract_sections(input_string, sections=["Facts", "Findings"]):
    data = {section: None for section in sections}

    for i, section in enumerate(sections):
        if f"{section}:" in input_string:
            start = input_string.index(f"{section}:") + len(f"{section}:")
            end = len(input_string)
            if i < len(sections) - 1:  # If not the last section
                next_section = sections[i + 1]
                if f"{next_section}:" in input_string:
                    end = input_string.index(f"{next_section}:")
            data[section] = input_string[start:end].strip()

    return data


def extract_using_generative(extraction_word, content, model_link, language):

    question = {
        "en": f"""Extract the {extraction_word} from this case. Only write down the {extraction_word}, don't go into more details. Don't write down "The {extraction_word} is ...", simply writing down the {extraction_word} itself is enough.""",
        "fr": f"""Extrait {extraction_word} de ce cas. cris seulement {extraction_word}, ne donne pas plus de dtails. N'cris pas "{extraction_word} est ..." simplement crire {extraction_word} sans phrase de contexte est suffisant.""",
    }
    extraction = client.chat.completions.create(
        model=model_link,  # model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": system_prompt[language]},
            {"role": "user", "content": "### Content: " + content},
            {"role": "user", "content": "### Question: " + question[language]},
        ],
        temperature=0.1,  # set this to a low value, such as 0.2, to make the output more focused and deterministic. This will reduce the randomness in the generated response
        top_p=1.0,  # set this to a high value, such as 0.9 or 1, so that the model only considers the tokens with the highest probability mass. This will make the output more predictable and less likely to generate unexpected responses.
        frequency_penalty=0.0,  # set this to a high positive value, such as 2.0, to penalize the model for repeating the same line verbatim. This will encourage the model to generate more diverse responses.
        presence_penalty=1.8,  # set this to a high positive value, such as 2.0, to penalize the model for introducing new tokens that do not appear in the input text. This will encourage the model to generate responses that are more closely related to the input text.
    )

    return extraction.choices[0].message.content, extraction.usage.total_tokens


def extract_court_judgment(content, model_str, language):

    question = {
        "en": """Find the complete court's judgment found under "THIS COURTS JUDGMENT is that:". Make sure each individual court judgment is listed and numbered, in the form of 1. First court judgment 2. Second court judgment, and so forth. Your reply should simply be the complete list of the court judgment, don't include anything else.""",
        "fr": """Trouvez le jugement complet du tribunal sous "LE JUGEMENT DE CE TRIBUNAL est que:". Assurez-vous que chaque jugement individuel du tribunal est rpertori et numrot, sous la forme de 1. Premier jugement du tribunal 2. Deuxime jugement du tribunal, et ainsi de suite. Votre rponse devrait simplement tre la liste du jugement complet du tribunal, ne comprenant rien d'autre.""",
    }
    extraction = client.chat.completions.create(
        model=model_str,
        messages=[
            {"role": "system", "content": system_prompt[language]},
            {"role": "user", "content": "### Content: " + content},
            {"role": "user", "content": "### Question: " + question[language]},
        ],
        temperature=0.1,  # set this to a low value, such as 0.2, to make the output more focused and deterministic. This will reduce the randomness in the generated response
        frequency_penalty=0.0,  # set this to a high positive value, such as 2.0, to penalize the model for repeating the same line verbatim. This will encourage the model to generate more diverse responses.
        presence_penalty=1.8,  # set this to a high positive value, such as 2.0, to penalize the model for introducing new tokens that do not appear in the input text. This will encourage the model to generate responses that are more closely related to the input text.
    )

    return extraction.choices[0].message.content, extraction.usage.total_tokens


def replace_with_acronyms(text, acronym_dict):
    for acronym, full_version in acronym_dict.items():
        # Pattern to match the full version followed by an optional any text in parentheses
        regex_pattern = r"\b" + re.escape(full_version) + r"\b(?: \([^)]*\))?"
        # Replace the pattern with just the acronym
        text = re.sub(regex_pattern, acronym, text, flags=re.IGNORECASE)
    return text


def extract_meta_info(text_for_regex, text_for_llm, model_str, language):
    extra_cost = 0
    # Extract date
    date_match = re.search(r"Date:\s*(\d{4})((\s*(\d{1,2}))+)", text_for_regex)
    if date_match:
        matched_date = (
            "".join(date_match.groups())
            .replace("\n", "")
            .replace("\t", "")
            .replace(" ", "")
        )
        # Split based on number of digits
        year = int(matched_date[:4])
        month = int(matched_date[4:6])
        day = int(matched_date[6:8])
        date_obj = dt(year, month, day)

        if (
            language == "fr"
            and date_obj.strftime("%B").lower() in months_in_french.keys()
        ):
            # Get the month name in French
            month_name_french = months_in_french[date_obj.strftime("%B").lower()]

            # Format the date manually in French
            date = f"{day} {month_name_french.title()} {year}"  # Format like '31 Octobre 2023'
        else:

            # Format the date
            date = date_obj.strftime("%B %d, %Y")  # Format like 'October 23, 2023'

    else:
        extraction_word = "date" if language == "en" else "la date"
        date, date_cost = extract_using_generative(
            extraction_word, text_for_llm, model_str, language
        )
        extra_cost += date_cost

    # Extract docket number
    docket_match = re.search(
        r"(Docket|DOCKET):\s*([A-Z]+)\s*-\s*(\d+)\s*-\s*(\d+)", text_for_regex
    )
    if docket_match:
        docket_number = "-".join(
            docket_match.groups()[1:]
        )  # Excluding the first group as it's "Docket" or "DOCKET"
    else:
        extraction_word = (
            "docket number" if language == "en" else "le numro de dossier"
        )
        docket_number, docket_number_cost = extract_using_generative(
            extraction_word, text_for_llm, model_str, language
        )
        extra_cost += docket_number_cost

    # Extract citation
    citation_match = re.search(
        r"Citation:\s*(\d{4})\s*([A-Z]+)\s*(\d+)", text_for_regex
    )
    if citation_match:
        citation = " ".join(citation_match.groups())
    else:
        extraction_word = "citation" if language == "en" else "la rfrence"
        citation, citation_cost = extract_using_generative(
            extraction_word, text_for_llm, model_str, language
        )
        extra_cost += citation_cost
    citation.replace("\n", " ").strip()

    # Extract the title
    question = {
        "en": "Find the title of this legal case. Write it in the format with the first entity before 'v.' and the second entity after. For example, Applicant v. Respondent. Only output the title itself, don't write anything else. Also make sure the reponse is in the format of a title with the appropirate capitalization.",
        "fr": "Trouvez le titre de cette affaire juridique. crivez-le dans le format avec la premire entit avant 'v.' et la deuxime entit aprs. Par exemple, Demandeur v. Dfendeur. Ne mentionnez que le titre lui-mme, n'crivez rien d'autre. Assurez-vous galement que la rponse est dans le format d'un titre avec la capitalisation approprie.",
    }

    title = client.chat.completions.create(
        model=model_str,
        messages=[
            {"role": "system", "content": system_prompt[language]},
            {"role": "user", "content": "### Content: " + text_for_llm},
            {"role": "user", "content": "### Question: " + question[language]},
        ],
        temperature=0.1,
        frequency_penalty=0.0,
        presence_penalty=1.8,
    )
    title = title.choices[0].message.content

    return date, docket_number, citation, title, extra_cost


def generate_immigration_case_report(text, language="en"):

    extra_cost = 0

    enc = tiktoken.get_encoding("cl100k_base")
    using_large_doc = False

    # Count how many characters are in the text
    token_count = len(enc.encode(text))

    # TODO: Change this to gpt-4 once we figure out how to deal with the gpt-4 delay errors
    token_count_max = 15000
    if token_count < token_count_max:
        content = text
    else:
        content = map_reduce(text, language, model_str)
        using_large_doc = True

    beginning_of_doc, end_of_doc = trim_to_tokens(text, max_tokens=token_count_max)

    # if we are using a large doc we'll just use the beginning of the doc to find what we want with the llm calls
    text_for_llm_meta_extraction = beginning_of_doc if using_large_doc else content
    date, docket_number, citation, title, extra_cost_meta = extract_meta_info(
        text, text_for_llm_meta_extraction, model_str, language
    )
    extra_cost += extra_cost_meta

    applicant = title.split("v.")[0].strip()
    respondent = title.split("v.")[1].strip()

    # Extract judge name
    judge_match = re.search(r"JUDGMENT AND REASONS:\s*([\w\s\.]+)DATED:", text)
    if judge_match:
        judge = judge_match.group(1).strip().title()
    else:
        judge_match = re.search(r"PRESENT:\s*The Honourable\s*([\w\s]+)BETWEEN:", text)
        if judge_match:
            judge = judge_match.group(1).strip().title()
        else:
            extraction_word = "judge" if language == "en" else "le juge"
            judge, judge_cost = extract_using_generative(
                extraction_word, text_for_llm_meta_extraction, model_str, language
            )
            extra_cost += judge_cost

    # if we are dealing with an english report lets try extracting the text itself first
    court_judgment_match = re.search(
        r"THIS COURTS JUDGMENT is that\s*((.|\n)*)[^]+\s*Judge", text
    )
    if court_judgment_match and language == "en":
        court_judgment = " ".join(court_judgment_match.groups())
    else:
        text_for_court_judgment_llm_call = end_of_doc if using_large_doc else content
        court_judgment, court_judgment_cost = extract_court_judgment(
            text_for_court_judgment_llm_call, model_str, language
        )

        extra_cost += court_judgment_cost

    def create_facts_and_court_sections():
        question = {
            "en": """Write down two section where the first section showcases the facts of the case, and the second section showcases the findings from the court. In both of these sections, make sure to mention in your answers important sections and subsections of relevant acts or regulations found in the text. For the first section, note that the facts are the who, when, what, where, and why of the case. Hence, describe the history of the applicant, the events that led to the case, the legal claims, and defenses of each party. As for the second section, summarize all the findings made specifically by the court during the trial, in addition to the result of the trial. If the findings did not come specifically from the court, do not mention it in the second section. Since all the findings mentioned in the second section came from the court, they should be written with the phrase "The Court" at the beginning of each sentence, for example "The Court found that...", "The Court noted..." or "The Court preferred...". Write the first section under "Facts:", and the second section under "Court:".""",
            "fr": """crivez deux sections o la premire section prsente les faits de l'affaire et la deuxime section prsente les conclusions du tribunal. Dans ces deux sections, assurez-vous de mentionner dans vos rponses les sections et sous-sections importantes des lois ou rglements pertinents trouvs dans le texte. Pour la premire section, notez que les faits sont le "qui, quand, quoi, o et pourquoi" de l'affaire. Par consquent, dcrivez l'historique du demandeur, les vnements qui ont conduit  l'affaire, les revendications juridiques et les dfenses de chaque partie. Quant  la deuxime section, rsumez toutes les conclusions spcifiquement formules par le tribunal lors du procs, ainsi que le rsultat du procs. Si les conclusions ne proviennent pas spcifiquement du tribunal, ne les mentionnez pas dans la deuxime section. tant donn que toutes les conclusions mentionnes dans la deuxime section proviennent du tribunal, elles doivent tre rdiges avec la phrase "Le tribunal a constat que", "Le tribunal a not" ou "Le tribunal a prfr". crivez la premire section sous "Faits:" et la deuxime section sous "Tribunal:".""",
        }

        facts = client.chat.completions.create(
            model=model_str,  # model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt[language]},
                {"role": "user", "content": "### Content: " + content},
                {"role": "user", "content": "### Question: " + question[language]},
            ],
            temperature=0.1,  # set this to a low value, such as 0.2, to make the output more focused and deterministic. This will reduce the randomness in the generated response
            frequency_penalty=0.0,  # set this to a high positive value, such as 2.0, to penalize the model for repeating the same line verbatim. This will encourage the model to generate more diverse responses.
            presence_penalty=1.8,  # set this to a high positive value, such as 2.0, to penalize the model for introducing new tokens that do not appear in the input text. This will encourage the model to generate responses that are more closely related to the input text.
        )
        return facts

    def create_key_findings(findings):
        question = {
            "en": f"""Give a brief overview of the key finding from the text "{findings}" without going into details. Make sure your response has a length of 30 words or less.""",
            "fr": f"""Donnez un bref aperu des principales conclusions du texte "{findings}" sans entrer dans les dtails. Assurez-vous que votre rponse a une longueur de 30 mots ou moins.""",
        }
        key_findings = client.chat.completions.create(
            model=model_str,  # model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt[language]},
                {"role": "user", "content": "### Question: " + question[language]},
            ],
            temperature=0.1,  # set this to a low value, such as 0.2, to make the output more focused and deterministic. This will reduce the randomness in the generated response
            frequency_penalty=0.0,  # set this to a high positive value, such as 2.0, to penalize the model for repeating the same line verbatim. This will encourage the model to generate more diverse responses.
            presence_penalty=1.8,  # set this to a high positive value, such as 2.0, to penalize the model for introducing new tokens that do not appear in the input text. This will encourage the model to generate responses that are more closely related to the input text.
        )
        return key_findings

    def court_decision():
        question = {
            "en": f"""Classify the text as one of the following categories: Dismissed, Granted, Suspended, Rejected, or None. Simply mention the classification without going into details.""",
            "fr": "Classifiez le texte dans l'une des catgories suivantes : Rejet, Accord, Suspendu, Rejet ou Aucun. Mentionnez simplement la classification sans entrer dans les dtails.",
        }

        decision = client.chat.completions.create(
            model=model_str,  # model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt[language]},
                {"role": "user", "content": "### Content: " + content},
                {"role": "user", "content": "### Question: " + question[language]},
            ],
            temperature=0.1,  # set this to a low value, such as 0.2, to make the output more focused and deterministic. This will reduce the randomness in the generated response
            frequency_penalty=0.0,  # set this to a high positive value, such as 2.0, to penalize the model for repeating the same line verbatim. This will encourage the model to generate more diverse responses.
            presence_penalty=1.8,  # set this to a high positive value, such as 2.0, to penalize the model for introducing new tokens that do not appear in the input text. This will encourage the model to generate responses that are more closely related to the input text.
        )
        return decision

    def find_keywords(findings):
        question = {
            "en": """Based on the findings, find multiple keywords of a total of around 5 to describe the case. Those keywords should have an emphasis on the type of application being challenged and what the applicant is seeking. Make sure your reply follows the format "keyword 1, keyword 2, ..., keyword 5". Make sure there's more than one keyword and don't include the court decision in the keyword. Do not reply anything else that doesn't follow this format""",
            "fr": """En fonction des rsultats, trouvez plusieurs mots-cls d'un total d'environ 5 pour dcrire le cas. Ces mots-cls devraient mettre l'accent sur le type d'application conteste et ce que le demandeur recherche. Assurez-vous que votre rponse suit le format "mot-cl 1, mot-cl 2, ..., mot-cl 5". Assurez-vous qu'il y ait plus d'un mot-cl et n'incluez pas la dcision de la cour dans le mot-cl. Ne rpondez rien d'autre qui ne suit pas ce format.""",
        }
        keywords = client.chat.completions.create(
            model=model_str,  # model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt[language]},
                {"role": "user", "content": "### Content: " + content},
                {"role": "user", "content": "### Question: " + question[language]},
                {"role": "user", "content": "### Findings: " + findings},
            ],
            temperature=0.1,  # set this to a low value, such as 0.2, to make the output more focused and deterministic. This will reduce the randomness in the generated response
            frequency_penalty=0.0,  # set this to a high positive value, such as 2.0, to penalize the model for repeating the same line verbatim. This will encourage the model to generate more diverse responses.
            presence_penalty=1.8,  # set this to a high positive value, such as 2.0, to penalize the model for introducing new tokens that do not appear in the input text. This will encourage the model to generate responses that are more closely related to the input text.
        )
        return keywords

    # CURRENTLY NOT IN USE
    def find_question_certification():
        question = {
            "en": f'Check to see if the applicant has proposed a question for certification. If yes, write down the question proposed and the outcome. If no, write down "The AI model was not able to find any proposed question for certification."',
            "fr": "Vrifiez si le demandeur a propos une question pour la certification. Si oui, notez la question propose et le rsultat. Si non, notez \"Le modle d'IA n'a pas pu trouver de question propose pour la certification.\"",
        }

        question_cert = client.chat.completions.create(
            model=model_str,  # model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt[language]},
                {"role": "user", "content": "### Content: " + content},
                {"role": "user", "content": "### Question: " + question[language]},
            ],
            temperature=0.1,  # set this to a low value, such as 0.2, to make the output more focused and deterministic. This will reduce the randomness in the generated response
            frequency_penalty=0.0,  # set this to a high positive value, such as 2.0, to penalize the model for repeating the same line verbatim. This will encourage the model to generate more diverse responses.
            presence_penalty=1.8,  # set this to a high positive value, such as 2.0, to penalize the model for introducing new tokens that do not appear in the input text. This will encourage the model to generate responses that are more closely related to the input text.
        )
        return question_cert

    # CURRENTLY NOT IN USE
    def find_test():
        question = {
            "en": 'If the application included any legal test, list out the full test and outcome of it. If no, simply write "The AI model was not able to find legal tests in this document".',
            "fr": "Si l'application incluait un test juridique, numrez le test complet et son rsultat. Sinon, crivez simplement \"Le modle d'IA n'a pas pu trouver de tests juridiques dans ce document\".",
        }

        test = client.chat.completions.create(
            model=model_str,  # model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt[language]},
                {"role": "user", "content": "### Content: " + content},
                {"role": "user", "content": "### Question: " + question[language]},
            ],
            temperature=0.1,  # set this to a low value, such as 0.2, to make the output more focused and deterministic. This will reduce the randomness in the generated response
            frequency_penalty=0.0,  # set this to a high positive value, such as 2.0, to penalize the model for repeating the same line verbatim. This will encourage the model to generate more diverse responses.
            presence_penalty=1.8,  # set this to a high positive value, such as 2.0, to penalize the model for introducing new tokens that do not appear in the input text. This will encourage the model to generate responses that are more closely related to the input text.
        )
        return test

    # now run the functions in parallel
    with concurrent.futures.ThreadPoolExecutor() as executor:
        future1 = executor.submit(create_facts_and_court_sections)
        future2 = executor.submit(court_decision)
        # TODO decide wether or not we want to keep the 'Test' and 'Question for Certerfication' part of the report
        # future3 = executor.submit(find_question_certification)
        # future4 = executor.submit(find_test)

        facts = future1.result()
        decision = future2.result()
        # question_cert = future3.result()
        # test = future4.result()

    result_text = facts.choices[0].message.content
    sections = ["Facts", "Court"] if language == "en" else ["Faits", "Tribunal"]
    extract_sections_data = extract_sections(result_text, sections=sections)
    facts_text = extract_sections_data[sections[0]]
    findings_text = extract_sections_data[sections[1]]
    decision_text = decision.choices[0].message.content
    # question_cert_text = question_cert.choices[0].message.content
    # test_text = test.choices[0].message.content

    with concurrent.futures.ThreadPoolExecutor() as executor:
        future5 = executor.submit(create_key_findings, findings_text)
        future6 = executor.submit(find_keywords, findings_text)

        key_findings = future5.result()
        keywords = future6.result()

    key_findings_text = key_findings.choices[0].message.content
    keywords_text = keywords.choices[0].message.content

    tokens_consumed = (
        (facts.usage.total_tokens)
        + key_findings.usage.total_tokens
        + decision.usage.total_tokens
        + keywords.usage.total_tokens
        + extra_cost
    )
    estimated_cost = (
        math.ceil(tokens_consumed * settings.OPENAI_COST_PER_TOKEN * 10000) / 10000
    )

    context = {
        "date": date,
        "docket_number": docket_number.replace("\n", " ").strip(),
        "citation": citation,
        "applicant": applicant,
        "respondant": respondent,
        "title": title,
        "judge": judge,
        "estimated_cost": estimated_cost,
        "Facts": facts_text,
        "Court": findings_text,
        "Key_Findings": key_findings_text,
        "Keywords": keywords_text,
        "decision": decision_text,
        # "Question_Certification": question_cert_text,
        # "Test": test_text,
        "Court_Judgment": court_judgment,
    }

    # # pass each text value of context in the acronym replacement function
    for key in context:
        if isinstance(context[key], str):  # Ensure the value is a string
            context[key] = replace_with_acronyms(context[key], acronym_dict)

    # Define the template file and output file paths
    template_path = os.path.join(
        settings.BASE_DIR,
        "template_wizard",
        "templates",
        "template_wizard",
        "canlii_wizard",
        f"immigration_case_report_{language}.docx",
    )

    # Load the template file
    tpl = DocxTemplate(template_path)

    # # Render the template and save the output to the temporary file
    tpl.render(context)

    # Save the updated document
    file_content = io.BytesIO()
    tpl.save(file_content)

    # Move the "cursor" to the beginning of the buffer
    file_content.seek(0)

    return file_content, citation


def generate_atip_case_report(text, language):

    extra_cost = 0
    using_large_doc = False

    enc = tiktoken.get_encoding("cl100k_base")

    # Count how many characters are in the text
    token_count = len(enc.encode(text))

    # TODO: Change this to gpt-4 once we figure out how to deal with the gpt-4 delay errors
    token_count_max = 15000
    if token_count < token_count_max:
        content = text

    else:
        content = map_reduce(text, language, model_str)
        using_large_doc = True

    beginning_of_doc, end_of_doc = trim_to_tokens(text, max_tokens=token_count_max)

    # if we are using a large doc we'll just use the beginning of the doc to find what we want with the llm calls
    text_for_llm_meta_extraction = beginning_of_doc if using_large_doc else content
    decision_date, docket_number, citation, title, extra_cost_meta = extract_meta_info(
        text, text_for_llm_meta_extraction, model_str, language
    )
    extra_cost += extra_cost_meta

    # Extract judges name
    question = {
        "en": """Find all judges who worked on this case. This will usually be found in the sections "REASONS FOR JUDGMENT BY" and "CONCURRED IN BY". For your reply, simply output each name seperated by a comma. Don't write anything else.""",
        "fr": """Trouvez tous les juges qui ont travaill sur cette affaire. Cela se trouve gnralement dans les sections "JUGEMENT ET MOTIFS PUBLIC" ou "MOTIFS DU JUGEMENT", et "PRONONCS  LAUDIENCE". Pour votre rponse, veuillez simplement afficher chaque nom spar par une virgule. N'crivez rien d'autre.""",
    }
    # use this end of the document if using a large document
    text_for_judge_extraction_llm_call = end_of_doc if using_large_doc else content
    extraction = client.chat.completions.create(
        model=model_str,
        messages=[
            {"role": "system", "content": system_prompt[language]},
            {
                "role": "user",
                "content": "### Content: " + text_for_judge_extraction_llm_call,
            },
            {"role": "user", "content": "### Question: " + question[language]},
        ],
        temperature=0.1,
        frequency_penalty=0.0,
        presence_penalty=1.8,
    )
    present = extraction.choices[0].message.content
    # extra_cost += extraction.usage.total_tokens

    def high_level_summary():
        question = {
            "en": "Using plain language, write a brief and high-level summary of the case in 1 or 2 sentences.",
            "fr": "En utilisant un langage simple, rdigez un rsum bref et de haut niveau du cas en 1 ou 2 phrases.",
        }

        response = client.chat.completions.create(
            model=model_str,
            messages=[
                {"role": "system", "content": system_prompt[language]},
                {"role": "user", "content": "### Content:" + content},
                {
                    "role": "user",
                    "content": "### Question:" + question[language],
                },
            ],
            temperature=0.1,
            frequency_penalty=0.0,
            presence_penalty=1.8,
        )

        return response

    def summarize_legal_facts():
        question = {
            "en": "Summarize the legal facts in the case, as described in the provided text. Do not include the issues. I'll ask that later.",
            "fr": "Rsumez les faits juridiques de l'affaire, tels qu'ils sont dcrits dans le texte fourni. N'incluez pas les problmes juridiques. Je les demanderai plus tard.",
        }

        response = client.chat.completions.create(
            model=model_str,
            messages=[
                {"role": "system", "content": system_prompt[language]},
                {"role": "user", "content": "### Content" + content},
                {
                    "role": "user",
                    "content": "### Question" + question[language],
                },
            ],
            temperature=0.1,
            frequency_penalty=0.0,
            presence_penalty=1.8,
        )

        return response

    def legal_issues_list():
        question = {
            "en": "List the legal issues in the case, as described in the provided text. Do not include anything else. I'll ask that later.",
            "fr": "numrez les problmes juridiques dans l'affaire, tels que dcrits dans le texte fourni. Ne mentionnez rien d'autre. Je demanderai cela plus tard.",
        }

        response = client.chat.completions.create(
            model=model_str,
            messages=[
                {"role": "system", "content": system_prompt[language]},
                {"role": "user", "content": "### Content" + content},
                {
                    "role": "user",
                    "content": "### Question" + question[language],
                },
            ],
            temperature=0.1,
            frequency_penalty=0.0,
            presence_penalty=1.8,
        )

        return response

    def decision_of_case():

        question = {
            "en": "Summarize the decision of the case in 60 words or less. Do not include the reasons for the decision. I'll ask that later.",
            "fr": "Rsumez la dcision de l'affaire en 60 mots ou moins. N'incluez pas les raisons de la dcision. Je vous demanderai cela plus tard.",
        }

        response = client.chat.completions.create(
            model=model_str,
            messages=[
                {"role": "system", "content": system_prompt[language]},
                {"role": "user", "content": "### Content" + content},
                {
                    "role": "user",
                    "content": "### Question" + question[language],
                },
            ],
            temperature=0.1,
            frequency_penalty=0.0,
            presence_penalty=1.8,
        )

        return response

    def reason_of_decision():

        question = {
            "en": "Summarize the reasons for the decision in the case. Do not include the decision itself. I'll ask that later.",
            "fr": "Rsumez les raisons de la dcision dans l'affaire. N'incluez pas la dcision elle-mme. Je la demanderai plus tard.",
        }

        response = client.chat.completions.create(
            model=model_str,
            messages=[
                {"role": "system", "content": system_prompt[language]},
                {"role": "user", "content": "### Content" + content},
                {
                    "role": "user",
                    "content": "### Question" + question[language],
                },
            ],
            temperature=0.1,
            frequency_penalty=0.0,
            presence_penalty=1.8,
        )

        return response

    def find_PA():
        question = {
            "en": "Find the specific provisions of the Privacy Act or the PA discussed in the legal document. Provide the response in a list format. If none are found, just answer 'Not found' and don't write anything else.",
            "fr": """Trouvez les dispositions spcifiques de la Loi sur la protection des renseignements personnels ou de la LP mentionnes dans le document juridique. Fournissez la rponse sous forme de liste. Si aucune n'est trouve, rpondez simplement "Non trouv" et n'crivez rien d'autre.""",
        }

        response = client.chat.completions.create(
            model=model_str,
            messages=[
                {"role": "system", "content": system_prompt[language]},
                {"role": "user", "content": "### Content" + content},
                {
                    "role": "user",
                    "content": "### Question" + question[language],
                },
            ],
            temperature=0.1,
            frequency_penalty=0.0,
            presence_penalty=1.8,
        )

        return response

    def find_ATIA():
        question = {
            "en": "Find the specific provisions of the Access to Information Act or the ATIA discussed in the provided legal document. Provide the response in a list format. If none are found, just answer 'Not found' and don't write anything else.",
            "fr": """Trouvez les dispositions spcifiques de la Loi sur l'accs  l'information ou la LAI discutes dans le document juridique fourni. Fournissez la rponse sous forme de liste. Si aucune n'est trouve, rpondez simplement "Non trouv" et n'crivez rien d'autre.""",
        }

        response = client.chat.completions.create(
            model=model_str,
            messages=[
                {"role": "system", "content": system_prompt[language]},
                {"role": "user", "content": "### Content:" + content},
                {
                    "role": "user",
                    "content": "### Question:" + question[language],
                },
            ],
            temperature=0.1,
            frequency_penalty=0.0,
            presence_penalty=1.8,
        )

        return response

    # now run the functions in parallel
    with concurrent.futures.ThreadPoolExecutor() as executor:
        future1 = executor.submit(high_level_summary)
        future2 = executor.submit(summarize_legal_facts)
        future3 = executor.submit(legal_issues_list)
        future4 = executor.submit(decision_of_case)
        future5 = executor.submit(reason_of_decision)
        future6 = executor.submit(find_PA)
        future7 = executor.submit(find_ATIA)

        summary_response = future1.result()
        facts_response = future2.result()
        issues_response = future3.result()
        decision_response = future4.result()
        reasons_response = future5.result()
        privacy_provisions_response = future6.result()
        access_to_info_provisions_response = future7.result()

    summary = summary_response.choices[0].message.content
    facts = facts_response.choices[0].message.content
    issues = issues_response.choices[0].message.content
    decision = decision_response.choices[0].message.content
    reasons = reasons_response.choices[0].message.content
    privacy_provisions = privacy_provisions_response.choices[0].message.content
    access_to_info_provisions = access_to_info_provisions_response.choices[
        0
    ].message.content

    tokens_consumed = (
        (summary_response.usage.total_tokens)
        + (facts_response.usage.total_tokens)
        + (issues_response.usage.total_tokens)
        + (decision_response.usage.total_tokens)
        + (reasons_response.usage.total_tokens)
        + (privacy_provisions_response.usage.total_tokens)
        + (access_to_info_provisions_response.usage.total_tokens)
        + extra_cost
    )
    estimated_cost = (
        math.ceil((tokens_consumed) * settings.OPENAI_COST_PER_TOKEN * 10000) / 10000
    )

    context = {
        "title": title.replace("\n", " ").strip(),
        "citation": citation.replace("\n", " ").strip(),
        "decision_date": decision_date.replace("\n", " ").strip(),
        "docket_number": docket_number.replace("\n", " ").strip(),
        "privacy_provisions": markdown.markdown(privacy_provisions),
        "access_to_info_provisions": markdown.markdown(access_to_info_provisions),
        "summary": markdown.markdown(summary),
        "facts": markdown.markdown(facts),
        "issues": markdown.markdown(issues),
        "decision": markdown.markdown(decision),
        "reasons": markdown.markdown(reasons),
        "present": present.replace("\n", " ").strip(),
        "estimated_cost": estimated_cost,
    }

    # Define the template file and output file paths
    template_path = os.path.join(
        settings.BASE_DIR,
        "template_wizard",
        "templates",
        "template_wizard",
        "canlii_wizard",
        f"atip_case_report_{language}.docx",
    )

    # Load the template file
    tpl = DocxTemplate(template_path)

    # Make a copy of the context dictionary and prep the html content for docx insertion
    from html2docx import html2docx

    context_copy = context.copy()
    # context_copy["source_url"] = url
    context_copy["privacy_provisions"] = tpl.new_subdoc(
        html2docx(context["privacy_provisions"], title="")
    )
    context_copy["access_to_info_provisions"] = tpl.new_subdoc(
        html2docx(context["access_to_info_provisions"], title="")
    )
    context_copy["summary"] = tpl.new_subdoc(html2docx(context["summary"], title=""))
    context_copy["facts"] = tpl.new_subdoc(html2docx(context["facts"], title=""))
    context_copy["issues"] = tpl.new_subdoc(html2docx(context["issues"], title=""))
    context_copy["decision"] = tpl.new_subdoc(html2docx(context["decision"], title=""))
    context_copy["reasons"] = tpl.new_subdoc(html2docx(context["reasons"], title=""))

    # Render the template and save the output to a new file
    tpl.render(context_copy)
    file_content = io.BytesIO()
    tpl.save(file_content)

    # Move the "cursor" to the beginning of the buffer
    file_content.seek(0)

    return file_content, citation


def generate_general_case_report(text, language):

    extra_cost = 0
    using_large_doc = False

    enc = tiktoken.get_encoding("cl100k_base")

    # Count how many characters are in the text
    token_count = len(enc.encode(text))

    # TODO: Change this to gpt-4 once we figure out how to deal with the gpt-4 delay errors
    token_count_max = 15000
    if token_count < token_count_max:
        content = text

    else:
        content = map_reduce(text, language, model_str)
        using_large_doc = True

    beginning_of_doc, end_of_doc = trim_to_tokens(text, max_tokens=token_count_max)

    # if we are using a large doc we'll just use the beginning of the doc to find what we want with the llm calls
    text_for_llm_meta_extraction = beginning_of_doc if using_large_doc else content
    decision_date, docket_number, citation, title, extra_cost_meta = extract_meta_info(
        text, text_for_llm_meta_extraction, model_str, language
    )
    extra_cost += extra_cost_meta

    # function to find keywords
    def find_keywords():
        question = {
            "en": """Find multiple keywords of a total of around 5 to describe the case. Those keywords should have an emphasis on the type of application being challenged and what the applicant is seeking. Make sure your reply follows the format "keyword 1, keyword 2, ..., keyword 5". Make sure there's more than one keyword and don't include the court decision in the keyword. Do not reply anything else that doesn't follow this format""",
            "fr": """Trouvez plusieurs mots-cls d'un total d'environ 5 pour dcrire le cas. Ces mots-cls devraient mettre l'accent sur le type d'application conteste et ce que le demandeur recherche. Assurez-vous que votre rponse suit le format "mot-cl 1, mot-cl 2, ..., mot-cl 5". Assurez-vous qu'il y ait plus d'un mot-cl et n'incluez pas la dcision de la cour dans le mot-cl. Ne rpondez rien d'autre qui ne suit pas ce format.""",
        }
        keywords = client.chat.completions.create(
            model=model_str,
            messages=[
                {"role": "system", "content": system_prompt[language]},
                {"role": "user", "content": "### Content: " + content},
                {"role": "user", "content": "### Question: " + question[language]},
            ],
            temperature=0.1,  # set this to a low value, such as 0.2, to make the output more focused and deterministic. This will reduce the randomness in the generated response
            frequency_penalty=0.0,  # set this to a high positive value, such as 2.0, to penalize the model for repeating the same line verbatim. This will encourage the model to generate more diverse responses.
            presence_penalty=1.8,  # set this to a high positive value, such as 2.0, to penalize the model for introducing new tokens that do not appear in the input text. This will encourage the model to generate responses that are more closely related to the input text.
        )
        return keywords

    # function to find cited legislation
    def find_cited_legislation():
        question = {
            "en": "Find all the legislation cited in the text. Provide the response in a list format. If none are found, just answer 'Not found' and don't write anything else.",
            "fr": "Trouvez toute la lgislation cite dans le texte. Fournissez la rponse sous forme d'une liste. Si aucune n'est trouve, rpondez simplement 'Non trouv' et n'crivez rien d'autre.",
        }
        response = client.chat.completions.create(
            model=model_str,
            messages=[
                {"role": "system", "content": system_prompt[language]},
                {"role": "user", "content": "### Content: " + content},
                {"role": "user", "content": "### Question: " + question[language]},
            ],
            temperature=0.1,
            frequency_penalty=0.0,
            presence_penalty=1.8,
        )
        return response

    # function to find facts and background of the case
    def find_facts_and_background():
        question = {
            "en": """Write down the facts and background of the case, and make sure to mention in your answers important sections and subsections of relevant acts or regulations found in the text. Note that the facts are the who, when, what, where, and why of the case. Hence, describe the history of the applicant, the events that led to the case, the legal claims, and defenses of each party. This section will all be written under 'Facts and Background:'. You will then write a second section which will present all key findings of the text. This second section will be under 'Key Findings:'.""",
            "fr": """crivez les faits et l'historique de l'affaire, et assurez-vous de mentionner dans vos rponses les sections et sous-sections importantes des lois ou rglements pertinents trouvs dans le texte. Notez que les faits sont le "qui, quand, quoi, o et pourquoi" de l'affaire. Dcrivez donc l'historique du demandeur, les vnements qui ont conduit  l'affaire, les revendications juridiques et les dfenses de chaque partie. Cette section sera entirement rdige sous 'Faits:'. Vous crirez ensuite une deuxime section qui prsentera toutes les conclusions cls du texte. Cette deuxime section sera sous 'Conclusions cls:'.""",
        }

        response = client.chat.completions.create(
            model=model_str,
            messages=[
                {"role": "system", "content": system_prompt[language]},
                {"role": "user", "content": "### Content: " + content},
                {"role": "user", "content": "### Question: " + question[language]},
            ],
            temperature=0.1,
            frequency_penalty=0.0,
            presence_penalty=1.8,
        )
        return response

    # function to generate summary of the case
    def generate_summary():
        question = {
            "en": "Write a brief summary of the case in 1 or 2 sentences.",
            "fr": "Rdigez un bref rsum de l'affaire en 1 ou 2 phrases.",
        }

        response = client.chat.completions.create(
            model=model_str,
            messages=[
                {"role": "system", "content": system_prompt[language]},
                {"role": "user", "content": "### Content: " + content},
                {"role": "user", "content": "### Question: " + question[language]},
            ],
            temperature=0.1,
            frequency_penalty=0.0,
            presence_penalty=1.8,
        )
        return response

    # function to find legal issues of the case
    def find_legal_issues():
        question = {
            "en": "List the legal issues in the case.",
            "fr": "numrez les questions juridiques de l'affaire.",
        }

        response = client.chat.completions.create(
            model=model_str,
            messages=[
                {"role": "system", "content": system_prompt[language]},
                {"role": "user", "content": "### Content: " + content},
                {"role": "user", "content": "### Question: " + question[language]},
            ],
            temperature=0.1,
            frequency_penalty=0.0,
            presence_penalty=1.8,
        )
        return response

    # now run the functions in parallel
    with concurrent.futures.ThreadPoolExecutor() as executor:
        future1 = executor.submit(find_keywords)
        future2 = executor.submit(find_cited_legislation)
        future3 = executor.submit(find_facts_and_background)
        future4 = executor.submit(generate_summary)
        future5 = executor.submit(find_legal_issues)

        keywords = future1.result()
        cited_legislation = future2.result()
        facts_findings = future3.result()
        summary = future4.result()
        legal_issues = future5.result()

    keywords_text = keywords.choices[0].message.content
    cited_legislation_text = cited_legislation.choices[0].message.content
    summary_text = summary.choices[0].message.content
    legal_issues_text = legal_issues.choices[0].message.content
    facts_findings_text = facts_findings.choices[0].message.content

    sections = (
        ["Facts and Background", "Key Findings"]
        if language == "en"
        else ["Faits", "Conclusions cls"]
    )
    extract_sections_data = extract_sections(facts_findings_text, sections=sections)
    facts_background_text = extract_sections_data[sections[0]]
    key_findings_text = extract_sections_data[sections[1]]

    tokens_consumed = (
        (keywords.usage.total_tokens)
        + (cited_legislation.usage.total_tokens)
        + (facts_findings.usage.total_tokens)
        + (summary.usage.total_tokens)
        + (legal_issues.usage.total_tokens)
        + extra_cost
    )

    estimated_cost = (
        math.ceil((tokens_consumed) * settings.OPENAI_COST_PER_TOKEN * 10000) / 10000
    )

    context = {
        "title": title.replace("\n", " ").strip(),
        "citation": citation.replace("\n", " ").strip(),
        "decision_date": decision_date.replace("\n", " ").strip(),
        "docket_number": docket_number.replace("\n", " ").strip(),
        "keywords": keywords_text,
        "cited_legislation": cited_legislation_text,
        "facts_background": facts_background_text,
        "summary": summary_text,
        "legal_issues": legal_issues_text,
        "key_findings": key_findings_text,
        "estimated_cost": estimated_cost,
    }

    # Define the template file and output file paths
    template_path = os.path.join(
        settings.BASE_DIR,
        "template_wizard",
        "templates",
        "template_wizard",
        "canlii_wizard",
        f"general_report_{language}.docx",
    )

    # Load the template file
    tpl = DocxTemplate(template_path)

    # Make a copy of the context dictionary and prep the html content for docx insertion
    from html2docx import html2docx

    context_copy = context.copy()
    # context_copy["source_url"] = url
    context_copy["keywords"] = tpl.new_subdoc(html2docx(context["keywords"], title=""))
    context_copy["cited_legislation"] = tpl.new_subdoc(
        html2docx(context["cited_legislation"], title="")
    )
    context_copy["facts_background"] = tpl.new_subdoc(
        html2docx(context["facts_background"], title="")
    )
    context_copy["summary"] = tpl.new_subdoc(html2docx(context["summary"], title=""))
    context_copy["legal_issues"] = tpl.new_subdoc(
        html2docx(context["legal_issues"], title="")
    )
    context_copy["key_findings"] = tpl.new_subdoc(
        html2docx(context["key_findings"], title="")
    )

    # Render the template and save the output to a new file
    tpl.render(context_copy)
    file_content = io.BytesIO()
    tpl.save(file_content)

    # Move the "cursor" to the beginning of the buffer
    file_content.seek(0)

    return file_content, citation



=== Contents of django\template_wizard\wizards\canlii_wizard\views.py ===
import os
import uuid

from django.conf import settings
from django.core.files.base import ContentFile
from django.core.files.storage import default_storage
from django.http import HttpResponse, HttpResponseNotAllowed, JsonResponse
from django.template.loader import render_to_string
from django.utils import timezone

import requests
from bs4 import BeautifulSoup

from otto.secure_models import AccessKey
from otto.utils.common import file_size_to_string
from template_wizard.models import Report

from .utils import (
    convert_to_text,
    generate_atip_case_report,
    generate_general_case_report,
    generate_immigration_case_report,
)

TEMPLATE_CHOICES = {
    "general_case_report_en": {
        "title": "General case report",
        "template_file": "general_case_report_en.docx",
        "output_file": "General_Case_Report_%TIMESTAMP%.docx",
    },
    "atip_case_report_en": {
        "title": "ATIP case report",
        "template_file": "atip_case_report_en.docx",
        "output_file": "ATIP_Case_Report_%TIMESTAMP%.docx",
    },
    "immigration_case_report_en": {
        "title": "Immigration case report",
        "template_file": "immigration_case_report_en.docx",
        "output_file": "Immigration_Case_Report_%TIMESTAMP%.docx",
    },
}


def sanitize_filename(filename):
    """
    A simple function to remove or replace potentially problematic characters
    from filenames. Expand this function based on your requirements.
    """
    return filename.replace(" ", "_").replace("%", "_")


def add_report_data(request, report_id):
    import os
    from urllib.parse import unquote

    access_key = AccessKey(bypass=True)

    report = Report.objects.get(access_key, id=report_id)  # More robust error handling

    report_data = report.data if report.data else {}

    data_source = request.POST.get("data_source")
    data_items = report_data.get("submitted_documents", [])

    if data_source == "canlii":
        url_input = request.POST.get("url_input")
        if url_input:
            data_items.append({"type": "url", "value": url_input, "name": url_input})
    elif data_source == "file":
        files = request.FILES.getlist("file_upload")
        for file in files:
            # Sanitize and decode the file name
            sanitized_filename = sanitize_filename(file.name)
            decoded_filename = unquote(
                sanitized_filename
            )  # Decode URL-encoded characters

            # Construct a safe, relative file path
            file_path = os.path.join("uploads", str(report_id), decoded_filename)

            # Save the file using Django's storage system
            saved_path = default_storage.save(file_path, ContentFile(file.read()))

            data_items.append(
                {
                    "type": "file",
                    "value": saved_path,
                    "name": file.name,
                    "content_type": file.content_type,
                    "generated_report": False,
                    "index": "0",
                }
            )
    report.data = {}
    report.data["submitted_documents"] = data_items
    report.save(access_key)

    return JsonResponse({"message": "Report data updated successfully."})


def select_data(request, report):
    selected_cases_count = (
        len(report.data.get("selected_cases", [])) if report.data else 0
    )
    return {
        "selected_cases_count": selected_cases_count,
    }


def delete_report_data_item(request, report_id, item_index):
    report = Report.objects.get(id=report_id)
    if report.data and 0 <= item_index < len(report.data):
        del report.data[item_index]
        report.save()
    # Redirect back to the page where the user can see the updated list of items
    return JsonResponse({"message": "Report data updated successfully."})


# def handle_immigration_data(request):

#     # Call your sum_bcro_report function with the request
#     file_path = sum_bcro_report(request)
#     # Assuming response_data contains the path to the generated .docx file
#     file_url = default_storage.url(file_path)
#     return JsonResponse({"success": True, "file_url": file_url})


def generate_report(request, report_id):

    template_key = request.POST.get("template_key")
    language_dropdown = request.POST.get("language_select")
    languages_selected = (
        ["en", "fr"] if language_dropdown == "both" else [language_dropdown]
    )

    access_key = AccessKey(user=request.user)
    report = Report.objects.get(access_key, id=report_id)

    # Generate the report content for each submitted document in desired languages
    for case in report.data["submitted_documents"]:
        for language in languages_selected:
            generated_report = _generate_report_content(case, template_key, language)
            report.data["generated_reports"].append(generated_report)

    report.save(access_key)

    html_content = render_to_string(
        "template_wizard/canlii_wizard/generated_reports_results.html",
        {
            "report": report,
        },
    )

    return HttpResponse(html_content)


def _generate_report_content(case, template_key, language):

    template = TEMPLATE_CHOICES.get(template_key)

    generated_report_id = str(uuid.uuid4())

    # Get the current date
    current_date = timezone.now()

    # Generate UUID for the filename
    output_file = template["output_file"].replace(
        "%TIMESTAMP%", current_date.strftime("%Y%m%d_%H%M%S")
    )

    title = template["title"] + " " + current_date.strftime("%Y-%m-%d")

    # Define the directory path
    directory = os.path.join(
        settings.MEDIA_ROOT,
        "generated_reports",
        str(current_date.year),
        str(current_date.month),
        str(current_date.day),
    )

    # Create the directory if it doesn't exist
    if not os.path.exists(directory):
        os.makedirs(directory)

    if case["type"] == "file":
        with default_storage.open(case["value"], "rb") as file:
            text = convert_to_text(file, content_type=case["content_type"])
    elif case["type"] == "url":
        html = requests.get(case["value"]).content
        soup = BeautifulSoup(html, "html.parser")
        text = soup.find(id="originalDocument").text

    # Generate the report content as io.BytesIO
    if template_key == "immigration_case_report_en":
        report_content, citation = generate_immigration_case_report(text, language)
    elif template_key == "atip_case_report_en":
        report_content, citation = generate_atip_case_report(text, language)
    elif template_key == "general_case_report_en":
        report_content, citation = generate_general_case_report(text, language)

    title = f"{title} - {citation} - {language}"

    # Define the file path
    file_path = os.path.join(directory, generated_report_id)

    # Write content to the file
    with open(file_path, "wb") as file:
        file.write(report_content.getvalue())

    return {
        "id": generated_report_id,
        "template_key": template_key,
        "title": title,
        "file_path": file_path,
        "output_file": output_file,
        "size": file_size_to_string(os.path.getsize(file_path)),
    }


def download_generated_report(request, report_id, generated_report_id):

    access_key = AccessKey(user=request.user)
    report = Report.objects.get(access_key, id=report_id)

    # Get the generated report data
    generated_reports = report.data.get("generated_reports", [])

    # Find the generated report data by generated_report_id
    generated_report = next(
        (item for item in generated_reports if item["id"] == generated_report_id), None
    )

    if not generated_report:
        return HttpResponseNotAllowed("Invalid generated report ID")

    # Get the file path
    file_path = generated_report["file_path"]

    # Read the file content
    with open(file_path, "rb") as file:
        file_content = file.read()

    # Get the filename
    output_file = generated_report["output_file"]

    # Prepare the response
    response = HttpResponse(file_content, content_type="application/octet-stream")
    response["Content-Disposition"] = f'attachment; filename="{output_file}"'

    return response


def delete_generated_report(request, report_id, generated_report_id):

    access_key = AccessKey(user=request.user)
    report = Report.objects.get(access_key, id=report_id)

    # Get the generated report data
    generated_reports = report.data.get("generated_reports", [])

    # Find the generated report data by output_file
    generated_report = next(
        (item for item in generated_reports if item["id"] == generated_report_id), None
    )

    if not generated_report:
        return HttpResponseNotAllowed("Invalid")

    # Delete the file
    try:
        os.remove(generated_report["file_path"])
    except:
        pass

    # Remove the generated report data from the report's data
    report.data["generated_reports"] = [
        item for item in generated_reports if item["id"] != generated_report_id
    ]
    report.save(access_key)

    html_content = render_to_string(
        "template_wizard/canlii_wizard/generated_reports_results.html",
        {
            "report": report,
        },
    )

    return HttpResponse(html_content)


def pick_template(request, report):

    access_key = AccessKey(user=request.user)

    if not report.data:
        report.data = {}

    report.data.setdefault("generated_reports", [])
    report.save(access_key)

    return {"templates": TEMPLATE_CHOICES}



=== Contents of django\tests\__init__.py ===



=== Contents of django\tests\conftest.py ===
import os
from datetime import datetime
from unittest.mock import MagicMock

from django.contrib.auth.models import Group
from django.core.management import call_command

import pytest
import pytest_asyncio
from asgiref.sync import sync_to_async
from PIL import Image
from reportlab.pdfgen import canvas

pytest_plugins = ("pytest_asyncio",)


@pytest_asyncio.fixture(scope="session")
async def django_db_setup(django_db_setup, django_db_blocker):
    def _inner():
        with django_db_blocker.unblock():
            call_command(
                "reset_app_data",
                "groups",
                "apps",
                "terms",
                "security_labels",
                "library_mini",
                "cost_types",
            )
            from django.conf import settings

            if not settings.IS_RUNNING_IN_GITHUB:
                call_command("load_corporate_library")

    return await sync_to_async(_inner)()


@pytest.fixture()
def all_apps_user(db, django_user_model):
    def new_user(username="all_apps_user"):
        user = django_user_model.objects.create_user(
            upn=f"{username}_upn",
            oid=f"{username}_oid",
            email=f"{username}@example.com",
        )
        user.groups.add(Group.objects.get(name="Otto admin"))
        # Accept the terms
        user.accepted_terms_date = datetime.now()
        user.save()
        return user

    return new_user


@pytest.fixture()
def basic_user(db, django_user_model):
    def new_user(username="basic_user", accept_terms=False):
        user = django_user_model.objects.create_user(
            upn=f"{username}_upn",
            oid=f"{username}_oid",
            email=f"{username}@example.com",
            accepted_terms_date=datetime.now() if accept_terms else None,
        )
        return user

    return new_user


@pytest.fixture
def mock_pdf_file():
    filename = "temp_file1.pdf"
    c = canvas.Canvas(filename)
    for i in range(3):  # Create 3 pages
        c.drawString(100, 100, f"Page {i+1}")
        c.showPage()
    c.save()

    # Open the file in binary read mode and return the file object
    with open(filename, "rb") as f:
        yield f
    os.remove(filename)


@pytest.fixture
def mock_pdf_file2():
    filename = "temp_file2.pdf"
    c = canvas.Canvas(filename)
    for i in range(10):  # Create 3 pages
        c.drawString(100, 100, f"Page {i+1}")
        c.showPage()
    c.save()

    # Open the file in binary read mode and return the file object
    with open(filename, "rb") as f:
        yield f
    os.remove(filename)


@pytest.fixture
def mock_image_file(filename="temp_image.jpg"):
    mock_file = MagicMock()
    mock_file.name = filename
    yield mock_file


@pytest.fixture
def mock_image_file2():
    img = Image.new("RGB", (1000, 500), "white")
    return img


@pytest.fixture
def mock_unsupported_file():
    mock_file = MagicMock()
    mock_file.name = "temp_unsupported.txt"
    yield mock_file


# Mocking file objects with a .name attribute
class MockFile:
    def __init__(self, name, total_page_num):
        self.name = name



=== Contents of django\tests\settings.py ===



=== Contents of django\tests\case_prep\test_case_prep.py ===
import json
import uuid

from django.core.files.base import ContentFile
from django.urls import reverse
from django.utils import timezone

import pytest

from case_prep.models import Document, Session
from otto.secure_models import AccessKey

pytestmark = pytest.mark.django_db


def test_session(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)

    response = client.get(reverse("case_prep:index"))
    assert response.status_code == 200
    assert "sessions" in response.context

    response = client.post(reverse("case_prep:create_session"))
    assert response.status_code == 302  # Should redirect to session_detail
    session = Session.objects.all(AccessKey(user=user)).latest("created_at")
    assert session.created_by == user

    response = client.get(reverse("case_prep:session_detail", args=[session.id]))
    assert response.status_code == 200
    assert "session" in response.context
    assert response.context["session"].id == session.id

    # Mocking a file upload
    file_content = ContentFile(b"Sample content", "sample.txt")
    file_content.content_type = "text/plain"

    response = client.post(
        reverse("case_prep:upload_files"),
        {
            "session_id": session.id,
            "documents": [file_content],
        },
        follow=True,
    )

    access_key = AccessKey(user)
    assert response.status_code == 200
    documents = Document.objects.filter(access_key, session=session)
    assert documents.count() == 1
    assert documents[0].name == "sample"

    response = client.post(reverse("case_prep:delete_session", args=[session.id]))
    assert response.status_code == 200
    assert not Session.objects.filter(access_key, id=session.id).exists()



=== Contents of django\tests\chat\test_chat_models.py ===
from django.db import IntegrityError
from django.utils import timezone

import pytest

from chat.models import Chat, Message


@pytest.mark.django_db
def test_message_feedback_toggle(all_apps_user):
    user = all_apps_user()
    chat = Chat.objects.create(title="test", user=user)
    message = Message.objects.create(chat=chat, feedback=1)

    assert message.feedback == 1

    negative_feedback = message.get_toggled_feedback(-1)
    assert negative_feedback == -1

    negative_feedback = message.get_toggled_feedback(1)
    assert negative_feedback == 0

    try:
        message.get_toggled_feedback(2)
    except ValueError:
        assert True


@pytest.mark.django_db
def test_message_parent_relationship(all_apps_user):
    user = all_apps_user()
    chat = Chat.objects.create(title="test", user=user)

    message = Message.objects.create(chat=chat, is_bot=False)
    assert message.parent == None

    response_message = Message.objects.create(chat=chat, is_bot=True)
    assert response_message.parent == None

    response_message.parent = message
    response_message.save()
    assert response_message.parent == message

    try:
        user_message = Message.objects.create(chat=chat, is_bot=False)
        message.parent = user_message
        message.save()
        assert message.parent == None
    except IntegrityError:
        assert True



=== Contents of django\tests\chat\test_chat_options.py ===
import tempfile

from django.conf import settings
from django.urls import reverse

import pytest
from asgiref.sync import sync_to_async

from chat.forms import ChatOptionsForm
from chat.models import Chat, ChatFile, ChatOptions, Message
from chat.utils import htmx_stream, title_chat
from librarian.models import Library

pytest_plugins = ("pytest_asyncio",)
skip_on_github_actions = pytest.mark.skipif(
    settings.IS_RUNNING_IN_GITHUB, reason="Skipping tests on GitHub Actions"
)

skip_on_devops_pipeline = pytest.mark.skipif(
    settings.IS_RUNNING_IN_DEVOPS, reason="Skipping tests on DevOps Pipelines"
)


@pytest.mark.django_db
def test_chat_options(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)

    # Create a chat by hitting the new chat route
    # Need to follow redirects to have it create the ChatOptions (in "chat" view)
    response = client.get(reverse("chat:new_chat"), follow=True)
    assert response.status_code == 200
    new_chat = Chat.objects.filter(user=user).order_by("-created_at").first()
    # Check that a ChatOptions object has been created
    assert new_chat.options is not None

    # ChatOptions GET route should not work, since we need to POST the form
    response = client.get(reverse("chat:chat_options", args=[new_chat.id]))
    assert response.status_code == 500

    new_chat = Chat.objects.get(id=new_chat.id)
    # Change the chat options through the form
    options_form = ChatOptionsForm(instance=new_chat.options, user=user)
    options_form_data = options_form.initial
    options_form_data["qa_library"] = 1
    options_form_data["chat_system_prompt"] = (
        "You are a cowboy-themed AI, and always start your response with 'Howdy!'"
    )
    # Fix up the form data so that it matches POST data from browser
    options_form_data = {k: v for k, v in options_form_data.items() if v is not None}
    options_form_data["qa_data_sources"] = [
        data_source.id for data_source in options_form_data["qa_data_sources"]
    ]
    # Submit the form
    response = client.post(
        reverse("chat:chat_options", args=[new_chat.id]), options_form_data
    )
    assert response.status_code == 200

    new_chat = Chat.objects.get(id=new_chat.id)

    # Check that the chat options have been updated in the database
    assert (
        new_chat.options.chat_system_prompt == options_form_data["chat_system_prompt"]
    )

    # Try saving this as a preset
    options_form_data["option_presets"] = "Cowboy AI"
    response = client.post(
        reverse("chat:chat_options", args=[new_chat.id, "save_preset"]),
        options_form_data,
    )
    # The response should contain the new preset
    assert "Cowboy AI" in response.content.decode("utf-8")

    # Try creating a new chat then loading the preset
    response = client.get(reverse("chat:chat_with_ai"), follow=True)
    assert response.status_code == 200

    new_chat = Chat.objects.filter(user=user).order_by("-created_at").first()
    # Add a message
    new_message = Message.objects.create(chat=new_chat, text="Hello!")
    new_message.save()

    # Load the preset
    response = client.post(
        reverse("chat:chat_options", args=[new_chat.id, "load_preset"]),
        options_form_data,
    )

    # The chat options accordion should be returned, including the system prompt
    assert "You are a cowboy-themed AI" in response.content.decode("utf-8")
    # Check that the chat options have been updated in the database
    new_chat = Chat.objects.get(id=new_chat.id)
    assert (
        new_chat.options.chat_system_prompt == options_form_data["chat_system_prompt"]
    )

    # Reset the chat options
    response = client.post(
        reverse("chat:chat_options", args=[new_chat.id, "reset"]),
        options_form_data,
    )
    assert response.status_code == 200

    # Finally, delete the Cowboy AI preset
    response = client.post(
        reverse("chat:chat_options", args=[new_chat.id, "delete_preset"]),
        options_form_data,
    )

    # The response should not contain the new preset
    assert "Cowboy AI" not in response.content.decode("utf-8")

    # Check that the Cowboy AI chat option preset has been deleted
    assert not ChatOptions.objects.filter(preset_name="Cowboy AI", user=user).exists()



=== Contents of django\tests\chat\test_chat_procs.py ===
import asyncio

import pytest
from asgiref.sync import sync_to_async
from bs4 import BeautifulSoup as bs

from chat.llm import OttoLLM
from chat.models import Chat, Message
from chat.utils import (
    htmx_stream,
    llm_response_to_html,
    summarize_long_text_async,
    url_to_text,
)

pytest_plugins = ("pytest_asyncio",)

tags_outside_backticks = """
<div>Here is some text</div>
<div>Here is some more text</div>
"""

tags_inside_triple_backticks = """
<div>Here is some text</div>
```
<div>Here is some more text</div>
```
"""

tags_inside_single_backticks = """
<div>Here is some text</div>
`<div>Here is some more text</div>`
"""

markdown_list = """
* Item 1
* Item 2
"""


def test_llm_response_formatter():

    # Test that markdown is parsed
    html = llm_response_to_html(markdown_list)
    soup = bs(html, "html.parser")
    assert soup.find_all("li")
    assert soup.find_all("ul")
    assert soup.find_all("li")[0].text == "Item 1"
    assert soup.find_all("li")[1].text == "Item 2"


def test_url_to_text():
    # Test that a URL with a valid article returns the article text
    url = "https://en.wikipedia.org/wiki/Ottawa"
    text = url_to_text(url)
    assert text
    assert len(text) > 100
    assert "Ottawa" in text
    assert "Canada" in text

    # Test that a URL with an invalid article returns an empty string
    url = "http://aofwgyauhwfg.awfognahwofg/"
    text = url_to_text(url)
    assert text == ""


@pytest.mark.django_db
@pytest.mark.asyncio
async def test_htmx_stream_response_stream(all_apps_user):
    llm = OttoLLM()

    async def stream_generator():
        for char in "Hi!":
            yield char
            await asyncio.sleep(0.1)

    # We first need an empty chat and a message
    user = await sync_to_async(all_apps_user)("test_user_1")
    chat = await sync_to_async(Chat.objects.create)(user=user)
    message = await sync_to_async(Message.objects.create)(chat=chat, text="Hello")
    assert await sync_to_async(chat.messages.count)() == 1
    response_stream = htmx_stream(
        chat,
        message.id,
        response_generator=stream_generator(),
        llm=llm,
    )
    # Iterate over the response_stream generator
    final_output = ""
    async for yielded_output in response_stream:
        # Output should start with "data: " for Server-Sent Events
        assert yielded_output.startswith("data: ")
        # Output should end with a double newline
        assert yielded_output.endswith("\n\n")
        final_output = yielded_output
    assert "Hi!" in final_output
    # There should be an element in the response to replace the SSE div
    assert "<div hx-swap-oob" in final_output
    # Message should have been updated
    assert await sync_to_async(chat.messages.count)() == 1


@pytest.mark.asyncio
@pytest.mark.django_db()
async def test_htmx_stream_response_str(all_apps_user):
    llm = OttoLLM()
    # We first need an empty chat and a message
    user = await sync_to_async(all_apps_user)("test_user_2")
    chat = await sync_to_async(Chat.objects.create)(user=user)
    message = await sync_to_async(Message.objects.create)(chat=chat, text="Hello")
    assert await sync_to_async(chat.messages.count)() == 1
    response_stream = htmx_stream(
        chat,
        message.id,
        response_str="Hi!",
        llm=llm,
    )
    # Iterate over the response_stream generator
    final_output = ""
    async for yielded_output in response_stream:
        # Output should start with "data: " for Server-Sent Events
        assert yielded_output.startswith("data: ")
        # Output should end with a double newline
        assert yielded_output.endswith("\n\n")
        final_output = yielded_output
    assert "Hi!" in final_output
    # There should be an element in the response to replace the SSE div
    assert "<div hx-swap-oob" in final_output
    # Message should have been updated
    assert await sync_to_async(chat.messages.count)() == 1


@pytest.mark.asyncio
@pytest.mark.django_db()
async def test_htmx_stream_response_generator(all_apps_user):
    llm = OttoLLM()

    class FakeFile:
        def __init__(self, name, text):
            self.name = name
            self.text = text

    async def stream_generator():
        files = [
            FakeFile("file1.txt", "This is the first file"),
            FakeFile("file2.txt", "This is the second file"),
        ]
        for i, file in enumerate(files):
            yield f"**{file.name}**\n"
            summary = await summarize_long_text_async(file.text, llm, "short")
            if i < len(files) - 1:
                yield f"{summary}\n\n-----\n"
            else:
                yield f"{summary}\n"

    # We first need an empty chat and a message
    user = await sync_to_async(all_apps_user)("test_user_3")
    chat = await sync_to_async(Chat.objects.create)(user=user)
    message = await sync_to_async(Message.objects.create)(chat=chat, text="Hello")
    assert await sync_to_async(chat.messages.count)() == 1
    response_stream = htmx_stream(
        chat,
        message.id,
        response_generator=stream_generator(),
        llm=llm,
    )
    # Iterate over the response_stream generator
    final_output = ""
    async for yielded_output in response_stream:
        # Output should start with "data: " for Server-Sent Events
        assert yielded_output.startswith("data: ")
        # Output should end with a double newline
        assert yielded_output.endswith("\n\n")
        final_output = yielded_output
    assert "file1.txt" in final_output
    assert "file2.txt" in final_output
    # There should be an element in the response to replace the SSE div
    assert "<div hx-swap-oob" in final_output
    # Message should have been updated
    assert await sync_to_async(chat.messages.count)() == 1


@pytest.mark.asyncio
@pytest.mark.django_db()
async def test_htmx_stream_response_replacer(basic_user):
    llm = OttoLLM()

    async def stream_generator():
        yield "first thing"
        yield "second thing"

    # We first need an empty chat and a message
    user = await sync_to_async(basic_user)("test_user_4")
    chat = await sync_to_async(Chat.objects.create)(user=user)
    message = await sync_to_async(Message.objects.create)(chat=chat, text="Hello")
    assert await sync_to_async(chat.messages.count)() == 1
    response_stream = htmx_stream(
        chat,
        message.id,
        response_replacer=stream_generator(),
        format=False,
        llm=llm,
    )
    # Iterate over the response_stream generator
    final_output = ""
    first = True
    async for yielded_output in response_stream:
        if first:
            assert "first thing" in yielded_output
            first = False
        else:
            assert "second thing" in yielded_output
        # Output should start with "data: " for Server-Sent Events
        assert yielded_output.startswith("data: ")
        # Output should end with a double newline
        assert yielded_output.endswith("\n\n")
        final_output = yielded_output
    assert "first thing" not in final_output
    assert "second thing" in final_output
    # There should be an element in the response to replace the SSE div
    assert "<div hx-swap-oob" in final_output
    # A new message should NOT have been created
    assert await sync_to_async(chat.messages.count)() == 1



=== Contents of django\tests\chat\test_chat_views.py ===
import json
import tempfile

from django.conf import settings
from django.urls import reverse
from django.utils import timezone

import pytest
from asgiref.sync import sync_to_async

from chat.llm import OttoLLM
from chat.models import Chat, ChatFile, Message
from chat.utils import htmx_stream, title_chat
from librarian.models import Library
from otto.models import App, Notification, SecurityLabel

pytest_plugins = ("pytest_asyncio",)
skip_on_github_actions = pytest.mark.skipif(
    settings.IS_RUNNING_IN_GITHUB, reason="Skipping tests on GitHub Actions"
)

skip_on_devops_pipeline = pytest.mark.skipif(
    settings.IS_RUNNING_IN_DEVOPS, reason="Skipping tests on DevOps Pipelines"
)


@pytest.mark.django_db
def test_title_chat(client, all_apps_user):
    llm = OttoLLM()
    user = all_apps_user()
    client.force_login(user)
    chat = Chat.objects.create(user=user)
    # The title_chat function, with force_title=True
    # should return "Untitled chat"
    chat_title = title_chat(chat.id, llm, force_title=True)
    assert chat_title == "Untitled chat"

    # Create 2 messages
    Message.objects.create(chat=chat, text="Hello")
    Message.objects.create(chat=chat, text="How are you?", is_bot=True)

    # The title_chat function, with force_title=False
    # should return an empty string
    chat_title = title_chat(chat.id, llm, force_title=False)
    assert chat_title == ""

    # The title_chat function, with force_title=True
    # should return a title
    chat_title = title_chat(chat.id, llm, force_title=True)
    assert chat_title != ""

    # Add a third message
    Message.objects.create(chat=chat, text="I'm doing well, thanks")

    # The title_chat function, with force_title=False
    # should now return a title since there are 3 messages
    chat_title = title_chat(chat.id, llm, force_title=False)
    assert chat_title != ""


@pytest.mark.django_db
def test_chat(client, basic_user, all_apps_user):
    # Test scenario: Not logged in
    response = client.get(reverse("chat:new_chat"))
    assert response.status_code == 302
    # This should redirect to the welcome page
    assert response.url == reverse("welcome") + "?next=" + reverse("chat:new_chat")

    # Test scenario: Logged in as a basic user
    user = basic_user()
    client.force_login(user)
    response = client.get(reverse("chat:new_chat"))
    # This should redirect to the accept terms page
    assert response.status_code == 302
    assert response.url == reverse("accept_terms") + "?next=" + reverse("chat:new_chat")

    # Accept the terms
    user.accepted_terms_date = timezone.now()
    user.save()

    response = client.get(reverse("chat:new_chat"))
    # This should now redirect to the index page and create a notification
    assert response.status_code == 302
    assert response.url == reverse("index")

    # Check that a notification was created
    notification = Notification.objects.filter(user=user).first()
    assert notification is not None

    # Test scenario: Logged in as all apps user
    user = all_apps_user()
    client.force_login(user)
    response = client.get(reverse("chat:new_chat"))
    assert response.status_code == 302
    chat = Chat.objects.filter(user=user).order_by("-created_at").first()
    assert chat.security_label == SecurityLabel.default_security_label()
    chat_id = chat.id
    assert response.url == reverse("chat:chat", args=[chat_id])
    response = client.get(reverse("chat:chat", args=[chat_id]))
    assert "Untitled chat" in response.content.decode("utf-8")

    # Test scenario: Check that the chat will create a security label if it doesn't exist
    Message.objects.create(chat=chat, text="Message 1", chat_id=chat_id)
    Message.objects.create(chat=chat, text="Message 2", chat_id=chat_id)
    chat.security_label = None
    chat.save()

    client.get(reverse("chat:chat", args=[chat_id]))
    chat = Chat.objects.filter(user=user).order_by("-created_at").first()
    assert chat.security_label == SecurityLabel.default_security_label()


@pytest.mark.django_db
def test_chat_message(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)
    response = client.get(reverse("chat:chat_with_ai"), follow=True)
    # Find the newest user chat
    chat_id = Chat.objects.filter(user=user).order_by("-created_at").first().id
    response = client.post(
        reverse("chat:chat_message", args=[chat_id]),
        data={"user-message": "Hello"},
    )
    assert response.status_code == 200
    assert "Hello" in response.content.decode("utf-8")

    # Check that the message was saved
    assert Message.objects.filter(chat_id=chat_id).count() == 2
    message = Message.objects.filter(chat_id=chat_id).first()
    assert message.text == "Hello"

    response = client.get(reverse("chat:chat_response", args=[message.id + 1]))
    assert response.status_code == 200


# TODO: Test Celery tasks
@skip_on_github_actions
@skip_on_devops_pipeline
@pytest.mark.django_db
def test_translate_file(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)
    # Write a file to translate called "test file.txt" with contents "Hello"
    with tempfile.TemporaryDirectory() as tmpdirname:
        with open(f"{tmpdirname}/test file.txt", "w") as file:
            file.write("Hello")
        response = client.get(reverse("chat:new_chat"), follow=True)
        assert response.status_code == 200
        chat = Chat.objects.filter(user=user).order_by("-created_at").first()
        # Check that a ChatOptions object has been created
        assert chat.options is not None
        # Set mode to Translate
        chat.options.mode = "translate"
        chat.options.translate_language = "fr"
        chat.options.save()

        # Create a message and add a file
        in_message = Message.objects.create(chat=chat, text="")
        chat_file = ChatFile.objects.create(
            message_id=in_message.id,
            filename="test file.txt",
            eof=1,
            content_type="text/plain",
        )
        assert in_message.num_files == 1

        # Create the response message
        out_message = Message.objects.create(
            chat=chat, mode="translate", is_bot=True, parent=in_message
        )

        chat_file.saved_file.file.save(
            "test file.txt", open(f"{tmpdirname}/test file.txt", "rb")
        )
        response = client.post(reverse("chat:chat_response", args=[out_message.id]))
        assert response.status_code == 200

        # TODO: Test the Celery task
        # Need to research best practices. See https://docs.celeryq.dev/en/main/userguide/testing.html

        # assert translated_file.name == "test_file_FR.txt"
        # assert translated_file.content_type == "text/plain"
        # assert translated_file.eof == 1
        # # The translated file should contain the translation of "Hello" to French
        # with open(translated_file.file.path, "r") as file:
        #     assert "Bonjour" in file.read()
        # # Check that the translated file was saved
        # assert ChatFile.objects.count() == chatfile_count + 1
        # assert ChatFile.objects.filter(message_id=out_message.id).count() == 1
        # assert out_message.sorted_files.count() == 1


@pytest.mark.asyncio
@pytest.mark.django_db(transaction=True)
async def test_htmx_stream_stop(client, all_apps_user):
    llm = OttoLLM()

    async def stream_generator():
        yield "first thing"
        yield "second thing"
        yield "third thing"

    # We first need an empty chat and a message
    user = await sync_to_async(all_apps_user)("test_user_stream_stop")
    await sync_to_async(client.force_login)(user)
    chat = await sync_to_async(Chat.objects.create)(user=user)
    message = await sync_to_async(Message.objects.create)(chat=chat, text="Hello")
    response_message = await sync_to_async(Message.objects.create)(
        chat=chat, mode="chat", is_bot=True, parent=message
    )
    assert await sync_to_async(chat.messages.count)() == 2
    response_stream = htmx_stream(
        chat,
        response_message.id,
        response_replacer=stream_generator(),
        format=False,
        llm=llm,
    )
    # Iterate over the response_stream generator
    final_output = ""
    first = True
    async for yielded_output in response_stream:
        if first:
            assert "first thing" in yielded_output
            # Stop the stream by requesting chat:stop_response
            response = await sync_to_async(client.get)(
                reverse("chat:stop_response", args=[response_message.id])
            )
            first = False
            assert response.status_code == 200
        # Output should start with "data: " for Server-Sent Events
        assert yielded_output.startswith("data: ")
        # Output should end with a double newline
        assert yielded_output.endswith("\n\n")
        final_output = yielded_output
    # Before stopping, the second generated message should be in the output
    assert "second thing" in final_output
    # However, the third message should not be in the output
    assert "third thing" not in final_output
    # There should be an element in the response to replace the SSE div
    assert "<div hx-swap-oob" in final_output
    # A new message should NOT have been created
    assert await sync_to_async(chat.messages.count)() == 2


@pytest.mark.django_db
def test_chat_routes(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)
    new_translate = reverse("chat:translate")
    new_summarize = reverse("chat:summarize")
    new_qa = reverse("chat:qa")
    new_document_qa = reverse("chat:document_qa")
    new_chat = reverse("chat:new_chat")
    Chat.objects.all().delete()
    # Check that the routes are accessible. Each should create a new chat
    response = client.get(new_translate)
    assert response.status_code == 302
    original_chat_id = Chat.objects.filter(user=user).order_by("-created_at").first().id
    assert response.url == reverse("chat:chat", args=[original_chat_id])
    assert Chat.objects.count() == 1
    response = client.get(new_summarize)
    assert response.status_code == 302
    response = client.get(new_qa)
    assert response.status_code == 302
    response = client.get(new_document_qa)
    assert response.status_code == 302
    response = client.get(new_chat)
    assert response.status_code == 302
    # Now open the chat directly
    response = client.get(
        reverse(
            "chat:chat",
            args=[Chat.objects.filter(user=user).order_by("-created_at").first().id],
        )
    )
    assert response.status_code == 200
    assert "Untitled chat" in response.content.decode("utf-8")


# Test delete_chat view
@pytest.mark.django_db
def test_delete_chat(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)
    chat = Chat.objects.create(user=user)
    assert Chat.objects.filter(user=user).count() == 1
    response = client.get(reverse("chat:delete_chat", args=[chat.id, chat.id]))
    assert response.status_code == 200
    assert Chat.objects.filter(user=user).count() == 0
    # This should give a 404
    response = client.post(reverse("chat:delete_chat", args=[chat.id, chat.id]))
    assert response.status_code == 404


# Test delete_all_chats view
@pytest.mark.django_db
def test_delete_all_chats(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)

    # Create multiple chats for the user
    Chat.objects.create(user=user)
    Chat.objects.create(user=user)
    assert Chat.objects.filter(user=user).count() == 2

    # Call the delete_all_chats view
    response = client.get(reverse("chat:delete_all_chats"))

    # Check that all chats are deleted
    assert response.status_code == 200
    assert Chat.objects.filter(user=user).count() == 0

    # Check that the response contains the HX-Redirect header
    assert response["HX-Redirect"] == reverse("chat:new_chat")


# Test init_upload view
@pytest.mark.django_db
def test_init_upload(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)
    chat = Chat.objects.create(user=user)
    response = client.get(reverse("chat:init_upload", args=[chat.id]))
    assert response.status_code == 200


# Test done_upload view with modes "translate", "summarize" and "document_qa"
@pytest.mark.django_db
def test_done_upload(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)
    chat = Chat.objects.create(user=user)
    message = Message.objects.create(chat=chat, text="Hello", mode="translate")
    response = client.get(reverse("chat:done_upload", args=[message.id]))
    assert response.status_code == 200
    message = Message.objects.create(chat=chat, text="Hello", mode="summarize")
    response = client.get(reverse("chat:done_upload", args=[message.id]))
    assert response.status_code == 200
    message = Message.objects.create(chat=chat, text="Hello", mode="document_qa")
    response = client.get(reverse("chat:done_upload", args=[message.id]))
    assert response.status_code == 200


# TODO: Test chunk_upload (somewhat difficult)


# Test download_file view
@pytest.mark.django_db
def test_download_file(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)
    # Write a file to translate called "test file.txt" with contents "Hello"
    with tempfile.TemporaryDirectory() as tmpdirname:
        with open(f"{tmpdirname}/test file.txt", "w") as file:
            file.write("Hello")
        chat = Chat.objects.create(user=user)
        in_message = Message.objects.create(chat=chat, text="")
        chat_file = ChatFile.objects.create(
            message_id=in_message.id,
            filename="test file.txt",
            eof=1,
            content_type="text/plain",
        )
        chat_file.saved_file.file.save(
            "test file.txt", open(f"{tmpdirname}/test file.txt", "rb")
        )
        file_id = chat_file.id
        url = reverse("chat:download_file", args=[file_id])
        response = client.get(url)
        assert response.status_code == 200
    wrong_user = all_apps_user("wrong_user")
    client.force_login(wrong_user)
    response = client.get(url)
    assert response.status_code != 200
    # Non-existing chat file
    response = client.get(reverse("chat:download_file", args=[999]))
    assert response.status_code == 404


@pytest.mark.django_db
def test_chat_response(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)

    # Create a chat using the chat_with_ai route to create it with appropriate options
    response = client.get(reverse("chat:chat_with_ai"), follow=True)
    chat = Chat.objects.filter(user=user).order_by("-created_at").first()

    message = Message.objects.create(chat=chat, text="Hello", mode="chat")
    response_message = Message.objects.create(
        chat=chat, mode="chat", is_bot=True, parent=message
    )

    response = client.get(reverse("chat:chat_response", args=[response_message.id]))
    assert response.status_code == 200
    # Test different lengths of input
    text_between_4k_and_16k = "Hello there!\n" * 2000
    message = Message.objects.create(
        chat=chat, text=text_between_4k_and_16k, mode="chat"
    )
    response_message = Message.objects.create(
        chat=chat, mode="chat", is_bot=True, parent=message
    )
    response = client.get(reverse("chat:chat_response", args=[response_message.id]))
    assert response.status_code == 200
    # Text over 16k should still return a correct response
    text_over_16k = "Hello there!\n" * 16000
    message = Message.objects.create(chat=chat, text=text_over_16k, mode="chat")
    response_message = Message.objects.create(
        chat=chat, mode="chat", is_bot=True, parent=message
    )
    response = client.get(reverse("chat:chat_response", args=[response_message.id]))
    assert response.status_code == 200
    # Test GPT-4
    message = Message.objects.create(
        chat=chat, text="Hello", mode="chat", details={"model": "gpt-4"}
    )
    response_message = Message.objects.create(
        chat=chat, mode="chat", is_bot=True, parent=message
    )
    response = client.get(reverse("chat:chat_response", args=[response_message.id]))
    assert response.status_code == 200

    # Test chat_response with an invalid mode
    message = Message.objects.create(chat=chat, text="Hello", mode="invalid_mode")
    response_message = Message.objects.create(
        chat=chat, mode="chat", is_bot=True, parent=message
    )
    response = client.get(reverse("chat:chat_response", args=[response_message.id]))
    # This should also return a 200 status code, albeit with an error message
    assert response.status_code == 200


# Test chat_response with Summarize mode
@pytest.mark.django_db
def test_chat_summarization_response(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)

    # Create a chat using the route to create it with appropriate options
    response = client.get(reverse("chat:summarize"), follow=True)
    chat = Chat.objects.filter(user=user).order_by("-created_at").first()

    text_between_4k_and_16k = "Hello there!\n" * 2000

    message = Message.objects.create(chat=chat, text="Hello", mode="summarize")
    response_message = Message.objects.create(
        chat=chat, mode="summarize", is_bot=True, parent=message
    )
    response = client.get(reverse("chat:chat_response", args=[response_message.id]))
    assert response.status_code == 200
    # Test longer message
    message = Message.objects.create(
        chat=chat, text=text_between_4k_and_16k, mode="summarize"
    )
    response_message = Message.objects.create(
        chat=chat, mode="summarize", is_bot=True, parent=message
    )
    response = client.get(reverse("chat:chat_response", args=[response_message.id]))
    assert response.status_code == 200

    # Test very long message: TODO: This Sumy code does NOT work!!!
    # message = Message.objects.create(chat=chat, text=text_over_16k, mode="summarize")
    # response = client.get(reverse("chat:chat_response", args=[message.id]))
    # assert response.status_code == 200

    # Test with a URL
    message = Message.objects.create(
        chat=chat, text="https://en.wikipedia.org/wiki/Ottawa", mode="summarize"
    )
    response_message = Message.objects.create(
        chat=chat, mode="summarize", is_bot=True, parent=message
    )
    response = client.get(reverse("chat:chat_response", args=[response_message.id]))
    assert response.status_code == 200
    # Test with multiple files
    files_message = Message.objects.create(chat=chat, text="", mode="summarize")
    files_message_response = Message.objects.create(
        chat=chat, text="", mode="summarize", is_bot=True, parent=files_message
    )

    with tempfile.TemporaryDirectory() as tmpdirname:
        with open(f"{tmpdirname}/test file.txt", "w") as file:
            file.write("Hello")
        file1 = ChatFile.objects.create(
            message_id=files_message.id,
            filename="test file.txt",
            eof=1,
            content_type="text/plain",
        )
        file1.saved_file.file.save(
            "test file.txt", open(f"{tmpdirname}/test file.txt", "rb")
        )
        file2 = ChatFile.objects.create(
            message_id=files_message.id,
            filename="test file2.txt",
            eof=1,
            content_type="text/plain",
        )
        file2.saved_file.file.save(
            "test file2.txt", open(f"{tmpdirname}/test file.txt", "rb")
        )
        response = client.get(
            reverse("chat:chat_response", args=[files_message_response.id])
        )
        assert response.status_code == 200


# Test chat_response with QA and Translate modes
# These require additional setup / authentications and won't run on GitHub
@skip_on_github_actions
@pytest.mark.django_db
def test_translate_response(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)

    # Create a chat using the route to create it with appropriate options
    response = client.get(reverse("chat:translate"), follow=True)
    chat = Chat.objects.filter(user=user).order_by("-created_at").first()

    # Test chat_response with Translate mode
    message = Message.objects.create(chat=chat, text="Hello", mode="translate")
    message = Message.objects.create(
        chat=chat, mode="translate", is_bot=True, parent=message
    )
    response = client.get(reverse("chat:chat_response", args=[message.id]))
    assert response.status_code == 200
    # Test with files.
    # TODO: File upload doesn't actually complete, again because of the SSE testing issue
    files_message = Message.objects.create(
        chat=chat, text="", mode="translate", is_bot=True, parent=message
    )
    with tempfile.TemporaryDirectory() as tmpdirname:
        with open(f"{tmpdirname}/test file.txt", "w") as file:
            file.write("Hello")
        file1 = ChatFile.objects.create(
            message_id=files_message.id,
            filename="test file.txt",
            eof=1,
            content_type="text/plain",
        )
        file1.saved_file.file.save(
            "test file.txt", open(f"{tmpdirname}/test file.txt", "rb")
        )
        file2 = ChatFile.objects.create(
            message_id=files_message.id,
            filename="test file2.txt",
            eof=1,
            content_type="text/plain",
        )
        file2.saved_file.file.save(
            "test file2.txt", open(f"{tmpdirname}/test file.txt", "rb")
        )
    files_message = Message.objects.create(
        chat=chat, text="", mode="translate", is_bot=True, parent=files_message
    )
    response = client.get(reverse("chat:chat_response", args=[files_message.id]))
    assert response.status_code == 200


@pytest.mark.django_db
def test_qa_response(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)

    # Create a chat using the route to create it with appropriate options
    response = client.get(reverse("chat:qa"), follow=True)
    chat = Chat.objects.filter(user=user).order_by("-created_at").first()

    # Test corporate chatbot QA mode
    corporate_library_id = Library.objects.get_default_library().id
    message = Message.objects.create(
        chat=chat, text="What is my dental coverage?", mode="qa"
    )
    message.details["library"] = corporate_library_id
    message.save()
    response_message = Message.objects.create(
        chat=chat, mode="qa", is_bot=True, parent=message
    )
    response = client.get(reverse("chat:chat_response", args=[response_message.id]))
    assert response.status_code == 200

    # TODO: Check that the newest message in the Chat now has some AnswerSources
    # I can't get this working! I think its because of the Server-Sent-Events
    # It is unclear how to test SSE responses in Django tests

    # response_message = (
    #     Message.objects.filter(chat=chat).order_by("-created_at").first()
    # )
    # assert response_message.sources.count() > 0


@pytest.mark.django_db
def test_api_qa(client, all_apps_user, settings):

    # For some reason, the rule isn't getting loaded automatically in this test!
    # So I have to add the permission manually. TODO: Fix this...
    from rules import add_perm

    from otto.rules import can_access_app

    add_perm("otto:access_app", can_access_app)

    # Create a test user
    user = all_apps_user("api_user")
    client.force_login(user)

    # Define the endpoint
    url = reverse("chat:api_qa")

    # Define the request payload
    payload = {
        "upn": "api_user_upn",
        "library": "Corporate",
        "data_sources": ["Pay and Benefits"],
        "user_message": "What are my leave entitlements?",
    }

    # Override the token for test
    settings.OTTO_VERIFICATION_TOKEN = "test-token"

    # Define the headers
    headers = {
        "HTTP_X_VERIFICATION_TOKEN": settings.OTTO_VERIFICATION_TOKEN,
    }

    # Make the API call with the JSON payload
    response = client.post(
        url,
        data=json.dumps(payload),
        content_type="application/json",
        **headers,
        follow=True,
    )

    print(response.content.decode("utf-8"))

    # Check the response status
    assert response.status_code == 200
    response_data = response.json()
    assert response_data["status"] == "success"
    assert "redirect_url" in response_data

    # Check if the chat and messages were created correctly
    chat = Chat.objects.filter(user=user).order_by("-created_at").first()
    library = Library.objects.get(name="Corporate")
    assert chat is not None
    assert chat.options.mode == "qa"
    assert chat.options.qa_library == library

    user_message = Message.objects.filter(chat=chat, is_bot=False).first()
    assert user_message is not None
    assert user_message.text == payload["user_message"]

    bot_message = Message.objects.filter(chat=chat, is_bot=True).first()
    assert bot_message is not None
    assert bot_message.parent == user_message

    # Test with missing verification token
    headers.pop("HTTP_X_VERIFICATION_TOKEN")
    response = client.post(
        url,
        data=json.dumps(payload),
        content_type="application/json",
        **headers,
        follow=True,
    )
    assert response.status_code == 400
    response_data = response.json()
    assert response_data["error_code"] == "MISSING_TOKEN"

    # Test with invalid verification token
    headers["HTTP_X_VERIFICATION_TOKEN"] = "invalid-token"
    response = client.post(
        url,
        data=json.dumps(payload),
        content_type="application/json",
        **headers,
        follow=True,
    )
    assert response.status_code == 403
    response_data = response.json()
    assert response_data["error_code"] == "INVALID_TOKEN"

    # Test with invalid user
    payload["upn"] = "invalid_user"
    headers["HTTP_X_VERIFICATION_TOKEN"] = settings.OTTO_VERIFICATION_TOKEN
    response = client.post(
        url,
        data=json.dumps(payload),
        content_type="application/json",
        **headers,
        follow=True,
    )
    assert response.status_code == 401
    response_data = response.json()
    assert response_data["error_code"] == "USER_NOT_FOUND"

    # Test with invalid library
    payload["upn"] = "api_user_upn"
    payload["library"] = "Invalid Library"
    response = client.post(
        url,
        data=json.dumps(payload),
        content_type="application/json",
        **headers,
        follow=True,
    )
    assert response.status_code == 404
    response_data = response.json()
    assert response_data["error_code"] == "LIBRARY_NOT_FOUND"


@pytest.mark.django_db
def test_qa_response(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)

    # Create a chat using the route to create it with appropriate options
    response = client.get(reverse("chat:qa"), follow=True)
    chat = Chat.objects.filter(user=user).order_by("-created_at").first()

    # Test chat_response with Document QA mode. Start with no files
    # Now make a new message asking a question about the document(s)
    message = Message.objects.create(
        chat=chat,
        text="What is the capital of Canada?",
        mode="qa",
    )
    response_message = Message.objects.create(
        chat=chat, mode="qa", is_bot=True, parent=message
    )
    response = client.get(reverse("chat:chat_response", args=[response_message.id]))
    assert response.status_code == 200

    # TODO: The latest bot message should NOT have answersources
    # response_message = (
    #     Message.objects.filter(chat=chat).order_by("-created_at").first()
    # )
    # assert response_message.sources.count() == 0

    # Now add some files
    # TODO: This doesn't actually complete, again because of the SSE testing issue
    files_message = Message.objects.create(chat=chat, text="", mode="qa")
    files_message_reponse = Message.objects.create(
        chat=chat, text="", mode="qa", is_bot=True, parent=files_message
    )
    with tempfile.TemporaryDirectory() as tmpdirname:
        with open(f"{tmpdirname}/test file.txt", "w") as file:
            file.write("The capital of Canada is Ottawa.")
        file1 = ChatFile.objects.create(
            message_id=files_message.id,
            filename="test file.txt",
            eof=1,
            content_type="text/plain",
        )
        file1.saved_file.file.save(
            "test file.txt", open(f"{tmpdirname}/test file.txt", "rb")
        )
        file2 = ChatFile.objects.create(
            message_id=files_message.id,
            filename="test file2.txt",
            eof=1,
            content_type="text/plain",
        )
        file2.saved_file.file.save(
            "test file2.txt", open(f"{tmpdirname}/test file.txt", "rb")
        )
        response = client.get(
            reverse("chat:chat_response", args=[files_message_reponse.id])
        )
        assert response.status_code == 200

    # Ask the question again
    message = Message.objects.create(
        chat=chat,
        text="What is the capital of Canada?",
        mode="qa",
    )
    response_message = Message.objects.create(
        chat=chat, text="", mode="qa", is_bot=True, parent=message
    )
    response = client.get(reverse("chat:chat_response", args=[response_message.id]))
    assert response.status_code == 200

    # TODO: The latest bot message should have answersources
    # response_message = (
    #     Message.objects.filter(chat=chat).order_by("-created_at").first()
    # )
    # assert response_message.sources.count() > 0


@pytest.mark.django_db
def test_positive_thumbs_feedback(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)
    chat = Chat.objects.create(title="test", user=user)
    Message.objects.create(chat=chat)
    message = Message.objects.create(chat=chat, is_bot=True)

    response = client.get(
        reverse(
            "chat:thumbs_feedback", kwargs={"message_id": message.id, "feedback": "1"}
        )
    )

    assert Message.objects.filter(chat_id=chat.id).last().feedback == 1
    assert response.status_code == 200


@pytest.mark.django_db
def test_negative_thumbs_feedback(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)
    chat = Chat.objects.create(title="test", user=user)
    Message.objects.create(chat=chat)
    message = Message.objects.create(chat=chat, is_bot=True)

    response = client.get(
        reverse(
            "chat:thumbs_feedback", kwargs={"message_id": message.id, "feedback": "-1"}
        )
    )

    assert Message.objects.filter(chat_id=chat.id).last().feedback == -1
    assert (
        response.status_code == 200
        and "Provide feedback" in response.content.decode("utf-8")
    )


@pytest.mark.django_db
def test_rename_chat_title(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)
    chat = Chat.objects.create(user=user)
    chat.title = "My chat"
    chat.save()

    # Create 3 messages
    Message.objects.create(chat=chat, text="Hello")
    Message.objects.create(chat=chat, text="How are you?", is_bot=True)
    Message.objects.create(chat=chat, text="I'm doing well, thanks")

    # Test the title_chat function
    response = client.get(
        reverse(
            "chat:chat_list_item", kwargs={"chat_id": chat.id, "current_chat": "True"}
        )
    )
    assert response.status_code == 200
    assert "My chat" in response.content.decode("utf-8")

    # Rename the chat to "My new chat"
    new_title = "My new chat"
    response = client.post(
        reverse(
            "chat:rename_chat", kwargs={"chat_id": chat.id, "current_chat": "True"}
        ),
        data={"title": new_title},
    )
    assert response.status_code == 200
    assert new_title in response.content.decode("utf-8")

    invalid_title = "".join("a" for _ in range(256))
    # Test invalid form
    response = client.post(
        reverse(
            "chat:rename_chat", kwargs={"chat_id": chat.id, "current_chat": "True"}
        ),
        data={"title": invalid_title},
    )
    assert response.status_code == 200
    assert f'value="{invalid_title}"' in response.content.decode("utf-8")

    # Test get
    response = client.get(
        reverse("chat:rename_chat", kwargs={"chat_id": chat.id, "current_chat": "True"})
    )
    assert response.status_code == 200
    assert f'value="{new_title}"' in response.content.decode("utf-8")



=== Contents of django\tests\laws\conftest.py ===
from django.core.management import call_command

import pytest_asyncio
from asgiref.sync import sync_to_async


@pytest_asyncio.fixture(scope="session")
async def django_db_setup(django_db_setup, django_db_blocker):
    def _inner():
        with django_db_blocker.unblock():
            call_command("load_laws_xml", "--reset", "--small")

    return await sync_to_async(_inner)()



=== Contents of django\tests\laws\test_laws_views.py ===
import urllib.parse

from django.conf import settings
from django.core.cache import cache
from django.urls import reverse

import pytest

pytest_plugins = ("pytest_asyncio",)
skip_on_github_actions = pytest.mark.skipif(
    settings.IS_RUNNING_IN_GITHUB, reason="Skipping tests on GitHub Actions"
)

skip_on_devops_pipeline = pytest.mark.skipif(
    settings.IS_RUNNING_IN_DEVOPS, reason="Skipping tests on DevOps Pipelines"
)


@pytest.mark.django_db
def test_laws_index(client, all_apps_user):
    client.force_login(all_apps_user())
    response = client.get(reverse("laws:index"))
    assert response.status_code == 200
    assert "Legislation search" in response.content.decode()


@pytest.mark.django_db
def test_laws_search_form(client, all_apps_user):
    client.force_login(all_apps_user())
    # Basic search form
    # Advanced search form
    response = client.get(reverse("laws:advanced_search_form"))
    assert response.status_code == 200
    assert "filter" in response.content.decode().lower()


@pytest.mark.django_db
def test_laws_search_and_answer(client, all_apps_user):
    client.force_login(all_apps_user())
    # Test basic search
    query = (
        "who has the right to access records about the defence of canada regulations?"
    )
    response = client.post(reverse("laws:search"), {"query": query})
    assert response.status_code == 200
    assert query in response.content.decode()
    # The results should have been cached
    assert cache.get(f"sources_{query}") is not None

    # Test answer
    response = client.get(
        reverse("laws:answer") + f"?query={urllib.parse.quote_plus(query)}"
    )
    assert response.status_code == 200
    # The results cache should have been deleted
    assert cache.get(f"sources_{query}") is None

    query = (
        "are the defence of canada regulations exempt from access to information act?"
    )
    # Test advanced search - with no acts/regs selected it should return an error message
    response = client.post(reverse("laws:search"), {"query": query, "advanced": "true"})
    assert response.status_code == 200
    assert "No sources found" in response.content.decode()
    # There are no sources, so they should not be cached
    assert cache.get(f"sources_{query}") is None



=== Contents of django\tests\librarian\test_librarian.py ===
from django.conf import settings
from django.urls import reverse

import pytest

from librarian.forms import LibraryDetailForm
from librarian.models import DataSource, Document, Library
from librarian.views import get_editable_libraries

skip_on_github_actions = pytest.mark.skipif(
    settings.IS_RUNNING_IN_GITHUB, reason="Skipping tests on GitHub Actions"
)

skip_on_devops_pipeline = pytest.mark.skipif(
    settings.IS_RUNNING_IN_DEVOPS, reason="Skipping tests on DevOps Pipelines"
)


@pytest.mark.django_db
def test_editable_library_list_and_library_form(client, all_apps_user, basic_user):
    # All apps user should be able to edit all public libraries
    user = all_apps_user()
    client.force_login(user)
    user_libraries = get_editable_libraries(user)
    assert len(user_libraries) == Library.objects.filter(is_public=True).count()
    # Add a library for the all apps user
    form = LibraryDetailForm(
        user=user, data={"name_en": "Test Library", "is_public": False, "order": 0}
    )
    form.save()
    user_libraries = get_editable_libraries(user)
    assert len(user_libraries) == Library.objects.filter(is_public=True).count() + 1
    # All apps user can create public libraries
    form = LibraryDetailForm(
        user=user, data={"name_en": "Test Library 2", "is_public": True, "order": 0}
    )
    form.save()
    user_libraries = get_editable_libraries(user)
    assert len(user_libraries) == Library.objects.filter(is_public=True).count() + 1
    # Public libraries must have a name
    form = LibraryDetailForm(
        user=user, data={"name_en": "", "is_public": True, "order": 0}
    )
    with pytest.raises(ValueError):
        form.save()

    # Basic user should not be able to edit any libraries at this point
    other_user = basic_user()
    client.force_login(other_user)
    user_libraries = get_editable_libraries(other_user)
    assert len(user_libraries) == 0
    # Add a library for the basic user
    form = LibraryDetailForm(user=other_user, data={"is_public": False, "order": 0})
    form.save()
    user_libraries = get_editable_libraries(other_user)
    assert len(user_libraries) == 1
    # Basic user can't create public libraries; it will just end up as a private library
    num_public_libraries = Library.objects.filter(is_public=True).count()
    form = LibraryDetailForm(
        user=other_user,
        data={"name_en": "Test Library 3", "is_public": True, "order": 0},
    )
    form.save()
    assert Library.objects.filter(is_public=True).count() == num_public_libraries

    # Check that admin user can't edit the basic user's non-public library
    client.force_login(user)
    user_libraries = get_editable_libraries(user)
    assert len(user_libraries) == Library.objects.filter(is_public=True).count() + 1


@pytest.mark.django_db
def test_modal_library_list(client, all_apps_user):
    client.force_login(all_apps_user())
    url = reverse("librarian:modal")
    response = client.get(url)
    assert response.status_code == 200


@pytest.mark.django_db
def test_modal_create_library_get(client, all_apps_user):
    client.force_login(all_apps_user())
    url = reverse("librarian:modal_create_library")
    response = client.get(url)
    assert response.status_code == 200


@pytest.mark.django_db
def test_modal_create_library_post(client, all_apps_user):
    client.force_login(all_apps_user())
    url = reverse("librarian:modal_create_library")
    response = client.post(url, {"name_en": "New Library", "is_public": True})
    assert response.status_code == 200  # or 302 if it redirects after creation


@pytest.mark.django_db
def test_modal_edit_library_get(client, all_apps_user, basic_user):
    client.force_login(all_apps_user())
    library = Library.objects.get_default_library()
    url = reverse("librarian:modal_edit_library", kwargs={"library_id": library.id})
    response = client.get(url)
    assert response.status_code == 200
    # Basic user should not be able to edit
    client.force_login(basic_user())
    response = client.get(url)
    # Redirects home with error notification
    assert response.status_code == 302


# @pytest.mark.django_db
# def test_modal_edit_library_post(client, all_apps_user, library):
#     client.force_login(all_apps_user())
#     url = reverse("librarian:modal_edit_library", kwargs={"library_id": library.id})
#     response = client.post(url, {"name_en": "Updated Library", "is_public": True})
#     assert response.status_code == 200  # or 302 if it redirects after update


# @pytest.mark.django_db
# def test_modal_delete_library(client, all_apps_user, library):
#     client.force_login(all_apps_user())
#     url = reverse("librarian:modal_delete_library", kwargs={"library_id": library.id})
#     response = client.delete(url)
#     assert response.status_code == 200  # or 302 if it redirects after deletion


# # Tests for permission checks
# @pytest.mark.django_db
# def test_modal_create_library_post_no_permission(client, basic_user):
#     client.force_login(basic_user())
#     url = reverse("librarian:modal_create_library")
#     response = client.post(url, {"name_en": "New Library", "is_public": True})
#     assert response.status_code == 403


# @pytest.mark.django_db
# def test_modal_edit_library_post_no_permission(client, basic_user, library):
#     client.force_login(basic_user())
#     url = reverse("librarian:modal_edit_library", kwargs={"library_id": library.id})
#     response = client.post(url, {"name_en": "Updated Library", "is_public": True})
#     assert response.status_code == 403


# @pytest.mark.django_db
# def test_modal_delete_library_no_permission(client, basic_user, library):
#     client.force_login(basic_user())
#     url = reverse("librarian:modal_delete_library", kwargs={"library_id": library.id})
#     response = client.delete(url)
#     assert response.status_code == 403


# TODO: These all need to be rewritten for the new librarian / Celery rewrite
"""
@pytest.mark.django_db
@skip_on_github_actions
def test_library(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)

    # Create a library
    Library.objects.create(
        name="Test Library 1",
        description="Library description",
        vector_store_table="test_library_1",
        modified_by=user,
    )

    # Get the library
    library = Library.objects.get(name="Test Library 1")

    # Assert that the library was created
    assert library.description == "Library description"

    # Test that changing the vector_store_table to an invalid value raises a ValidationError
    with pytest.raises(ValidationError):
        library.vector_store_table = "invalid vector table"
        library.save()

    # Test that changing the vector_store_table to a valid value does not raise a ValidationError
    library.vector_store_table = "valid_vector_table"
    library.save()

    # Test that the library can be updated
    library.name = "Updated Library"
    library.save()

    # Assert that the library was updated
    assert library.name == "Updated Library"

    library_pk = library.pk

    # Test that the library can be deleted
    library.delete()

    # Assert that the library was deleted
    assert Library.objects.filter(pk=library_pk).count() == 0


@pytest.mark.django_db
def test_data_source(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)

    # Create a library
    library = Library.objects.create(
        name="Test Library 2",
        description="Library description",
        vector_store_table="test_library_2",
        modified_by=user,
    )

    # Create a data source associated with the library
    data_source = DataSource.objects.create(
        name="Test DataSource",
        library=library,
        modified_by=user,
    )

    assert data_source.security_label == SecurityLabel.default_security_label()

    # Retrieve the created data source
    retrieved_data_source = DataSource.objects.get(name="Test DataSource")

    # Assert the data source was created and associated with the library
    assert retrieved_data_source.name == "Test DataSource"
    assert retrieved_data_source.library == library

    # Test updating the data source
    retrieved_data_source.name = "Updated DataSource"
    retrieved_data_source.save()

    # Assert that the data source was updated
    assert retrieved_data_source.name == "Updated DataSource"

    ds_pk = retrieved_data_source.pk
    # Test that the data source can be deleted
    retrieved_data_source.delete()

    # Assert that the data source was deleted
    assert DataSource.objects.filter(pk=ds_pk).count() == 0


# Test behavior upon Library deletion
@pytest.mark.django_db
@skip_on_github_actions
def test_data_source_deletion_on_library_delete(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)

    library = Library.objects.create(
        name="Test Library 4",
        description="Library description",
        vector_store_table="test_library_4",
        modified_by=user,
    )

    data_source = DataSource.objects.create(
        name="Test DataSource XYZ",
        library=library,
        modified_by=user,
    )

    # Deleting the library and checking if DataSource gets deleted as well
    library.delete()
    assert DataSource.objects.filter(name="Test DataSource XYZ").count() == 0


@skip_on_github_actions
def test_fetch_and_process_data_source(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)

    # Create a library
    library = Library.objects.create(
        name="Test Library 6",
        description="Library description",
        vector_store_table="test_library_6",
        modified_by=user,
    )

    # Create a data source associated with the library
    data_source = DataSource.objects.create(
        name="Test DataSource",
        library=library,
        modified_by=user,
    )

    # Discover content for the data source
    data_source.discover_content()

    # Fetch and process the data source
    data_source.fetch_and_process()

    # Confirm that documents exist in the database after the fetch and process
    assert Document.objects.filter(data_source=data_source).exists()

"""



=== Contents of django\tests\otto\test_manage_users.py ===
import os

from django.urls import reverse

import numpy as np
import pytest

from otto.models import Group, Notification, User


@pytest.mark.django_db
def test_access_manage_users(client, basic_user, all_apps_user):
    user = basic_user(accept_terms=True)
    client.force_login(user)
    response = client.get(reverse("manage_users"))
    assert response.status_code == 302
    # Should be redirected back to index page since this isn't allowed
    assert response.url == reverse("index")
    # Notification should have been created
    notification = Notification.objects.get(user=user)
    assert reverse("manage_users") in notification.text

    # Now test with a user that has the correct permissions (all_apps_user)
    user = all_apps_user()
    client.force_login(user)
    response = client.get(reverse("manage_users"))
    assert response.status_code == 200


@pytest.mark.django_db
def test_modify_user(client, basic_user, all_apps_user):
    user = basic_user(username="basic_user", accept_terms=True)
    admin_user = all_apps_user()
    client.force_login(admin_user)

    # Modify the basic_user
    response = client.post(
        reverse("manage_users"),
        data={"email": [user.id], "group": [1, 2]},
    )
    assert response.status_code == 200
    user.refresh_from_db()
    assert user.groups.count() == 2

    # Modify multiple users
    user2 = basic_user(username="basic_user2", accept_terms=True)
    response = client.post(
        reverse("manage_users"),
        data={"email": [user.id, user2.id], "group": [1, 2, 3]},
    )
    assert response.status_code == 200
    user.refresh_from_db()
    user2.refresh_from_db()
    assert user.groups.count() == 3
    assert user2.groups.count() == 3


@pytest.mark.django_db
def test_get_user_form(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)

    response = client.get(reverse("manage_users_form"))
    assert response.status_code == 200

    response = client.get(reverse("manage_users_form", kwargs={"user_id": user.id}))
    assert response.status_code == 200


@pytest.mark.django_db
def test_manage_users_upload(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)

    response = client.post(reverse("upload_users"), data={})
    assert response.status_code == 302
    assert response.url == reverse("manage_users")

    # Test with a csv file ("users.csv" in this directory)
    """
    upn,roles
    Firstname.Lastname@justice.gc.ca,AI assistant user|template wizard user | CFS Admin
    """
    this_dir = os.path.dirname(os.path.abspath(__file__))
    with open(os.path.join(this_dir, "users.csv"), "rb") as file:
        response = client.post(reverse("upload_users"), data={"csv_file": file})
    assert response.status_code == 302
    assert response.url == reverse("manage_users")
    # Check that the users were created
    new_user = User.objects.filter(upn="Firstname.Lastname@justice.gc.ca")
    assert new_user.exists()
    new_user = new_user.first()
    assert new_user.groups.count() == 3
    assert new_user.first_name == "Firstname"
    assert new_user.last_name == "Lastname"
    assert new_user.email == "Firstname.Lastname@justice.gc.ca"


@pytest.mark.django_db
def test_manage_users_download(client, all_apps_user, basic_user):
    user = all_apps_user()
    client.force_login(user)

    # Create a few basic users and add them to random groups
    group_ids = Group.objects.values_list("id", flat=True)
    u = basic_user(username="user1", accept_terms=True)
    for group_id in np.random.choice(group_ids, min(3, len(group_ids)), replace=False):
        u.groups.add(group_id)
    u = basic_user(username="user2", accept_terms=True)
    for group_id in np.random.choice(group_ids, min(2, len(group_ids)), replace=False):
        u.groups.add(group_id)
    u = basic_user(username="user3", accept_terms=True)
    for group_id in np.random.choice(group_ids, min(4, len(group_ids)), replace=False):
        u.groups.add(group_id)

    users = User.objects.all().values_list("upn", "groups__name")

    response = client.get(reverse("download_users"))
    assert response.status_code == 200
    assert response["Content-Type"] == "text/csv"
    assert "attachment" in response["Content-Disposition"]
    # Save the file to check its contents
    with open("users.csv", "wb") as file:
        file.write(response.content)

    # Upload it
    with open("users.csv", "rb") as file:
        response = client.post(reverse("upload_users"), data={"csv_file": file})
    assert response.status_code == 302

    # Check that the users are unchanged
    updated_users = User.objects.all().values_list("upn", "groups__name")
    assert sorted(list(users)) == sorted(list(updated_users))
    os.remove("users.csv")



=== Contents of django\tests\otto\test_otto_forms.py ===
from django.utils import timezone

import pytest

from otto.forms import FeedbackForm
from otto.models import Feedback


@pytest.mark.django_db
def test_feedback_form_is_valid(all_apps_user):
    user = all_apps_user()
    date_and_time = timezone.now().strftime("%Y%m%d-%H%M%S")

    feedback_form = FeedbackForm(
        user,
        None,
        data={
            "feedback_type": Feedback.FEEDBACK_TYPE_CHOICES[0][0],
            "feedback_message": "Test Message",
            "app": "AI assistant",
            "chat_message_id": -1,
            "modified_by": user,
            "created_at": date_and_time,
            "modified_at": date_and_time,
            "otto_version": "v0",
        },
    )

    assert feedback_form.is_valid()



=== Contents of django\tests\otto\test_otto_models.py ===
import pytest

from otto.models import SecurityLabel


@pytest.mark.django_db
def test_maximumof():
    acronyms_full = ["UC", "PA", "PB"]
    acronyms_empty = []
    acronyms_with_random = ["UC", "PA", "PB", "ZZ"]

    assert SecurityLabel.maximum_of(acronyms_full) == SecurityLabel.objects.get(
        acronym_en="PB"
    )
    assert SecurityLabel.maximum_of(acronyms_with_random) == SecurityLabel.objects.get(
        acronym_en="PB"
    )
    assert SecurityLabel.maximum_of(acronyms_empty) == SecurityLabel.objects.get(
        acronym_en="UC"
    )



=== Contents of django\tests\otto\test_otto_views.py ===
"""
Test the core Otto views (index, login, etc.)
"""

import json

from django.urls import reverse
from django.utils import timezone

import pytest
from bs4 import BeautifulSoup

from chat.models import Chat, Message
from otto.models import Feedback, Notification


@pytest.mark.django_db
def test_homepage(client, basic_user):
    user = basic_user()
    client.force_login(user)
    response = client.get(reverse("index"))
    assert response.status_code == 200
    soup = BeautifulSoup(response.content, "html.parser")
    text = soup.get_text()
    assert "Otto" in text


@pytest.mark.django_db
def test_notifications(client, basic_user):
    """
    1. Create a Notification manually
    2. Check that a li.notification is included from the notifications route
    3. Test the delete notification route
    4. Check that it was deleted in the database
    5. Check that it was deleted via the notifications route
    """
    user = basic_user(accept_terms=True)
    client.force_login(user)
    Notification.objects.create(
        user=user,
        heading="Access controls",
        text=f"You are not authorized to access...",
        category="error",
    )
    notification = user.notifications.first()
    assert notification is not None
    response = client.get(reverse("notifications"))
    assert response.status_code == 200
    soup = BeautifulSoup(response.content, "html.parser")
    # Check that there is exactly one notification
    assert len(soup.find_all("li", class_="notification")) == 1
    response = client.delete(
        reverse("notification", kwargs={"notification_id": notification.id})
    )
    assert response.status_code == 200  # HTMX delete routes return a fragment to swap
    assert user.notifications.count() == 0
    response = client.get(reverse("notifications"))
    assert response.status_code == 200
    soup = BeautifulSoup(response.content, "html.parser")
    assert soup.find("li", class_="notification") is None


def test_valid_feedback_form(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)
    date_and_time = timezone.now().strftime("%Y%m%d-%H%M%S")

    data = {
        "user": user,
        "feedback_type": Feedback.FEEDBACK_TYPE_CHOICES[0][0],
        "feedback_message": "Test Message",
        "app": "AI assistant",
        "chat_message_id": -1,
        "modified_by": user.id,
        "created_at": date_and_time,
        "modified_at": date_and_time,
        "otto_version": "v0",
    }

    response = client.post(
        reverse("user_feedback"),
        data=data,
    )
    assert response.status_code == 302 and "feedback_success" in response.url


def test_valid_feedback_form_from_message(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)
    chat = Chat.objects.create(title="test", user=user)
    Message.objects.create(chat=chat)
    message = Message.objects.create(chat=chat, is_bot=True)
    date_and_time = timezone.now().strftime("%Y%m%d-%H%M%S")

    data = {
        "user": user,
        "feedback_type": Feedback.FEEDBACK_TYPE_CHOICES[0][0],
        "feedback_message": "Test Message",
        "app": "chat",
        "chat_message_id": -1,
        "modified_by": user.id,
        "created_at": date_and_time,
        "modified_at": date_and_time,
        "otto_version": "v0",
    }

    response = client.post(
        reverse("user_feedback", kwargs={"message_id": message.id}),
        data=data,
    )
    assert response.status_code == 200



=== Contents of django\tests\otto\test_utils_common.py ===
from otto.utils.common import file_size_to_string


def test_file_size_to_string():
    assert file_size_to_string(10) == "10 bytes"
    assert file_size_to_string(1024) == "1.00 KB"
    assert file_size_to_string(1024 * 1024) == "1.00 MB"
    assert file_size_to_string(1024 * 1024 * 1024) == "1024.00 MB"



=== Contents of django\tests\template_wizard\test_template_wizard_views.py ===
from django.urls import reverse

import pytest

from otto.secure_models import AccessKey
from template_wizard.models import Report

pytestmark = pytest.mark.django_db


def test_canlii_wizard(client, all_apps_user):
    user = all_apps_user()
    client.force_login(user)

    response = client.get(reverse("template_wizard:index"))
    assert response.status_code == 200

    # Simulate posting the selection of starting a new report
    response = client.post(
        reverse("template_wizard:index"),
        data={"new_or_open": "new", "wizard": "canlii_wizard"},
        follow=True,  # Follow redirects
    )
    assert response.status_code == 200

    # Get the latest Report for the user
    report = Report.objects.all(AccessKey(user=user)).latest("created_at")
    assert report.wizard == "canlii_wizard"

    # Simulate posting the selection of opening an existing report
    response = client.post(
        reverse("template_wizard:index"),
        data={"new_or_open": "open", "report_id": report.id},
        follow=True,  # Follow redirects
    )
    assert response.status_code == 200

    # Delete the report by calling the delete_report view
    response = client.get(reverse("template_wizard:delete_report", args=[report.id]))
    assert response.status_code == 200
    assert not Report.objects.filter(AccessKey(user=user), id=report.id).exists()

    # TODO: Select data for the report
    # TODO: Pick a template for the report
    # TODO: Download the report



=== Contents of django\tests\text_extractor\helpers\test_utils.py ===
import pytest

from text_extractor.utils import *


def test_format_merged_file_name():
    # Test when all file names fit
    file_names_to_merge = ["file1", "file2", "file3"]
    merged_file_name = format_merged_file_name(file_names_to_merge)
    assert merged_file_name == "Merged_file1_file2_file3"

    max_length = 4  # set a max_length so that no file names fit
    merged_file_name = format_merged_file_name(file_names_to_merge, max_length)
    assert merged_file_name == "Merged_3_files"

    max_length = 15  # set a max_length so that only some file names fit
    merged_file_name = format_merged_file_name(file_names_to_merge, max_length)
    assert merged_file_name == "Merged_file1_file2_and_1_more"


def test_resize_image_to_a4(mock_image_file2):
    # DPI can be adjusted if needed
    dpi = 150
    a4_width, a4_height = int(8.27 * dpi), int(11.69 * dpi)

    # Call the function under test
    resized_img = resize_image_to_a4(mock_image_file2, dpi=dpi)

    # Assert the size of the returned image is A4
    assert resized_img.size == (
        a4_width,
        a4_height,
    ), "The resized image does not match A4 size"

    # Assert the mode of the returned image is "RGB"
    assert resized_img.mode == "RGB", "The mode of the resized image is not RGB"


def test_dist():
    class Point:
        def __init__(self, x, y):
            self.x = x
            self.y = y

    p1 = Point(0, 0)
    p2 = Point(3, 4)
    assert dist(p1, p2) == 5

    p1 = Point(-3, -4)
    p2 = Point(0, 0)
    assert dist(p1, p2) == 5  # Testing with negative points

    p1 = Point(-3, 4)
    p2 = Point(3, -4)
    assert dist(p1, p2) == 10  # Testing with points in different quadrants

    p1 = Point(-1, -1)
    p2 = Point(-4, -5)
    assert dist(p1, p2) == 5  # Both points negative, distance should still be 5

    p1 = Point(-3, 0)
    p2 = Point(0, 4)
    assert dist(p1, p2) == 5  # One point negative, the other positive


def test_get_page_count_pdf(mock_pdf_file):
    page_count = get_page_count(mock_pdf_file)
    assert page_count == 3, "The page count should be 3"


def test_get_page_count_image(mock_image_file):
    page_count = get_page_count(mock_image_file)
    assert page_count == 1


def test_get_page_count_unsupported(mock_unsupported_file):
    with pytest.raises(ValueError):
        get_page_count(mock_unsupported_file)


def test_calculate_start_pages_empty():
    assert calculate_start_pages([]) == {}, "Should return an empty dict for no files"


def test_calculate_start_pages_single_file(mock_pdf_file):
    files = [mock_pdf_file]
    expected = {"temp_file1.pdf": 2}
    assert (
        calculate_start_pages(files) == expected
    ), "Incorrect start page for a single file"


def test_calculate_start_pages_multiple_files(
    mock_pdf_file, mock_pdf_file2, mock_image_file
):
    expected = {"temp_file1.pdf": 2, "temp_file2.pdf": 5, "temp_image.jpg": 15}
    with mock_pdf_file, mock_pdf_file2, mock_image_file:
        files = [mock_pdf_file, mock_pdf_file2, mock_image_file]
        result = calculate_start_pages(files)
        assert result == expected, f"Expected {expected}, got {result}"



=== Contents of django\tests\text_extractor\helpers\test_views.py ===
from django.conf import settings
from django.urls import reverse

import pytest

from text_extractor.views import *

pytest_plugins = ("pytest_asyncio",)
skip_on_github_actions = pytest.mark.skipif(
    settings.IS_RUNNING_IN_GITHUB, reason="Skipping tests on GitHub Actions"
)

skip_on_devops_pipeline = pytest.mark.skipif(
    settings.IS_RUNNING_IN_DEVOPS, reason="Skipping tests on DevOps Pipelines"
)


# These tests are failing on GitHub and DevOps due to authorization issues
@skip_on_github_actions
@skip_on_devops_pipeline
def test_merged_document_submission(client, all_apps_user, mock_pdf_file):
    user = all_apps_user()
    client.force_login(user)

    response = client.get(reverse("text_extractor:index"))
    assert response.status_code == 200

    # Prepare the data for the POST request
    data = {"file_upload": mock_pdf_file, "merge_docs_checkbox": "on"}

    # Make a POST request to the submit_document view
    response = client.post(reverse("text_extractor:submit_document"), data)

    # Check if the response status code is 200
    assert response.status_code == 200

    # Check that the response text does not contain "error"
    assert "error" not in response.content.decode().lower()

    # Check if the response contains the expected context data
    assert "ocr_docs" in response.context
    assert "user_request_id" in response.context


# These tests are failing on GitHub and DevOps due to authorization issues
@skip_on_github_actions
@skip_on_devops_pipeline
def test_document_submission_and_download(client, all_apps_user, mock_pdf_file):
    user = all_apps_user()
    client.force_login(user)

    response = client.get(reverse("text_extractor:index"))
    assert response.status_code == 200

    # Prepare the data for the POST request
    data = {"file_upload": mock_pdf_file}

    # Make a POST request to the submit_document view
    response = client.post(reverse("text_extractor:submit_document"), data)

    # Check if the response status code is 200
    assert response.status_code == 200

    # Check that the response text does not contain "error"
    assert "error" not in response.content.decode().lower()

    # Check if the response contains the expected context data
    assert "ocr_docs" in response.context
    assert "user_request_id" in response.context

    # Test the download view: "download_document/<str:file_id>/<str:user_request_id>",
    user_request_id = response.context["user_request_id"]
    docs = response.context["ocr_docs"]
    assert len(docs) == 1

    # There should be two properties on the doc: "pdf" and "txt". Each has a file_id
    pdf_file_id = docs[0]["pdf"]["file"].file_id
    txt_file_id = docs[0]["txt"]["file"].file_id

    # Make a GET request to the download_document view
    response = client.get(
        reverse("text_extractor:download_document", args=[pdf_file_id, user_request_id])
    )
    # Validate these properties:
    #    response = HttpResponse(file.read(), content_type="application/octet-stream")
    #    response["Content-Disposition"] = (
    #        f'attachment; filename="{output_file.file_name}"'
    #    )
    assert response.status_code == 200
    assert response["Content-Type"] == "application/octet-stream"
    assert "attachment" in response["Content-Disposition"].lower()
    # Same for Text file
    response = client.get(
        reverse("text_extractor:download_document", args=[txt_file_id, user_request_id])
    )
    assert response.status_code == 200
    assert response["Content-Type"] == "application/octet-stream"
    assert "attachment" in response["Content-Disposition"].lower()

    # Try a random File ID; this should return the error message ("error" in the response)
    response = client.get(
        reverse(
            "text_extractor:download_document", args=["random_file_id", user_request_id]
        )
    )
    assert "error" in response.content.decode().lower()



=== Contents of django\text_extractor\__init__.py ===



=== Contents of django\text_extractor\admin.py ===
from django.contrib import admin

# Register your models here.



=== Contents of django\text_extractor\apps.py ===
import os

from django.apps import AppConfig
from django.conf import settings


class OcrConfig(AppConfig):
    default_auto_field = "django.db.models.BigAutoField"
    name = "text_extractor"

    def ready(self):
        # This line ensures that the import happens when the app is ready,
        # preventing any AppRegistryNotReady exception.
        from django.core.files.storage import default_storage as storage

        # Define the path for the ocr_output_files directory
        ocr_output_path = os.path.join(settings.MEDIA_ROOT, "ocr_output_files")

        # Check if the directory exists, and create it if it doesn't
        if not storage.exists(ocr_output_path):
            os.makedirs(ocr_output_path, exist_ok=True)



=== Contents of django\text_extractor\models.py ===
# Create your models here.
from django.db import models

from otto.secure_models import SecureModel


class UserRequest(SecureModel):
    name = models.CharField(max_length=255, default="Untitled request")
    created_at = models.DateTimeField(auto_now_add=True)

    def __str__(self):
        return f"{self.name} - {self.created_at.strftime('%Y-%m-%d %H:%M:%S')}"


class OutputFile(SecureModel):
    file_id = models.CharField(max_length=255, null=True, blank=True)
    file = models.FileField(upload_to="ocr_output_files/")
    file_name = models.CharField(max_length=255, null=True, blank=True)
    user_request = models.ForeignKey(
        UserRequest, related_name="output_files", on_delete=models.CASCADE
    )

    def get_permission_parents(self):
        return [self.user_request]



=== Contents of django\text_extractor\tests.py ===
from django.test import TestCase

# Create your tests here.



=== Contents of django\text_extractor\urls.py ===
from django.urls import path

from . import views

app_name = "text_extractor"

urlpatterns = [
    path("", views.index, name="index"),
    path("submit_document/", views.submit_document, name="submit_document"),
    path(
        "download_document/<str:file_id>/<str:user_request_id>",
        views.download_document,
        name="download_document",
    ),
]



=== Contents of django\text_extractor\utils.py ===
import io
import math
import os
import tempfile
from io import BytesIO

from django.conf import settings

from azure.ai.formrecognizer import DocumentAnalysisClient
from azure.core.credentials import AzureKeyCredential
from pdf2image import convert_from_path
from PIL import Image, ImageSequence
from PIL.Image import Resampling
from PyPDF2 import PdfReader, PdfWriter
from reportlab.lib import pagesizes
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas

default_font = "Helvetica"
img_extensions = (".tif", ".tiff", ".jpg", ".jpeg", ".png", ".bmp")


def format_merged_file_name(file_names_to_merge, max_length=35):

    # sort files by shortest name to longest name
    file_names_to_merge.sort(key=len)

    joined_file_names = ""
    extra_files = 0
    for file_name in file_names_to_merge:
        if len(joined_file_names) + len(file_name) <= max_length:
            joined_file_names += file_name + "_"
        else:
            extra_files += 1
    joined_file_names = joined_file_names.rstrip("_")
    if len(joined_file_names) == 0:
        merged_file_name = (
            f"Merged_{extra_files}_files" if extra_files > 1 else "Merged_1_file"
        )
    elif extra_files > 0:
        merged_file_name = f"Merged_{joined_file_names}_and_{extra_files}_more"
    else:
        merged_file_name = f"Merged_{joined_file_names}"
    return merged_file_name


def create_toc_pdf(file_names, start_pages):
    default_font = "Times-Roman"
    toc_pdf_bytes = BytesIO()
    c = canvas.Canvas(toc_pdf_bytes, pagesize=A4)
    y_position = 750
    c.setFont(default_font, 12)
    c.drawString(30, y_position, "Table of Contents/Table des matires")
    y_position -= 30

    for index, file in enumerate(file_names, start=1):
        file_name = file.name  # Adjust based on your file object properties
        c.drawString(50, y_position, file_name)  # Draw the file name
        c.drawRightString(
            550, y_position, str(start_pages[file_name])
        )  # Draw the page number right-aligned
        y_position -= 20
        if y_position < 50:  # Start a new page if there's no room
            c.showPage()
            c.setFont(default_font, 12)
            y_position = 750

    c.showPage()
    c.save()
    toc_pdf_bytes.seek(0)
    return toc_pdf_bytes


def get_page_count(file):
    extension = os.path.splitext(file.name)[1].lower()
    if extension == ".pdf":
        reader = PdfReader(file)
        return len(reader.pages)
    elif extension in img_extensions:
        # For image files, consider each file as one page
        return 1
    else:
        raise ValueError(f"Unsupported file type: {extension}")


def calculate_start_pages(files):
    start_pages = {}
    current_page = 2  # Start numbering from 2, bec 1 is table of contents

    for file in files:
        file_name = file.name  # Adjust based on your file object properties
        start_pages[file_name] = current_page
        current_page += get_page_count(file)

    return start_pages


def resize_image_to_a4(img, dpi=150):
    a4_width = int(8.27 * dpi)  # 8.27 inches is 210mm
    a4_height = int(11.69 * dpi)  # 11.69 inches is 297mm

    # Calculate the scaling factor to maintain aspect ratio
    img_ratio = img.width / img.height
    a4_ratio = a4_width / a4_height

    if img_ratio > a4_ratio:
        # Image is wider than A4 ratio, fit by width
        new_width = int(a4_width / 2)
        new_height = int(new_width / img_ratio)
    else:
        # Image is taller than A4 ratio, fit by height
        new_height = a4_height - 30
        new_width = int(new_height * img_ratio)

    # Resize the image using LANCZOS (formerly ANTIALIAS)
    resized_img = img.resize((new_width, new_height), Resampling.LANCZOS)

    # Create an A4 background
    background = Image.new("RGB", (a4_width, a4_height), "white")
    offset = ((a4_width - new_width) // 2, (a4_height - new_height) // 2)
    background.paste(resized_img, offset)
    return background


def dist(p1, p2):
    return math.sqrt((p1.x - p2.x) * (p1.x - p2.x) + (p1.y - p2.y) * (p1.y - p2.y))


def create_searchable_pdf(input_file, add_header):
    # Create a temporary file and write the contents of the uploaded file to it
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp:
        for chunk in input_file.chunks():
            temp.write(chunk)
        temp_path = temp.name

    if input_file.name.lower().endswith(".pdf"):
        # image_pages = convert_from_path(temp_path)
        image_pages = convert_from_path(
            temp_path, dpi=100
        )  # Adjust DPI as needed for compression

        # Save the compressed images to a new temporary file
        with tempfile.NamedTemporaryFile(
            delete=False, suffix=".pdf"
        ) as temp_compressed:
            for page in image_pages:
                page.save(
                    temp_compressed, "PDF", resolution=50
                )  # Adjust resolution as needed
            temp_path = temp_compressed.name

    elif input_file.name.lower().endswith(img_extensions):
        with Image.open(temp_path) as img:
            image_pages_original = ImageSequence.Iterator(img)
            image_pages = [resize_image_to_a4(image) for image in image_pages_original]
        # Save the resized images to a new temporary file
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp_resized:
            for page in image_pages:
                page.save(temp_resized, "PDF")
            temp_path = temp_resized.name

    else:
        raise ValueError(
            f"Unsupported file type:{input_file}. Supported extensions: .pdf or {img_extensions}"
        )

    # Running OCR using Azure Form Recognizer Read API------
    document_analysis_client = DocumentAnalysisClient(
        endpoint=settings.AZURE_COGNITIVE_SERVICE_ENDPOINT,
        credential=AzureKeyCredential(settings.AZURE_COGNITIVE_SERVICE_KEY),
        headers={"x-ms-useragent": "searchable-pdf-blog/1.0.0"},
    )
    with open(temp_path, "rb") as f:
        poller = document_analysis_client.begin_analyze_document(
            "prebuilt-read", document=f
        )

    ocr_results = poller.result()

    print(
        f"Azure Form Recognizer finished OCR text for {len(ocr_results.pages)} pages."
    )
    all_text = []
    for page in ocr_results.pages:
        for line in page.lines:
            all_text.append(line.content)

    all_text = "\n".join(all_text)

    # Generate OCR overlay layer
    output = PdfWriter()

    for page_id, page in enumerate(ocr_results.pages):
        ocr_overlay = io.BytesIO()
        # Calculate overlay PDF page size
        if image_pages[page_id].height > image_pages[page_id].width:
            page_scale = float(image_pages[page_id].height) / pagesizes.letter[1]
        else:
            page_scale = float(image_pages[page_id].width) / pagesizes.letter[1]

        page_width = float(image_pages[page_id].width) / page_scale
        page_height = float(image_pages[page_id].height) / page_scale

        scale = (page_width / page.width + page_height / page.height) / 2.0
        pdf_canvas = canvas.Canvas(ocr_overlay, pagesize=(page_width, page_height))

        # Add image into PDF page
        pdf_canvas.drawInlineImage(
            image_pages[page_id],
            0,
            0,
            width=page_width,
            height=page_height,
            preserveAspectRatio=True,
        )

        text = pdf_canvas.beginText()
        # Set text rendering mode to invisible
        text.setTextRenderMode(3)

        for word in page.words:
            # Calculate optimal font size
            desired_text_width = (
                max(
                    dist(word.polygon[0], word.polygon[1]),
                    dist(word.polygon[3], word.polygon[2]),
                )
                * scale
            )
            desired_text_height = (
                max(
                    dist(word.polygon[1], word.polygon[2]),
                    dist(word.polygon[0], word.polygon[3]),
                )
                * scale
            )
            font_size = desired_text_height
            actual_text_width = pdf_canvas.stringWidth(
                word.content, default_font, font_size
            )

            # Calculate text rotation angle
            text_angle = math.atan2(
                (
                    word.polygon[1].y
                    - word.polygon[0].y
                    + word.polygon[2].y
                    - word.polygon[3].y
                )
                / 2.0,
                (
                    word.polygon[1].x
                    - word.polygon[0].x
                    + word.polygon[2].x
                    - word.polygon[3].x
                )
                / 2.0,
            )
            text.setFont(default_font, font_size)
            text.setTextTransform(
                math.cos(text_angle),
                -math.sin(text_angle),
                math.sin(text_angle),
                math.cos(text_angle),
                word.polygon[3].x * scale,
                page_height - word.polygon[3].y * scale,
            )
            text.setHorizScale(desired_text_width / actual_text_width * 100)
            text.textOut(word.content + " ")

        # add header
        if add_header:
            header_text = f"Filename: {str(input_file)}"
            pdf_canvas.setFont(default_font, 10)
            pdf_canvas.drawString(30, page_height - 30, header_text)

        pdf_canvas.drawText(text)
        pdf_canvas.save()

        # Move to the beginning of the buffer
        ocr_overlay.seek(0)

        # Create a new PDF page
        new_pdf_page = PdfReader(ocr_overlay)  # changed
        output.add_page(new_pdf_page.pages[0])

    return output, all_text



=== Contents of django\text_extractor\views.py ===
import os
from datetime import datetime
from io import BytesIO

from django.core.files.base import ContentFile
from django.core.files.uploadedfile import InMemoryUploadedFile
from django.http import HttpResponse, JsonResponse
from django.shortcuts import render

from PyPDF2 import PdfMerger

from otto.secure_models import AccessKey
from otto.utils.common import file_size_to_string
from otto.utils.decorators import app_access_required
from text_extractor.models import OutputFile, UserRequest

from .utils import (
    calculate_start_pages,
    create_searchable_pdf,
    create_toc_pdf,
    format_merged_file_name,
)

app_name = "text_extractor"


@app_access_required(app_name)
def index(request):
    from text_extractor.utils import img_extensions

    extensions = ", ".join(list(img_extensions) + [".pdf"])
    return render(request, "text_extractor/ocr.html", {"extensions": extensions})


def submit_document(request):

    if request.method == "POST":
        files = request.FILES.getlist("file_upload")

        print(f"Received {len(files)} files")
        access_key = AccessKey(user=request.user)

        UserRequest.grant_create_to(access_key)
        OutputFile.grant_create_to(access_key)
        user_request = UserRequest.objects.create(access_key)

        user_name = request.user.username
        user_request.name = user_name

        completed_documents = []
        all_texts = []

        merged = request.POST.get("merge_docs_checkbox", False)
        merger = PdfMerger() if merged else None
        file_names_to_merge = []

        try:
            if merged:
                start_pages = calculate_start_pages(files)
                toc_pdf_bytes = create_toc_pdf(files, start_pages)
                toc_file = InMemoryUploadedFile(
                    toc_pdf_bytes,
                    "file",
                    "toc.pdf",
                    "application/pdf",
                    toc_pdf_bytes.getbuffer().nbytes,
                    None,
                )
                files.insert(0, toc_file)

            current_time = datetime.now().strftime("%Y%m%d_%H%M%S")

            for idx, file in enumerate(files):

                ocr_file, txt_file = create_searchable_pdf(file, merged and idx > 0)
                all_texts.append(txt_file)

                input_name, _ = os.path.splitext(file.name)

                pdf_bytes = BytesIO()
                ocr_file.write(pdf_bytes)

                if merged:
                    file_name = input_name
                    pdf_bytes.seek(0)
                    merger.append(pdf_bytes)
                    if idx > 0:  # Exclude TOC from file names to merge
                        file_names_to_merge.append(file_name)
                else:
                    file_id = f"{user_name}_{current_time}_OCR_{input_name}.pdf"
                    text_id = f"{user_name}_{current_time}_{input_name}.txt"
                    file_name = f"OCR_{input_name}.pdf"
                    text_name = f"OCR_{input_name}.txt"

                    content_file = ContentFile(pdf_bytes.getvalue(), name=file_id)
                    content_text = ContentFile(txt_file, name=text_id)

                    output_file = OutputFile.objects.create(
                        access_key,
                        file=content_file,
                        file_id=file_id,
                        file_name=file_name,
                        user_request=user_request,
                    )

                    output_text = OutputFile.objects.create(
                        access_key,
                        file=content_text,
                        file_id=text_id,
                        file_name=text_name,
                        user_request=user_request,
                    )

                    output_file.save(access_key)
                    output_text.save(access_key)
                    completed_documents.append(
                        {
                            "pdf": {
                                "file": output_file,
                                "size": file_size_to_string(output_file.file.size),
                            },
                            "txt": {
                                "file": output_text,
                                "size": file_size_to_string(output_text.file.size),
                            },
                        }
                    )

            if merged:

                formatted_merged_name = format_merged_file_name(
                    file_names_to_merge, max_length=40
                )
                merged_file_id = (
                    f"{user_name}_{current_time}_{formatted_merged_name}.pdf"
                )
                merged_text_id = (
                    f"{user_name}_{current_time}_{formatted_merged_name}.txt"
                )
                merge_file_name = f"{formatted_merged_name}.pdf"
                merged_text_name = f"{formatted_merged_name}.txt"

                merged_pdf_bytes = BytesIO()
                merger.write(merged_pdf_bytes)
                merged_pdf_file = ContentFile(
                    merged_pdf_bytes.getvalue(), name=merged_file_id
                )

                all_texts_bytes = BytesIO()
                for text in all_texts:
                    all_texts_bytes.write(text.encode())
                    all_texts_bytes.write(b"\n")
                all_texts_bytes.seek(0)
                all_texts_file = ContentFile(
                    all_texts_bytes.getvalue(), name=merged_text_id
                )

                output_file = OutputFile.objects.create(
                    access_key,
                    file=merged_pdf_file,
                    file_id=merged_file_id,
                    file_name=merge_file_name,
                    user_request=user_request,
                )

                output_text = OutputFile.objects.create(
                    access_key,
                    file=all_texts_file,
                    file_id=merged_text_id,
                    file_name=merged_text_name,
                    user_request=user_request,
                )

                output_file.save(access_key)
                output_text.save(access_key)
                completed_documents.append(
                    {
                        "pdf": {
                            "file": output_file,
                            "size": file_size_to_string(output_file.file.size),
                        },
                        "txt": {
                            "file": output_text,
                            "size": file_size_to_string(output_text.file.size),
                        },
                    }
                )

            context = {
                "ocr_docs": completed_documents,
                "user_request_id": user_request.id,
            }
            user_request.save(access_key)

            return render(request, "text_extractor/completed_documents.html", context)

        except Exception as e:
            # Improve error logging
            import traceback

            print(f"ERROR: {str(e)}")
            print(traceback.format_exc())
            return render(
                request, "text_extractor/error_message.html", {"error_message": str(e)}
            )
    else:
        return JsonResponse({"error": "Invalid request method."}, status=400)


def download_document(request, file_id, user_request_id):
    access_key = AccessKey(user=request.user)
    user_request = UserRequest.objects.get(access_key, id=user_request_id)

    try:
        output_file = user_request.output_files.get(
            access_key=access_key, file_id=file_id
        )
    except OutputFile.DoesNotExist:
        return render(request, "text_extractor/error_message.html")

    with output_file.file.open("rb") as file:
        response = HttpResponse(file.read(), content_type="application/octet-stream")
        response["Content-Disposition"] = (
            f'attachment; filename="{output_file.file_name}"'
        )
        return response



=== Contents of django\text_extractor\migrations\__init__.py ===



=== Contents of django\text_extractor\migrations\0001_initial.py ===
# Generated by Django 5.0.7 on 2024-07-25 20:33

import django.db.models.deletion
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        ("otto", "0001_initial"),
    ]

    operations = [
        migrations.CreateModel(
            name="UserRequest",
            fields=[
                (
                    "id",
                    models.UUIDField(editable=False, primary_key=True, serialize=False),
                ),
                ("name", models.CharField(default="Untitled request", max_length=255)),
                ("created_at", models.DateTimeField(auto_now_add=True)),
                ("access_controls", models.ManyToManyField(to="otto.accesscontrol")),
            ],
            options={
                "abstract": False,
            },
        ),
        migrations.CreateModel(
            name="OutputFile",
            fields=[
                (
                    "id",
                    models.UUIDField(editable=False, primary_key=True, serialize=False),
                ),
                ("file_id", models.CharField(blank=True, max_length=255, null=True)),
                ("file", models.FileField(upload_to="ocr_output_files/")),
                ("file_name", models.CharField(blank=True, max_length=255, null=True)),
                ("access_controls", models.ManyToManyField(to="otto.accesscontrol")),
                (
                    "user_request",
                    models.ForeignKey(
                        on_delete=django.db.models.deletion.CASCADE,
                        related_name="output_files",
                        to="text_extractor.userrequest",
                    ),
                ),
            ],
            options={
                "abstract": False,
            },
        ),
    ]



